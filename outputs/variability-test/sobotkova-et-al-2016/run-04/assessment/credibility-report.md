# Credibility Assessment Report

**Paper:** Sobotkova, A., Ross, S.A., Ballsun-Stanton, B., Fairbairn, A., Thompson, J., & VanValkenburgh, P. (2016). Measure Twice, Cut Once: Cooperative Deployment of a Generalized, Archaeology-Specific Field Data Collection System. In *Mobilizing the Past for a Digital Future*, 337-371.

**Run ID:** run-04
**Assessment Date:** 2025-12-04
**Quality State:** HIGH

---

## Executive Summary

| Dimension | Score | Assessment |
|-----------|-------|------------|
| Cluster 1: Foundational Clarity | 70.0 | MODERATE-HIGH |
| Cluster 2: Evidential Strength | 62.5 | MODERATE |
| Cluster 3: Reproducibility | 62.0 | MODERATE |
| **Aggregate Score** | **65.0** | **MODERATE** |

This methodological paper documents the cooperative deployment of the FAIMS mobile platform through three archaeological case studies. The paper demonstrates moderate overall credibility, with particular strengths in transparency (open-source software, supplementary materials) and plausibility (well-supported claims with quantitative evidence). Key limitations include potential conflicts of interest (authors include FAIMS developers), undocumented thematic analysis procedures, and limited generalisability from three case studies.

---

## Classification Summary

| Attribute | Value |
|-----------|-------|
| Paper Type | Methodological |
| Research Approach | Inductive |
| Mixed Methods | Yes (qualitative + quantitative) |
| Context Flags | ðŸ“¦ Software/tool paper |
| HARKing Detected | No |

---

## Signal Scores

### Cluster 1: Foundational Clarity (Transparency Pillar)

| Signal | Score | Key Findings |
|--------|-------|--------------|
| Comprehensibility | 68 | Clear structure and terminology; thematic analysis procedure undocumented |
| Transparency | 72 | Strong code/data availability; conflicts of interest undisclosed |

### Cluster 2: Evidential Strength (Credibility Pillar)

| Signal | Score | Key Findings |
|--------|-------|--------------|
| Plausibility | 78 | Claims well-supported by quantitative evidence; appropriately hedged |
| Validity | 65 | Appropriate case study design; potential selection and self-report bias |
| Robustness | 52 | Convergent evidence across cases; no sensitivity analysis; limited sample |
| Generalisability | 55 | Diverse contexts; single platform limits broader claims |

### Cluster 3: Reproducibility Pillar

| Signal | Score | Key Findings |
|--------|-------|--------------|
| Reproducibility | 62 | Strong materials access; analytical procedure undocumented |

---

## Aggregate Score Calculation

| Cluster | Score | Weight | Weighted |
|---------|-------|--------|----------|
| Cluster 1 | 70.0 | 0.30 | 21.0 |
| Cluster 2 | 62.5 | 0.40 | 25.0 |
| Cluster 3 | 62.0 | 0.30 | 18.6 |
| **Total** | â€” | â€” | **64.6 â‰ˆ 65** |

---

## Key Strengths

1. **Open Source Availability:** FAIMS software and modules available on GitHub under GPLv.3 licence, enabling independent verification and reuse
2. **Comprehensive Supplementary Materials:** Complete unedited communications with project directors available, supporting transparency
3. **Well-Documented Quantitative Evidence:** Specific cost and time savings figures (e.g., 95% labour saving, AU$5,000-10,000 annually) with clear sources
4. **Appropriate Research Design:** Multi-case study approach suitable for exploratory evaluation of technology intervention
5. **Convergent Findings:** Consistent themes across three diverse archaeological contexts (Turkey, Malawi, Peru)

---

## Key Limitations

1. **Undisclosed Conflicts of Interest:** Authors include FAIMS development team members evaluating their own platform
2. **Undocumented Thematic Analysis:** Procedure for deriving three themes from data not described, preventing replication
3. **Potential Selection Bias:** Project directors "offered to share" experiences - volunteer participants may not be representative
4. **Limited Sample Size:** Three case studies constrain robustness and generalisability claims
5. **Single Platform Focus:** All cases used FAIMS; no comparison with alternative digital recording systems

---

## Assessment Notes

### Approach-Specific Considerations

As an **inductive methodological paper**, this work was assessed against anchors emphasising:
- Workflow transparency rather than pre-registration
- Sampling documentation and case selection rationale
- Clarity of iterative analytical procedures
- Appropriate hedging of generalisations from limited cases

### Software/Tool Paper Context

The ðŸ“¦ context flag acknowledges this paper's primary purpose is technology evaluation rather than archaeological findings. Assessment weighted:
- Code/software availability highly
- Documentation and user support transparency
- Evidence of practical utility across deployment contexts

---

## Recommendations for Future Research

1. **Pre-register deployment evaluations** to reduce confirmation bias risk
2. **Include comparison groups** (projects using alternative systems)
3. **Document thematic analysis procedures** for qualitative synthesis
4. **Recruit independent evaluators** to avoid self-assessment bias
5. **Report unsuccessful deployments** to provide balanced perspective
6. **Add ORCID identifiers** for author disambiguation

---

## Conclusion

Sobotkova et al. (2016) provides a moderately credible account of FAIMS platform deployment with notable strengths in transparency and evidence quality. The paper's primary value lies in its candid reporting of co-development challenges and quantified benefits. However, the potential for bias (self-evaluation), limited sample size, and undocumented analytical procedures constrain the weight that should be placed on its generalisable conclusions. The open-source software and supplementary materials enable independent verification of specific claims.

**Overall Assessment:** This paper meets moderate credibility standards for a methodological evaluation. Claims about cost-benefit trade-offs are well-supported; broader generalisations about co-development best practices should be treated with appropriate caution given the study's limitations.

---

*Assessment conducted using repliCATS Seven Signals framework adapted for HASS disciplines*
*Approach-specific scoring anchors: Inductive*
*Quality gating: HIGH - full assessment completed*
