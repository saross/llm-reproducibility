{
  "paper_id": "ballsun-stanton-et-al-2018",
  "run_id": "run-04",
  "assessment_date": "2025-12-03",
  "framework": "repliCATS Seven Signals (HASS-adapted)",

  "classification": {
    "paper_type": "methodological",
    "paper_type_confidence": "high",
    "research_approach": "inductive",
    "research_approach_confidence": "medium",
    "context_flags": ["ðŸ“¦", "ðŸ”§"],
    "special_considerations": [
      "Software publication assessment criteria applied",
      "FAIR4RS principles used for reproducibility evaluation",
      "Impact evidence relies on self-report"
    ]
  },

  "quality_gating": {
    "quality_state": "high",
    "route": "full_assessment",
    "extraction_completeness": {
      "evidence_count": 43,
      "claims_count": 58,
      "implicit_arguments_count": 8,
      "research_designs_count": 4,
      "methods_count": 4,
      "protocols_count": 9
    },
    "known_uncertainties": 4
  },

  "signals": {
    "comprehensibility": {
      "cluster": 1,
      "rating": "strong",
      "score": 85,
      "key_factors": [
        "Clear architecture description",
        "Effective browser-website analogy",
        "Comprehensive feature documentation",
        "Visual aids support understanding"
      ],
      "limitations": [
        "Technical jargon assumes developer familiarity",
        "No end-to-end workflow narrative"
      ]
    },
    "transparency": {
      "cluster": 1,
      "rating": "strong",
      "score": 90,
      "key_factors": [
        "Full source code under GPLv3",
        "Multiple repository access points",
        "Comprehensive documentation channels",
        "Perma.cc archival links"
      ],
      "limitations": [
        "Deployment statistics methodology not documented",
        "User feedback selection criteria unclear"
      ]
    },
    "validity": {
      "cluster": 2,
      "rating": "adequate",
      "score": 70,
      "key_factors": [
        "Technical claims verifiable through code",
        "Deployment evidence across 60 projects",
        "External validation reference (Sobotkova 2016)"
      ],
      "limitations": [
        "Self-reported impact metrics",
        "No independent verification",
        "Potential selection bias"
      ]
    },
    "robustness": {
      "cluster": 2,
      "rating": "adequate",
      "score": 65,
      "key_factors": [
        "Five years development maturity",
        "40+ customisations demonstrate stability",
        "Cross-disciplinary deployment success"
      ],
      "limitations": [
        "No systematic testing documented",
        "Edge cases not discussed",
        "No comparative benchmarks"
      ]
    },
    "generalisability": {
      "cluster": 2,
      "rating": "adequate",
      "score": 72,
      "key_factors": [
        "Seven disciplines mentioned",
        "Customisation architecture supports adaptation",
        "Offline operation suits diverse contexts"
      ],
      "limitations": [
        "Archaeology dominates evidence",
        "Adoption barriers not analysed",
        "Resource requirements unclear"
      ]
    },
    "reproducibility": {
      "cluster": 3,
      "rating": "strong",
      "score": 88,
      "key_factors": [
        "Complete source code availability",
        "Multiple installation pathways",
        "Comprehensive documentation",
        "Version control and archival"
      ],
      "limitations": [
        "Server setup complexity",
        "No containerised deployment",
        "Hardware requirements unspecified"
      ]
    }
  },

  "cluster_summaries": {
    "cluster_1_foundational_clarity": {
      "rating": "strong",
      "average_score": 87.5,
      "signals": ["comprehensibility", "transparency"]
    },
    "cluster_2_evidential_strength": {
      "rating": "adequate",
      "average_score": 69,
      "signals": ["validity", "robustness", "generalisability"]
    },
    "cluster_3_reproducibility": {
      "rating": "strong",
      "average_score": 88,
      "signals": ["reproducibility"]
    }
  },

  "fair_assessment": {
    "findable": 9,
    "accessible": 9,
    "interoperable": 8,
    "reusable": 9,
    "total": 35,
    "max_possible": 40,
    "percentage": 87.5
  },

  "overall": {
    "verdict": "good",
    "aggregate_score": 78,
    "score_calculation": "Weighted average: (87.5 + 69 + 88) / 3 = 81.5, adjusted for software publication genre",
    "summary": "Strong transparency and reproducibility practices with adequate evidential strength. Exemplary open-source software publication with limited impact evidence methodology."
  },

  "key_strengths": [
    "Full GPLv3 source code availability",
    "Comprehensive multi-audience documentation",
    "Clear technical communication with effective analogies",
    "Strong archival and version control practices"
  ],

  "key_weaknesses": [
    "Impact metrics lack methodology documentation",
    "Self-reported evidence without independent verification",
    "No systematic testing documentation",
    "Cross-disciplinary claims exceed evidence breadth"
  ]
}
