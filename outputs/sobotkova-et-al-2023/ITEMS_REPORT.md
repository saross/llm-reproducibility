====================================================================================================
HUMAN-READABLE EXTRACTION REPORT
Sobotkova et al. 2023: Crowdsourced Map Digitisation Case Study
====================================================================================================


====================================================================================================
CLAIMS (78 items)
====================================================================================================

[C001] Crowdsourcing approach produced large, high-quality geospatial dataset
  Type: methodological_argument | Role: core
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Here we present a customisation of the Field Acquired Information Management Systems (FAIMS) Mobile platform tailored to offer a streamlined, collabor..."
  Evidence: E001, E002, E004

[C002] FAIMS Mobile customisation enabled effective crowdsourcing with minimal training
  Type: methodological_argument | Role: intermediate
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Deployed in Bulgaria as an ancillary activity during 2017–2018 archaeological fieldwork, FAIMS Mobile was used to digitise 10,827 mound features from ..."
  Evidence: E001, E002, E005

[C003] Crowdsourcing approach is most efficient for digitisation projects of 10,000-60,000 features
  Type: interpretation | Role: core
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "A conservative estimate based on our work suggests our crowdsourcing approach is most efficient for digitisation projects of 10,000–60,000 features, b..."
  Evidence: E001

[C004] Volunteer-based digitisation was resource-efficient compared to alternatives
  Type: interpretation | Role: intermediate
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "This digitisation required 241 person-hours (57 from staff; 184 from novice volunteers), with an error rate under 6%."
  Evidence: E002

[C005] Crowdsourcing approach produced high-quality, analysis-ready data
  Type: interpretation | Role: intermediate
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "The resulting dataset was consistent, well-documented, and ready for analysis with a few hours of processing."
  Evidence: E003, E004

[C006] Systems designed for field data collection can be profitably customised for participatory geospatial data systems accessible to novices
  Type: methodological_argument | Role: core
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Furthermore, it indicates that systems designed for field data collection, running on mobile devices, can be profitably customised to serve as partici..."
  Evidence: E004

[C007] Unlocking data from historical maps for landscape analysis is costly
  Type: background | Role: supporting
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Unlocking data from historical maps for landscape analysis is costly."
  Evidence: E001

[C008] Machine Learning requires extensive preparation and expertise
  Type: background | Role: supporting
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Automatic extraction using Machine Learning (ML) requires extensive preparation and expertise."

[C009] Crowdsourcing scales better than direct digitisation by experts but requires appropriate platform and technical skills
  Type: background | Role: supporting
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Crowdsourcing scales better than direct digitisation by experts, but requires an appropriate platform and the technical skills to adapt it."

[C010] Existing research provides little guidance on when investments in different digitisation approaches become worthwhile
  Type: gap | Role: supporting
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Existing research provides little guidance as to when investments in these approaches become worthwhile."

[C011] Approach complements Machine Learning by requiring less technical expertise, time, and resourcing
  Type: methodological_argument | Role: intermediate
  Location: Section: Introduction | Page: 1 | Para: 1
  Quote: "It complements Machine Learning (ML) and other automated approaches in that it requires less technical expertise, time, and resourcing to undertake."

[C012] Approach is suitable for small to mid-sized datasets that don't warrant ML investment
  Type: methodological_argument | Role: intermediate
  Location: Section: Introduction | Page: 1 | Para: 1
  Quote: "Such an approach is suitable for projects working with small to mid-sized data sources (100s–10,000s of features) that do not warrant the investment n..."

[C013] Burial mounds are archaeologically and culturally significant
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.2 Burial mounds in Bulgarian archaeology | Page: 2 | Para: 1
  Quote: "The mounds and their contents are important archaeologically as they attest to demographics, social complexity, international connections, and other i..."
  Evidence: E006, E007

[C014] Burial mounds are endangered and require systematic recording
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.2 Burial mounds in Bulgarian archaeology | Page: 2 | Para: 3
  Quote: "Burial mounds are an irreplaceable - but endangered - aspect of Bulgarian cultural heritage, making their systematic recording and registration an urg..."

[C015] Historical maps help heritage specialists analyse change over time
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 2 | Para: 2
  Quote: "Historical maps help heritage specialists analyse change over time in order to monitor and mitigate the impact of urban development, climate change, b..."

[C016] Value of historical maps has been underexploited due to manual digitisation challenges
  Type: gap | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 2 | Para: 3
  Quote: "The value of such maps has, however, been underexploited due to the entailed process of manual digitisation needed to transform their analogue informa..."

[C017] Manual desktop GIS digitisation is time-consuming and requires specialised skills
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 2 | Para: 4
  Quote: "Manually drawing and annotating shapes in historical maps using a desktop GIS is time-consuming and requires specialised skills (Can, Gerrits, and Kab..."

[C018] Desktop GIS scalability is limited by difficulty of training and supporting novice users
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 2 | Para: 4
  Quote: "Its principal limitations are difficulty of scaling the effort, particularly restricted time and availability of expert users to either undertake digi..."

[C019] ML has unmatched potential for large-scale digitisation but requires specific programming expertise
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 2
  Quote: "ML has unmatched potential for large-scale data digitisation, but it requires specific programming expertise, and familiarity with the capabilities an..."

[C020] Naive use of ML likely produces biased or unreliable results
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 2
  Quote: "Naive use of ML is likely to produce biased or otherwise unreliable results (Mehrabi et al., 2021; Schwemmer et al., 2020; Besse et al., 2018; Fuchs, ..."

[C021] ML expertise is difficult to attract to smaller HASS projects
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 2
  Quote: "This technical expertise is in high demand, and may be difficult to attract to the smaller humanities and social sciences (HASS) projects that underta..."

[C022] ML requires manual creation of training data and quality assurance
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 2
  Quote: "Training an algorithm, moreover, requires manual creation and preparation of training data and manual quality assurance (Bennett et al., 2014; Can & K..."

[C023] Crowdsourcing can expand scope of map digitisation
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 3
  Quote: "Crowdsourcing can expand the scope of map digitisation."

[C024] Volunteers lack the skills necessary to use GIS software
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.4 Sociotechnical barriers to collaborative map digitisation | Page: 3 | Para: 2
  Quote: "Volunteers often lack the skills necessary to use GIS software (Elwood, 2008b; Jones & Weber, 2012; Owen et al., 2009)."

[C025] Digital divide can be bridged through expert training and guidance but approach scales poorly
  Type: background | Role: supporting
  Location: Section: Introduction | Subsection: 1.4 Sociotechnical barriers to collaborative map digitisation | Page: 3 | Para: 2
  Quote: "This 'digital divide' can be bridged in part through more expert training and guidance of novice users (Owen et al., 2009, p. 24). Such an approach sc..."

[C026] Crowdsourcing offers advantages compared to alternative approaches under many map digitisation scenarios
  Type: methodological_argument | Role: core
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 4
  Quote: "This paper argues that crowdsourcing offers advantages compared to alternative approaches under many, if not most, map digitisation scenarios."

[C027] Crowdsourcing requires more upfront investment than desktop GIS but scales better
  Type: methodological_argument | Role: intermediate
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 4
  Quote: "Crowdsourcing requires more upfront investment in system setup than using available GIS specialists or training and supervising volunteers using deskt..."

[C028] Crowdsourcing requires less specialised expertise and time than ML
  Type: methodological_argument | Role: intermediate
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 4
  Quote: "Compared to ML, it requires less specialised and hard-to-come-by expertise, requires less time for initial setup, and produces high-quality datasets w..."
  Evidence: E009, E010

[C029] Soviet topographic maps contained high-density, moderately obtrusive mound symbols suitable for digitisation
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.1 Archaeological features in Soviet topographic maps | Page: 4 | Para: 1
  Quote: "Such symbols occurred at a high density, averaging about 200 per tile (0.5 per sq km), with counts per tile ranging from about 50 to 400."
  Evidence: E011, E012, E013, E014

[C030] Field school students were novices in archaeology, cartography, and digital methods
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 2
  Quote: "Most had no training in archaeology, cartography, or digital methods (unlike Pod˝ or, ¨ 2015 or Can et al., 2021)."
  Evidence: E015, E016

[C031] 2010 desktop GIS digitisation attempt was unsuccessful due to volunteer attrition and staff demands
  Type: background | Role: supporting
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Quote: "In the end, volunteer attrition combined with demands on staff time during the height of fieldwork rendered this approach unsuccessful."
  Evidence: E017, E018

[C032] Desktop GIS approach was unsuccessful due to difficulty training novice volunteers
  Type: background | Role: supporting
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Quote: "Our experience was much like that of other projects: novice volunteers found learning to configure and navigate desktop GIS challenging; many quit and..."
  Evidence: E017, E018

[C033] Streamlined mobile approach empowered volunteers to digitise independently with minimal training
  Type: methodological_argument | Role: intermediate
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Quote: "Our approach sought to help novice users begin digitising quickly and then work productively for the duration of each field season with minimal suppor..."
  Evidence: E019, E020

[C034] Simple UI allowed students to begin digitising after only minutes of training
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Quote: "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only min..."
  Evidence: E020, E027

[C035] Offline capability was essential for field-based digitisation in rural Bulgaria
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 3
  Quote: "Reliable internet connectivity could not be guaranteed under these circumstances; a system that tolerated degraded network connectivity was required."
  Evidence: E021, E022

[C036] Mobile devices were more available than computers for field school participants
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 5 | Para: 3
  Quote: "This choice also reduced competition for the limited number of computers, ESRI licences, and desk space available in the field, plus it allowed studen..."
  Evidence: E023

[C037] Customisation and setup required modest upfront investment of staff time
  Type: methodological_argument | Role: intermediate
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 2
  Quote: "Across both seasons, customisation, setup, and supervision took about 51 h, including 36 h from the programmer and 15 from project staff."
  Evidence: E024, E025, E026, E028, E029 ...

[C038] In-field staff time demands were minimal
  Type: methodological_argument | Role: intermediate
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 2
  Quote: "Of this time, initial customisation and setup time before fieldwork was 44 h, while the time required during fieldwork to prepare and distribute maps,..."
  Evidence: E027, E031

[C039] Workflow moved technical activities to specialist phases while simplifying volunteer tasks
  Type: methodological_argument | Role: intermediate
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 1
  Quote: "This approach moved activities requiring technical expertise to phases where specialists could contribute, while simplifying the tasks assigned to stu..."
  Evidence: E032, E037

[C040] FAIMS Mobile automated necessary tasks to make work easier for staff and participants
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 2
  Quote: "To support this workflow and make work easier for both project staff and participants, FAIMS Mobile automated a number of tasks and provided necessary..."
  Evidence: E033

[C041] Digitisation interface was streamlined as much as possible
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 2
  Quote: "The digitisation interface itself was as streamlined as possible (see Figs. 4 and 5)."
  Evidence: E034, E035, E036

[C042] Volunteers were insulated from technical friction of setup and data management
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "Since project staff set up the infrastructure and pre-processed and loaded the required maps, volunteers were insulated from the friction of setup, la..."
  Evidence: E037, E038

[C043] Digitisation and metadata creation required no GIS or computing skills
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "Digitisation and metadata creation required no GIS or computing skills."
  Evidence: E039, E040

[C044] Only few important controls were present in interface
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "Only a few important controls, including layer management, map navigation, record search and retrieval, and shape and attribute creation and editing, ..."
  Evidence: E041

[C045] Users could focus on digitisation without being distracted by technology
  Type: methodological_argument | Role: intermediate
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "As a result, users required almost no training and could focus on the act of digitisation without being distracted by the technology used to accomplis..."
  Evidence: E042

[C046] Exported data was FAIR-compliant
  Type: methodological_argument | Role: intermediate
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 2
  Quote: "This data adhered to key elements of the FAIR data principles, especially the production of 'rich' and 'plural' metadata at the time of data creation ..."
  Evidence: E043, E044

[C047] Project systematically evaluated digital fieldwork approaches
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 1
  Quote: "At that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a research progra..."
  Evidence: E046, E047, E049

[C048] Early success prompted systematic evaluation
  Type: interpretation | Role: supporting
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 1
  Quote: "The success of this approach became apparent early in the 2017 field season. At that point, we decided to catalogue inputs (time invested by staff and..."
  Evidence: E046, E047

[C049] Multiple data sources used to comprehensively track time investment and quality
  Type: methodological_argument | Role: supporting
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Quote: "Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project s..."
  Evidence: E048, E050, E051

[C050] Volunteer digitisation produced large volume of high-quality geospatial data
  Type: interpretation | Role: intermediate
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 4
  Quote: "In total, 10,827 point features, mostly burial and settlement mounds, were recorded in 189.4 student-hours (63 s per record)."
  Evidence: E052, E053, E054, E055, E056 ...

[C051] Concentrated digitisation was more productive than intermittent work
  Type: interpretation | Role: supporting
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 4
  Quote: "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets uti..."
  Evidence: E052, E053, E061, E063

[C052] System flexibility enabled opportunistic digitisation during spare time
  Type: methodological_argument | Role: supporting
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 3
  Quote: "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation."
  Evidence: E055, E057, E061

[C053] Desktop GIS placed high cognitive load on novice users, causing volunteer attrition
  Type: interpretation | Role: supporting
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 2
  Quote: "These problems reflect the high cognitive load desktop GIS places on novice users."
  Evidence: E065, E066, E067, E068, E069 ...

[C054] Mobile customisation met usability requirements and enabled productive volunteer work
  Type: methodological_argument | Role: intermediate
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 3
  Quote: "By contrast, our customised application met fundamental usability requirements (e.g., Nielsen, 2012), both due to careful design of the customisation ..."
  Evidence: E071, E072, E073, E074, E075 ...

[C055] Performance degradation was mitigated through export and restart workflow
  Type: methodological_argument | Role: supporting
  Location: Section: Results | Subsection: 3.4 Application performance | Page: 7 | Para: 2
  Quote: "Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application."
  Evidence: E077, E078, E079, E080, E085

[C056] Recoverable data omissions were low and mostly correctable
  Type: interpretation | Role: supporting
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "Recoverable data omissions across both years totaled 223 (2.06% of records), including 205 spatial and 18 attribute omissions."
  Evidence: E081, E082, E083, E084, E085 ...

[C057] Validation improvements in 2018 dramatically reduced omissions
  Type: interpretation | Role: supporting
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "Before the 2018 season, we added validation addressing this problem, resulting in only 13 spatial errors and one attribute omission (0.52%)."
  Evidence: E086, E087, E088

[C058] Overall digitisation accuracy was high (>94%) despite some errors
  Type: interpretation | Role: intermediate
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "Unlike some volunteer digitisation projects, overall accuracy was high, over 94% for processed maps."
  Evidence: E090, E091, E092, E093, E094 ...

[C059] Error patterns were predictable and easy to identify for correction
  Type: interpretation | Role: supporting
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 2
  Quote: "Moreover, the pattern of errors - mostly false negatives and double-marked features, mostly from contiguous map sections - made them relatively easy t..."
  Evidence: E094, E095, E096, E097, E101 ...

[C060] Best digitisers were both fast and accurate
  Type: interpretation | Role: supporting
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 1
  Quote: "Note that the two fastest digitisers (Students A and B; 44 and 45 s per feature respectively) also had the lowest error rates (1.3 and 2.9%), while th..."
  Evidence: E098, E099, E100, E101, E102

[C061] Simple quality control expedients would eliminate most errors with less effort than expert digitisation
  Type: methodological_argument | Role: intermediate
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 2
  Quote: "Simple expedients, such as assigning multiple students to digitise the same map tiles independently or assigning one student to review work by another..."
  Evidence: E104, E105, E106

[C062] Crowdsourcing system has payoff threshold of 3,420-4,275 features versus direct staff digitisation
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 2
  Quote: "At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420–..."
  Evidence: E107, E108, E110, E138

[C063] Crowdsourcing system has payoff threshold of 7,410-10,260 features versus volunteers using desktop GIS
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 3
  Quote: "Had specialist project staff instead trained and supervised volunteers to use desktop GIS for digitisation, based on our 2010 digitisation rate of 130..."
  Evidence: E109, E110, E139

[C064] Crowdsourcing approach provides outsourcing advantage with only 21h internal staff time versus 57h total
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 5
  Quote: "First, customisation of systems like FAIMS Mobile can be outsourced more easily than other project activities. Only 21 of the 57 h needed to support t..."
  Evidence: E110, E111, E112, E113

[C065] Staff time during field season was scarce and valuable, making in-field efficiency critical
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 2
  Quote: "Second, given competing responsibilities, staff time during the field season was scarce and valuable. We could afford to invest in customisation and s..."
  Evidence: E114, E115, E140

[C066] Marginal cost for each additional feature digitised is low (4.3 seconds of staff support)
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 3
  Quote: "Third, the marginal cost for each additional feature digitised is low. This figure includes in-field support and quality assurance (13 h), and transla..."
  Evidence: E116, E117

[C067] Scalability of crowdsourcing approach makes it more attractive as project expands
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 4
  Quote: "The scalability of our crowdsourcing approach makes it more attractive if a project may expand over time to include more volunteers, more redeployment..."
  Evidence: E116, E117, E118, E119

[C068] Qualitative factors argue for mobile crowdsourcing approach over desktop GIS
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 5
  Quote: "Finally, qualitative factors also argue for implementing a crowdsourcing approach using a mobile application."
  Evidence: E120, E121, E122

[C069] Crowdsourcing approach most suitable for datasets numbering 10,000-60,000 records
  Type: interpretation | Role: primary
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 4
  Quote: "To summarise in round numbers, a crowdsourcing approach like ours is most suitable for datasets numbering perhaps 10,000–60,000 records, assuming simi..."
  Evidence: E107, E110, E112, E114, E127 ...

[C070] Below 10,000 records, desktop GIS approaches should be considered
  Type: interpretation | Role: primary
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 4
  Quote: "Below 10,000 records, approaches using desktop GIS should be considered."
  Evidence: E107, E108, E109, E138, E139

[C071] Above 60,000 records, machine learning approaches should be contemplated if expertise available
  Type: interpretation | Role: primary
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 4
  Quote: "Above 60,000 records, ML approaches should be contemplated, but only if a project has access to the requisite expertise."
  Evidence: E123, E124, E125, E126, E127 ...

[C072] Machine learning and crowdsourcing approaches are complementary, not exclusive
  Type: interpretation | Role: primary
  Location: Section: Discussion | Subsection: 4.2 Combining crowdsourcing and ML approaches | Page: 10 | Para: 1
  Quote: "Finally, since training a model requires a manually produced dataset and a degree of manual error-checking, a combination of ML and crowdsourcing appr..."
  Evidence: E123, E129, E130, E131, E142

[C073] Typical HASS project can deploy crowdsourcing system but may struggle with machine learning
  Type: interpretation | Role: primary
  Location: Section: Discussion | Subsection: 4.3 Overall feasibility | Page: 10 | Para: 1
  Quote: "Today, a typical project in history or archaeology - often small, under-resourced, and pursuing several research activities - may not be able to dedic..."
  Evidence: E132, E133, E134

[C074] Technical barriers to deploying mobile GIS customisation systems are declining
  Type: interpretation | Role: intermediate
  Location: Section: Discussion | Subsection: 4.3 Overall feasibility | Page: 10 | Para: 2
  Quote: "Many of these systems attempt to make customisation as easy as possible, a goal at the heart of recent FAIMS redevelopment (ARDC, 2022); in future the..."
  Evidence: E134, E135

[C075] Crowdsourced map digitisation using mobile GIS proved unexpectedly successful
  Type: interpretation | Role: primary
  Location: Section: Discussion | Page: 9 | Para: 1
  Quote: "Our crowdsourced digitisation effort involving novice volunteers using an adapted mobile application for data capture proved unexpectedly successful."
  Evidence: E136, E137

[C076] Approach is readily transferable to other mobile GIS systems and map corpora
  Type: interpretation | Role: primary
  Location: Section: Conclusion | Page: 11 | Para: 4
  Quote: "This approach is readily transferable to other mobile GIS systems and map corpora"
  Evidence: E136

[C077] More projects need to track and publish time/error data for map digitisation
  Type: gap | Role: secondary
  Location: Section: Conclusion | Page: 11 | Para: 4
  Quote: "More projects - whether they use manual or automated approaches - need to track and publish the expert and volunteer time required for setup, training..."

[C078] Authors plan to use TRAP dataset to train ML model for systematic comparison with crowdsourcing
  Type: background | Role: secondary
  Location: Section: Conclusion | Page: 11 | Para: 4
  Quote: "We next plan to take our dataset and use it to train and error-check a ML model, to more systematically compare the results of crowdsourcing versus ma..."


====================================================================================================
EVIDENCE (107 items)
====================================================================================================

[E001] FAIMS Mobile was used to digitise 10,827 mound features from Soviet military topographic maps
  Type: observation
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "FAIMS Mobile was used to digitise 10,827 mound features from Soviet military topographic maps."

[E002] Digitisation required 241 person-hours: 57 from staff and 184 from novice volunteers
  Type: measurement
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "This digitisation required 241 person-hours (57 from staff; 184 from novice volunteers), with an error rate under 6%."

[E003] Error rate under 6%
  Type: measurement
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "This digitisation required 241 person-hours (57 from staff; 184 from novice volunteers), with an error rate under 6%."

[E004] Dataset was consistent, well-documented, and ready for analysis with a few hours of processing
  Type: observation
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "The resulting dataset was consistent, well-documented, and ready for analysis with a few hours of processing."

[E005] Deployment occurred during 2017-2018 archaeological fieldwork in Bulgaria
  Type: observation
  Location: Section: Abstract | Page: 1 | Para: 1
  Quote: "Deployed in Bulgaria as an ancillary activity during 2017–2018 archaeological fieldwork, FAIMS Mobile was used to digitise 10,827 mound features from ..."

[E006] An estimated 50,000 burial mounds were built in Bulgarian lands from the Early Bronze Age through the Middle Ages
  Type: measurement
  Location: Section: Introduction | Subsection: 1.2 Burial mounds in Bulgarian archaeology | Page: 2 | Para: 1
  Quote: "An estimated 50,000 burial mounds were built in Bulgarian lands from the Early Bronze Age through the Middle Ages (Shkorpil & Shkorpil, 1989, p. 20; K..."

[E007] Mounds range in size from 10 to 50 m in diameter and 0.5–20 m in height
  Type: measurement
  Location: Section: Introduction | Subsection: 1.2 Burial mounds in Bulgarian archaeology | Page: 2 | Para: 1
  Quote: "They were constructed of earth and rubble, and range in size from 10 to 50 m in diameter and 0.5–20 m in height (see Fig. 1)."

[E008] Between 2008 and 2016, TRAP catalogued 773 mounds in Kazanlak Valley and 431 mounds in Yambol region
  Type: measurement
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 3
  Quote: "Between 2008 and 2016, TRAP catalogued some 773 mounds in the Kazanlak Valley and 431 mounds in the Yambol region using pedestrian surface survey supp..."

[E009] Desktop GIS approach in 2010 produced dataset of 915 features
  Type: measurement
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 2
  Quote: "Although we did not maintain detailed volunteer time-on-task records, we know this effort produced a dataset of 915 features and required about 5–7 h ..."

[E010] Desktop GIS approach in 2010 required 5-7 hours of staff training, support, and error-checking
  Type: measurement
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 2
  Quote: "Although we did not maintain detailed volunteer time-on-task records, we know this effort produced a dataset of 915 features and required about 5–7 h ..."

[E011] Soviet topographic maps available as georeferenced GeoTIFFs at 1:50,000 scale, dating to 1980s, each covering ca 400 sq km, containing symbols representing burial/settlement mounds at high density (averaging ~200 per tile, 0.5 per sq km)
  Type: observation
  Location: Section: Approach | Subsection: 2.1 Archaeological features in Soviet topographic maps | Page: 4 | Para: 1
  Quote: "The goal of the work was to extract archaeological features from 1:50,000 scale Soviet military topographic maps dating to the 1980s. Available as geo..."

[E015] Students came from a range of academic backgrounds in Arts and Humanities
  Type: observation
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 2
  Quote: "Our students came from a range of academic backgrounds in Arts and Humanities."

[E016] Most students had no training in archaeology, cartography, or digital methods
  Type: observation
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 2
  Quote: "Most had no training in archaeology, cartography, or digital methods (unlike Pod˝ or, ¨ 2015 or Can et al., 2021)."

[E017] In 2010, novice volunteers found learning desktop GIS challenging; many quit and those who continued required ongoing support
  Type: observation
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Quote: "Our experience was much like that of other projects: novice volunteers found learning to configure and navigate desktop GIS challenging; many quit and..."

[E018] In 2010, volunteer attrition combined with demands on staff time rendered desktop GIS approach unsuccessful
  Type: observation
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Quote: "In the end, volunteer attrition combined with demands on staff time during the height of fieldwork rendered this approach unsuccessful."

[E019] Mobile application approach stripped GIS functionality to essentials: layer selection, shape digitisation, and annotation
  Type: observation
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Quote: "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validatio..."

[E020] Simple and intuitive UI allowed students to begin digitising after only minutes of training
  Type: observation
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Quote: "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only min..."

[E021] FAIMS Mobile works offline
  Type: observation
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 3
  Quote: "First, FAIMS Mobile worked offline."

[E022] Digitisation took place at field bases in rural Bulgaria where reliable internet connectivity could not be guaranteed
  Type: observation
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 3
  Quote: "Our digitisation took place alongside fieldwork, at field bases in rural Bulgaria. Reliable internet connectivity could not be guaranteed under these ..."

[E023] Only two of 12 students brought computers, and none brought mice, but all had mobile devices
  Type: measurement
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 5 | Para: 3
  Quote: "This choice also reduced competition for the limited number of computers, ESRI licences, and desk space available in the field, plus it allowed studen..."

[E024] For 2017 season, creating Map Digitisation customisation required 35h from student programmer plus 4h from staff; in-field setup required 3h from staff; map preparation required 1.5h; file compression/transfer 2.5h; training/supervision 0.5h total
  Type: measurement
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 1
  Quote: "For the first season of use (2017), creating the Map Digitisation customisation of FAIMS Mobile required 35 h from an undergraduate student programmer..."

[E027] Training and supervision of students took no more than half an hour of staff time across entire 2017 season
  Type: measurement
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 1
  Quote: "Training and supervision of students took no more than half an hour of staff time across the entire season."

[E031] In-field time during fieldwork to prepare maps and supervise participants was 7 h
  Type: measurement
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 2
  Quote: "Of this time, initial customisation and setup time before fieldwork was 44 h, while the time required during fieldwork to prepare and distribute maps,..."

[E032] FAIMS Mobile implementation included 7 stages: data modeling, customisation, SRS definition, shape drawing, attribute transcription, data export, accuracy checking
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 1
  Quote: "The stages of FAIMS Mobile implementation (Fig. 3) included: (1) project staff modelled the data and workflow to ensure that the final dataset met res..."

[E033] FAIMS Mobile automated spatial reference system, map rendering, layer management, shape topology, vocabularies, metadata, history, validation, data merging, and export
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 2
  Quote: "It applied the spatial reference system, rendered maps in the workspace, provided layer management (including a data entry layer), enforced shape topo..."

[E034] Digitisation interface streamlined with map view for geospatial data interactions and form view for attribute creation/editing; volunteers could toggle between views, adjust layer focus/visibility, pan, zoom, and search/retrieve/inspect/edit existing records
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 4
  Quote: "The digitisation interface itself was as streamlined as possible (see Figs. 4 and 5). Volunteers could toggle between a map view for geospatial data i..."

[E037] Staff set up infrastructure and preprocessed and loaded maps
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "Since project staff set up the infrastructure and pre-processed and loaded the required maps, volunteers were insulated from the friction of setup, la..."

[E038] GIS features not needed for digitisation were hidden or eliminated
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "GIS features not needed for digitisation were hidden or eliminated."

[E039] Digitisation and metadata creation required no GIS or computing skills
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "Digitisation and metadata creation required no GIS or computing skills."

[E040] Students capable of basic tasks (selecting files, panning, zooming, dropping points, filling forms) could create data
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "Students capable of selecting files from a list, panning and zooming a map, dropping a point, and filling out a form were able to create data."

[E041] Only few important controls were present: layer management, navigation, search, shape and attribute editing
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "Only a few important controls, including layer management, map navigation, record search and retrieval, and shape and attribute creation and editing, ..."

[E042] Users required almost no training and could focus on digitisation without being distracted by technology
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Quote: "As a result, users required almost no training and could focus on the act of digitisation without being distracted by the technology used to accomplis..."

[E043] Exported data was consistent, complete, ready for analysis with minimal cleaning
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 2
  Quote: "Exported data was consistent and complete, ready for analysis with minimal cleaning."

[E044] Data adhered to FAIR principles F2, R1.1-R1.3 through rich and plural metadata at time of creation
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 2
  Quote: "This data adhered to key elements of the FAIR data principles, especially the production of 'rich' and 'plural' metadata at the time of data creation ..."

[E045] Code defining customisation available on GitHub with description and user guide
  Type: observation
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 3
  Quote: "The code defining this customisation, along with a description and user guide, can be found on GitHub (https://github.com/FAIMS/map-digitisation/relea..."

[E046] Success of approach became apparent early in 2017 field season
  Type: observation
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 1
  Quote: "The success of this approach became apparent early in the 2017 field season."

[E047] Decision made to catalogue inputs versus outputs as part of research program to evaluate digital fieldwork approaches
  Type: observation
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 1
  Quote: "At that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a research progra..."

[E048] Time data collated from programmer timesheets, student record creation timestamps, and staff journals logging time-on-task; feature count from digitisation output
  Type: observation
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Quote: "To measure inputs, we collated the amount of time spent by various participants in the process, including the student programmer who instantiated the ..."

[E049] Number of features digitised taken as the output measure
  Type: observation
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Quote: "We took the number of features digitised as the output."

[E052] In 2017, system used for 125.8 person-hours concentrated across five rainy days
  Type: measurement
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 2
  Quote: "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days, during which time 8,343 features were digitised from 42 So..."

[E053] In 2017, 8,343 features were digitised from 42 Soviet topographic maps covering ca 17,000 sq km
  Type: measurement
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 2
  Quote: "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days, during which time 8,343 features were digitised from 42 So..."

[E054] In 2017, average time to record a point feature was 54 s based on device timestamps
  Type: measurement
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 2
  Quote: "The average time to record a point feature was 54 s, based on start and end times of feature creation as recorded by the devices (representing work ti..."

[E055] In 2018, system used for 63.6 person-hours with more sporadic use
  Type: measurement
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 3
  Quote: "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation. The system was used for 63.6 pers..."

[E056] In 2018, 2,484 features recorded from 16 maps covering ca 6,500 sq km
  Type: measurement
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 3
  Quote: "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation. The system was used for 63.6 pers..."

[E057] In 2018, average digitisation rate was one record every 92 s
  Type: measurement
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 3
  Quote: "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation. The system was used for 63.6 pers..."

[E058] In total, 10,827 point features (mostly burial and settlement mounds) recorded in 189.4 student-hours from 58 map tiles representing about 23,500 sq km
  Type: measurement
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 4
  Quote: "In total, 10,827 point features, mostly burial and settlement mounds, were recorded in 189.4 student-hours (63 s per record). Fifty-eight map tiles re..."

[E061] Concentrated 2017 digitisation was more productive than intermittent 2018 work
  Type: observation
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 4
  Quote: "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets uti..."

[E063] Work utilized time that might otherwise have been lost (e.g., to inclement weather)
  Type: observation
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 4
  Quote: "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets uti..."

[E064] Work required little supervision by project staff
  Type: observation
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 4
  Quote: "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets uti..."

[E065] 2010 desktop GIS attempt produced 915 features but required 5-7 hours of staff training/support over three weeks; high-touch training and volunteer dislike prevented scaling; high cognitive load from desktop GIS on novice users led to poor outcomes
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 1
  Quote: "TRAP had attempted an unsatisfactory digitisation effort in 2010 by students using ArcGIS. Although we did not maintain detailed volunteer time-on-tas..."

[E068] One persistent student accounted for almost all digitised features in 2010
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 2
  Quote: "Indeed, one persistent student accounted for almost all the digitised features; without his perseverance, the digitisation effort would have failed en..."

[E069] Without one persistent student, 2010 desktop GIS digitisation effort would have failed entirely
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 2
  Quote: "Indeed, one persistent student accounted for almost all the digitised features; without his perseverance, the digitisation effort would have failed en..."

[E070] Desktop GIS problems reflect high cognitive load placed on novice users
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 2
  Quote: "These problems reflect the high cognitive load desktop GIS places on novice users."

[E071] Customised application met fundamental usability requirements
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 3
  Quote: "By contrast, our customised application met fundamental usability requirements (e.g., Nielsen, 2012), both due to careful design of the customisation ..."

[E072] UI/UX approach from kinetic fieldwork translated well to map digitisation
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 3
  Quote: "It also benefited from the UI/UX approach employed for kinetic fieldwork (e.g., Pascoe et al., 2000). The principle that the technology had to conform..."

[E073] Result was simple, familiar mobile interface that let novices begin work with little training
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 3
  Quote: "The result was a simple, familiar mobile application interface that let novices begin work with little training and helped them resume work after any ..."

[E074] Use of controlled vocabularies, automation, and validation reduced errors
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 3
  Quote: "Use of controlled vocabularies, automation, and validation reduced errors."

[E075] Low volunteer attrition indicated satisfaction with experience
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 3
  Quote: "Low volunteer attrition indicated satisfaction with the experience."

[E076] Volunteers could attain high digitisation rate quickly and maintain it
  Type: observation
  Location: Section: Results | Subsection: 3.3 Digitisation comparison with desktop GIS | Page: 7 | Para: 3
  Quote: "Volunteers could attain a high rate of digitisation quickly and maintain it, although further design refinement could improve the ability of more expe..."

[E077] Performance degraded once approximately 2,500-3,000 records created; GPS coordinate extraction slowed from 3-5s to 30s; mitigated by exporting data and instantiating new empty application version
  Type: measurement
  Location: Section: Results | Subsection: 3.4 Application performance | Page: 7 | Para: 1
  Quote: "Automated testing of other customisations suggested that performance would degrade once approximately 3,000–6,000 records had been created. In use, au..."

[E081] Recoverable data omissions across both years totaled 223 (2.06% of records)
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "Recoverable data omissions across both years totaled 223 (2.06% of records), including 205 spatial and 18 attribute omissions."

[E082] Recoverable data omissions totaled 223 (2.06% of 10,827 records): 205 spatial omissions (empty lat/long fields due to users moving too quickly through forms) and 18 attribute omissions (missing map symbol specification); geodatabase preserved geometries allowing recovery
  Type: measurement
  Location: Section: Results | Subsection: 3.5.1 Recoverable data omissions and incomplete records | Page: 7 | Para: 1
  Quote: "Recoverable data omissions across both years totaled 223 (2.06% of records), including 205 spatial and 18 attribute omissions. Most occurred in 2017 w..."

[E085] Spatial data omissions resulted from failure to populate lat/long from geodatabase due to users moving through forms too quickly
  Type: observation
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "Spatial data omissions resulted from a failure of the software to populate the latitude and longitude fields from the application's SpatiaLite geodata..."

[E086] Before 2018 season, validation added addressing lat/long population problem, resulting in only 13 spatial errors and 1 attribute omission (0.52% vs 2.3% in 2017); fixable omissions delayed visualization/analysis but were recovered
  Type: measurement
  Location: Section: Results | Subsection: 3.5.1 Recoverable data omissions and incomplete records | Page: 7 | Para: 1
  Quote: "Before the 2018 season, we added validation addressing this problem, resulting in only 13 spatial errors and one attribute omission (0.52%). Since the..."

[E090] Overall accuracy was high, over 94% for processed maps
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "Unlike some volunteer digitisation projects, overall accuracy was high, over 94% for processed maps."

[E091] Participants failed to digitise some assigned maps, leaving noticeable gaps
  Type: observation
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "First, participants failed to digitise some assigned maps, leaving noticeable gaps (see Fig. 6)."

[E092] Map omission was obvious and could be corrected in later digitising session
  Type: observation
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 7 | Para: 1
  Quote: "This omission was obvious, and could be corrected in a later digitising session."

[E093] Review of four randomly selected maps (7% of total) found 49 errors from 834 true features (5.87% error rate)
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 1
  Quote: "Second, a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error ra..."

[E094] Of 49 total errors from 834 features (5.87% error rate): 42 false negatives (missed symbols), 6 double-marked (digitised twice), 1 classification error, 0 false positives; 35 of 42 false negatives from one student failing to digitise three contiguous map sections
  Type: measurement
  Location: Section: Results | Subsection: 3.5.2 Digitisation errors | Page: 8 | Para: 1
  Quote: "Second, a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error ra..."

[E098] Students' individual error rates ranged from 1.3% to 10.6%
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 1
  Quote: "Students' individual error rates ranged from 1.3% to 10.6%."

[E099] Two fastest digitisers (Students A and B, 44 and 45 s per feature) had lowest error rates (1.3% and 2.9%)
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 1
  Quote: "Note that the two fastest digitisers (Students A and B; 44 and 45 s per feature respectively) also had the lowest error rates (1.3 and 2.9%), while th..."

[E100] Two slowest digitisers (Students C and D, 61 and 73 s) had highest error rates (10.6% and 7.4%)
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 1
  Quote: "Note that the two fastest digitisers (Students A and B; 44 and 45 s per feature respectively) also had the lowest error rates (1.3 and 2.9%), while th..."

[E101] 35 of 49 false negatives resulted from Student C failing to digitise three contiguous map sections
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 1
  Quote: "Moreover, 35 of the 49 false negatives were the result of Student C failing to digitise three contiguous sections of an assigned map."

[E102] Student C's errors made 10.6% error rate an outlier; excluding Student C would cut cumulative error rate in half to 2.8%
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 1
  Quote: "These mistakes made his error rate of 10.6% an outlier; excluding Student C would have cut the cumulative error rate in half to 2.8%."

[E103] Overall error rate of 5.9% exceeded expectations
  Type: measurement
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 2
  Quote: "Nevertheless, the overall rate of 5.9% exceeded our expectations."

[E104] Error pattern (mostly false negatives and double-marked features from contiguous sections) made them easy to identify and correct
  Type: observation
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 2
  Quote: "Moreover, the pattern of errors - mostly false negatives and double-marked features, mostly from contiguous map sections - made them relatively easy t..."

[E105] Simple expedients (assigning multiple students to same tiles or peer review) would likely eliminate most errors
  Type: observation
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 2
  Quote: "Simple expedients, such as assigning multiple students to digitise the same map tiles independently or assigning one student to review work by another..."

[E106] Even using staff time, it was much faster to check volunteer work than digitise from scratch
  Type: observation
  Location: Section: Results | Subsection: 3.5 Data quality | Page: 8 | Para: 2
  Quote: "Even using staff time, it was much faster to check volunteer work than digitise from scratch."

[E107] Project staff with desktop GIS experience could digitise at sustained rate of 60-75 features per staff-hour
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 2
  Quote: "After brief workspace setup, project staff with desktop GIS experience could digitise at a sustained rate of 60–75 features per staff-hour."

[E108] 57 hours of staff time could produce 3,420-4,275 staff-digitised features at 60-75 features/hour
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 2
  Quote: "At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420–..."

[E109] Desktop GIS with volunteers: 130-180 features per staff-hour based on 2010 digitisation rate
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 3
  Quote: "Had specialist project staff instead trained and supervised volunteers to use desktop GIS for digitisation, based on our 2010 digitisation rate of 130..."

[E110] 57 hours of staff time using crowdsourcing system produced 10,827 features, approximately 190 features per staff-hour
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 4
  Quote: "By comparison, the 57 h of staff time required for our digitisation approach using a customisation of FAIMS Mobile produced 10,827 features, or about ..."

[E111] Only 21 of 57 staff hours came from project staff; other 36 hours from student programmer who could be outsourced
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 5
  Quote: "First, customisation of systems like FAIMS Mobile can be outsourced more easily than other project activities. Only 21 of the 57 h needed to support t..."

[E112] 21 internal staff hours represent digitisation rate of over 500 features per staff-hour
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 1
  Quote: "Those 21 internal staff hours represent a digitisation rate of over 500 features per staff-hour."

[E113] 21 hours would have yielded just 1,260-1,575 features if staff digitised directly, or 2,730-3,780 supervising desktop GIS
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 1
  Quote: "Twenty-one hours would have yielded just 1,260–1,575 features if staff had digitised them directly, or 2,730–3,780 had we supervised students using de..."

[E114] In-field support for volunteers was only 7 hours across two seasons, representing about 1,550 features per in-field staff-hour
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 2
  Quote: "Across two seasons, in-field support for volunteers was only 7 h, representing about 1,550 features per in-field staff-hour."

[E115] Seven hours in-field would only allow staff to directly digitise 420-525 features, or supervise digitisation of 910-1,260
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 2
  Quote: "Seven hours would only allow staff to directly digitise 420–525 features, or supervise the digitisation of 910-1,260."

[E116] Marginal cost for additional feature: 4.3 seconds of staff support per feature (from 13h support + QA)
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 3
  Quote: "Third, the marginal cost for each additional feature digitised is low. This figure includes in-field support and quality assurance (13 h), and transla..."

[E117] Preparing and distributing additional maps took only 6 minutes per map (6 hours for 58 maps)
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 3
  Quote: "Preparing and distributing additional maps took only 6 min per map (6 h for 58 maps)."

[E118] Adding another field season costs only one additional hour of setup time (based on 2018 redeployment)
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 3
  Quote: "Even adding another field season only costs one additional hour of setup time (based on our 2018 redeployment)."

[E119] In 2010 desktop GIS approach, demands on staff time never plateaued due to attrition and learning curve
  Type: observation
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 3
  Quote: "By comparison, in 2010, the demands on staff time related to volunteer support never plateaued, as attrition meant that we were constantly onboarding ..."

[E120] Desktop GIS approach caused continual stress/distraction from troubleshooting demands; volunteers perceived digitisation as burden (tethered to computer, tedious task), reducing morale and causing friction; mobile GIS switch nearly eliminated staff interventions and improved volunteer satisfaction
  Type: observation
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 5
  Quote: "First, the need for staff to be continually available to troubleshoot problems with desktop GIS, lest digitisation stall, provided a continual source ..."

[E123] Urban Occupations Project required 1,250 hours of manual digitisation to create training data for ML
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 2
  Quote: "The ERC-funded Urban Occupations Project (Can, Gerrits, and Kabadayi 2021), however, provides one benchmark for judging when pursuing a ML approach mi..."

[E124] Urban Occupations: ML expert spent seven days testing and fine tuning model after preprocessing and filtering
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 2
  Quote: "Using this input, and after additional preprocessing and filtering, an ML expert spent seven days testing and fine tuning the model."

[E125] Urban Occupations ML approach digitised approximately 300,000 km of roads
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 2
  Quote: "The output was impressive: some 300,000 km of roads were digitised."

[E126] ML approach required minimum 1,300 hours preparation time (1,250h digitisation + 7 days expert)
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 2
  Quote: "This example, which appears to have required a minimum of about 1,300 h of preparation time alone, suggests that ML approaches are worthwhile for larg..."

[E127] TRAP spent 241 hours total (44 staff + 184 volunteer + 7 support + 6 QA) producing 10,827 features = 44.9 features/person-hour
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 3
  Quote: "We spent 44 staff hours customising and deploying a streamlined geospatial system in FAIMS Mobile, 184 participant-hours digitising features, seven st..."

[E128] At TRAP rate (44.9 features/hour), 1,300 hours (ML prep time) would yield approximately 58,400 records
  Type: measurement
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 3
  Quote: "At that rate, the 1,300 h it took to deploy the ML approach taken by Can, Gerrits, and Kabadayi would yield about 58,400 records"

[E129] ML model training requires manually produced dataset and manual error-checking; datasets big enough for ML likely need training data big enough for crowdsourcing; crowdsourcing platform can be reused for ML quality assurance
  Type: observation
  Location: Section: Discussion | Subsection: 4.2 Combining crowdsourcing and ML approaches | Page: 10 | Para: 1
  Quote: "Finally, since training a model requires a manually produced dataset and a degree of manual error-checking, a combination of ML and crowdsourcing appr..."

[E132] Typical HASS project may lack personnel/infrastructure for ML but can deploy crowdsourcing; digital humanist at Software Carpentry skill level can customise platforms like FAIMS Mobile; entire class of customisable mobile GIS software exists (ArcGIS Field Maps, QField, Mergin Maps, GeoODK)
  Type: observation
  Location: Section: Discussion | Subsection: 4.3 Overall feasibility | Page: 10
  Quote: "Today, a typical project in history or archaeology - often small, under-resourced, and pursuing several research activities - may not be able to dedic..."

[E135] Many mobile GIS systems attempt to make customisation as easy as possible, goal of recent FAIMS redevelopment
  Type: observation
  Location: Section: Discussion | Subsection: 4.3 Overall feasibility | Page: 10 | Para: 2
  Quote: "Many of these systems attempt to make customisation as easy as possible, a goal at the heart of recent FAIMS redevelopment (ARDC, 2022); in future the..."

[E136] Total digitisation time: 57 staff-hours, 184 volunteer-hours, 241 total person-hours
  Type: measurement
  Location: Section: Conclusion | Page: 11 | Para: 2
  Quote: "The deployment of the Map Digitisation FAIMS Mobile customisation facilitated the rapid digitisation (57 staff-hours; 184 volunteer-hours; 241 total) ..."

[E137] Comprehensive, FAIR-compliant dataset ready for analysis with less than 2 hours of processing after collection
  Type: measurement
  Location: Section: Conclusion | Page: 11 | Para: 2
  Quote: "All collected data was available daily for review, and a comprehensive, FAIR-compliant dataset was ready for analysis with less than 2 h of processing..."

[E138] Payoff threshold approximately 4,500 features versus expert staff digitisation using desktop GIS
  Type: measurement
  Location: Section: Conclusion | Page: 11 | Para: 3
  Quote: "If staff time is the primary limiting resource, our approach becomes worthwhile for datasets no larger than about 4,500 features versus direct digitis..."

[E139] Payoff threshold approximately 10,000 features versus volunteer digitisation using desktop GIS
  Type: measurement
  Location: Section: Conclusion | Page: 11 | Para: 3
  Quote: "and no larger than about 10,000 features versus volunteer digitisation using desktop GIS."

[E140] Approach may pay off for fewer than 1,000 features if project staff time is at premium
  Type: measurement
  Location: Section: Conclusion | Page: 11 | Para: 3
  Quote: "It may pay off for fewer than 1,000 if project staff time is at a premium."

[E141] Crowdsourcing remains most efficient approach for datasets up to at least 60,000 features
  Type: measurement
  Location: Section: Conclusion | Page: 11 | Para: 3
  Quote: "It remains the most efficient approach for datasets up to at least 60,000 features, above which automated approaches like ML should be considered."


====================================================================================================
IMPLICIT ARGUMENTS (6 items)
====================================================================================================

[IA001] Novice volunteers can produce high-quality geospatial data if given appropriate tools
  Type: Type 2: Unstated Assumption
  Location: Section: Abstract | Page: 1 | Para: 1
  Trigger: "['volunteers with no prior GIS experience', 'with an error rate under 6%', 'The resulting dataset was consistent, well-documented']"
  Reasoning: The paper demonstrates that novice volunteers achieved low error rates and produced quality data, but doesn't explicitly state the underlying assumpti...

[IA002] Efficiency thresholds for digitisation approaches can be estimated from single-project data
  Type: Type 3: Bridging Claim
  Location: Section: Abstract | Page: 1 | Para: 1
  Trigger: "['A conservative estimate based on our work suggests our crowdsourcing approach is most efficient for digitisation projects of 10,000–60,000 features']"
  Reasoning: The paper makes efficiency recommendations for dataset sizes, but doesn't explicitly justify how findings from one project (10,827 features, Bulgarian...

[IA003] Error rates under 6% constitute 'high quality' for crowdsourced digitisation
  Type: Type 4: Disciplinary Assumption
  Location: Section: Abstract | Page: 1 | Para: 1
  Trigger: "['with an error rate under 6%', 'The resulting dataset was consistent, well-documented, and ready for analysis']"
  Reasoning: The paper presents 6% error rate alongside quality assertions, implying this rate is acceptable/good, but doesn't explicitly state what error threshol...

[IA004] If crowdsourcing scales better than desktop GIS approaches, then projects with volunteer attrition problems should prefer crowdsourcing
  Type: Type 1: Logical Implication
  Location: Section: Introduction | Subsection: 1.3 Extracting data from historical maps | Page: 3 | Para: 4
  Trigger: "['Crowdsourcing requires more upfront investment in system setup than using available GIS specialists or training and supervising volunteers using desktop GIS, but it scales better in the face of likely constraints related to expert staffing and volunteer attrition.']"
  Reasoning: The explicit claim states crowdsourcing scales better in face of volunteer attrition constraints. The logical implication (not stated) is that project...

[IA005] Simplified interfaces reduce cognitive load enough to overcome lack of GIS expertise
  Type: Type 2: Unstated Assumption
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Trigger: "['it stripped GIS functionality to its essentials, focusing on three tasks', 'simple and intuitive UI allowed students to begin digitising after only minutes of training', 'Most had no training in archaeology, cartography, or digital methods']"
  Reasoning: The paper shows that simplifying GIS to essentials enabled novices to work productively, but doesn't explicitly state the underlying UI/UX principle t...

[IA006] Automation and metadata capture during data creation ensures data quality and FAIRness
  Type: Type 2: Unstated Assumption
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 2
  Trigger: "['FAIMS Mobile automated a number of tasks', 'recorded creation time and author for each record, maintained a history of all changes to data', 'adhered to key elements of the FAIR data principles']"
  Reasoning: The paper describes extensive automation and metadata capture, then asserts FAIR compliance and data quality, but doesn't explicitly state the underly...


====================================================================================================
RESEARCH DESIGNS (15 items)
====================================================================================================

[RD001] Evaluate crowdsourcing approach for map digitization by measuring time inputs vs feature outputs
  Type: evaluation_study | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 1
  Purpose: Evaluate cost-effectiveness of crowdsourced map digitization using mobile GIS
  Objectives: 3 defined
  Enables Methods: M001, M002, M003
  Quote: "As such, at that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a resear..."

[RD002] Usability-focused design to minimize cognitive load and training requirements for novice volunteers
  Type: intervention_design | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Enables Methods: M004, M005, M006
  Quote: "Our approach sought to help novice users begin digitising quickly and then work productively for the duration of each field season with minimal suppor..."

[RD003] Comparative evaluation design: crowdsourcing vs desktop GIS vs machine learning
  Type: comparative_study | Status: explicit
  Location: Section: Discussion | Subsection: 4.1 Choosing an approach | Page: 9 | Para: 2
  Purpose: Compare payoff thresholds and tradeoffs between digitization approaches
  Objectives: 3 defined
  Enables Methods: M007, M008
  Quote: "Digitisation projects will likely choose between one of four principal approaches to digitising historical maps. 1. Have expert staff or specialists d..."

[RD004] Case study approach demonstrating unanticipated success of minimally resourced digitization for small-to-mid-sized datasets (100s-10,000s features), complementing ML for larger datasets
  Type: case_study | Status: explicit
  Location: Section: Introduction | Page: 1 | Para: 1
  Purpose: Document unexpected success of low-resource crowdsourcing approach and position it relative to ML alternatives
  Objectives: 3 defined
  Enables Methods: M007, M008, M009, M010
  Quote: "This article presents a case study of crowdsourced cultural heritage digitisation from historical maps... Such an approach is suitable for projects wo..."
  [CONSOLIDATED from: RD004, RD005]

[RD006] Secondary activity design: digitization as ancillary to primary pedestrian survey fieldwork
  Type: opportunistic_study | Status: explicit
  Location: Section: Introduction | Page: 1 | Para: 1
  Purpose: Leverage field school downtime for map digitization using repurposed tools
  Enables Methods: M004, M009
  Quote: "Digitisation was undertaken as a secondary activity on a landscape archaeology project focusing on pedestrian feature survey. Undergraduates in the as..."

[RD007] TRAP project: Long-term cultural development in environmental context combining multiple methodologies
  Type: interdisciplinary_study | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 1
  Purpose: Reconstruct ancient environment, map habitation evolution, explain human-environment interactions
  Objectives: 4 defined
  Enables Methods: M010, M011
  Quote: "It has explored long-term cultural development in its environmental context since 2008 (Ross et al., 2010, 2018; Sobotkova, 2013). Methodologically, i..."

[RD008] Three-activity research design for 2017-2018: mound registration, satellite monitoring, and map digitization with ground-truthing
  Type: multi_method_study | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Purpose: Record location, characteristics, and condition of burial mounds in Yambol region
  Objectives: 4 defined
  Enables Methods: M010, M011, M012
  Quote: "Three activities were undertaken: (1) visiting known burial mounds, registering their location and condition; (2) identifying changes in mound conditi..."

[RD009] Student involvement design: Involve field school undergraduates in authentic research through map digitization
  Type: participatory_research | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 1
  Purpose: Provide authentic research experience while accomplishing digitization goals
  Enables Methods: M015, M016
  Quote: "The task of digitising potentially thousands of mounds provided an opportunity to involve students in authentic research. Our students came from a ran..."

[RD010] Volunteer empowerment approach: Focus on implementing tools to enable independent volunteer work with minimal training and supervision
  Type: usability_focused_design | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Purpose: Enable novice volunteers to work independently with minimal training and support
  Objectives: 3 defined
  Enables Methods: M017, M018
  Quote: "In 2017, faced with a short field season and little time for student training, we focused on implementing tools that would empower volunteers to digit..."

[RD011] Platform selection design: Choose FAIMS Mobile for customization based on offline capability, functional requirements, workflow conformance, cost, and usability
  Type: technology_selection | Status: explicit
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4
  Purpose: Select appropriate platform for crowdsourced map digitization under field conditions
  Enables Methods: M019, M020
  Quote: "The decision to use mobile software, and FAIMS Mobile in particular, was based on several factors. First, FAIMS Mobile worked offline... Second, this ..."

[RD012] Division of labor design: Move technical expertise activities to specialist phases, simplify volunteer tasks to essential digitization
  Type: workflow_design | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 1
  Purpose: Optimize distribution of technical vs. simple tasks across project staff and volunteers
  Enables Methods: M021
  Quote: "This approach moved activities requiring technical expertise to phases where specialists could contribute, while simplifying the tasks assigned to stu..."

[RD013] System evaluation design: Catalogue inputs (staff and volunteer time) versus outputs (features digitized) to evaluate digital fieldwork approach
  Type: evaluation_study | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 1
  Purpose: Evaluate crowdsourcing approach efficiency as part of research program on digital fieldwork approaches
  Objectives: 3 defined
  Enables Methods: M022
  Quote: "The success of this approach became apparent early in the 2017 field season. At that point, we decided to catalogue inputs (time invested by staff and..."

[RD014] 2018 validation refinement: Address performance degradation problem discovered in 2017 season
  Type: iterative_design | Status: explicit
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 2
  Purpose: Improve data quality by addressing lat/long population failure discovered in 2017
  Objectives: 2 defined
  Enables Methods: M024
  Quote: "For the second season, adding additional validation to ensure population of latitude and longitude from GPS (see 'Recoverable data omissions and incom..."

[RD015] Four-approach decision framework for map digitization: desktop GIS by experts, desktop GIS by volunteers, crowdsourcing with collaborative system, or machine learning
  Type: comparative_framework | Status: explicit
  Location: Section: Discussion | Subsection: 4.1 Choosing an approach | Page: 9 | Para: 2
  Purpose: Provide decision framework for selecting digitization approach based on project constraints
  Objectives: 2 defined
  Enables Methods: M027
  Quote: "Digitisation projects will likely choose between one of four principal approaches to digitising historical maps. 1. Have expert staff or specialists d..."

[RD016] Payoff threshold analysis: Compare staff time investment thresholds for different digitization approaches
  Type: comparative_evaluation | Status: explicit
  Location: Section: Discussion | Subsection: 4.1 Choosing an approach | Page: 9 | Para: 3
  Purpose: Calculate dataset size thresholds where crowdsourcing becomes more efficient than alternatives
  Objectives: 2 defined
  Enables Methods: M028, M029
  Quote: "Note that in all following comparisons, we present our experience as a (perhaps idiosyncratic) example... This discussion, furthermore, focuses on our..."


====================================================================================================
METHODS (29 items)
====================================================================================================

[M001] Time measurement: collate time-on-task from programmer timesheets, student record timestamps, and staff journals
  Tier: data_collection | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Enabled by Designs: RD001
  Realized through Protocols: P001, P002, P003
  Quote: "To measure inputs, we collated the amount of time spent by various participants in the process, including the student programmer who instantiated the ..."

[M002] Output measurement: count features digitized from application records
  Tier: data_collection | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Enabled by Designs: RD001
  Realized through Protocols: P004
  Quote: "We took the number of features digitised as the output."

[M003] Quality assurance: random sampling of digitized maps with manual re-examination to characterize errors
  Tier: validation | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Enabled by Designs: RD001
  Realized through Protocols: P005
  Quote: "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors."

[M004] FAIMS Mobile customization for map digitization: definition files interpreted to generate customized Android application
  Tier: data_collection | Status: explicit
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 2
  Enabled by Designs: RD002
  Realized through Protocols: P006, P007, P008
  Quote: "FAIMS Mobile is a server-client platform that generates customised Android applications for data collection during offline field research. Customisati..."

[M005] Streamlined UI design: strip GIS to essentials (layer selection, shape digitization, annotation)
  Tier: intervention | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Enabled by Designs: RD002
  Realized through Protocols: P009, P010
  Quote: "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validatio..."

[M006] Automated metadata capture: system records creation time, author, change history for each record
  Tier: data_management | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 2
  Enabled by Designs: RD002
  Realized through Protocols: P011
  Quote: "FAIMS Mobile automated a number of tasks and provided necessary capabilities. It applied the spatial reference system, rendered maps in the workspace,..."

[M007] Payoff threshold calculation: compare staff-hours required vs features produced for each approach
  Tier: analysis | Status: explicit
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 3
  Enabled by Designs: RD003
  Realized through Protocols: P012
  Quote: "A minimum threshold for automation can be extrapolated from our 2017-18 fieldwork and the Urban Occupations Project."

[M008] Error characterization: categorize digitization errors by type (false positives, false negatives, double-marking, classification errors)
  Tier: analysis | Status: explicit
  Location: Section: Results | Subsection: 3.5.2 Digitisation errors | Page: 8 | Para: 1
  Enabled by Designs: RD001
  Realized through Protocols: P013
  Quote: "Second, a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error ra..."

[M009] Repurposing system from other project activities for map digitization
  Tier: adaptation | Status: explicit
  Location: Section: Introduction | Page: 1 | Para: 1
  Enabled by Designs: RD006
  Realized through Protocols: P014
  Quote: "Undergraduates in the associated field school digitised data from maps using a system repurposed from other project activities."

[M010] Digital field data collection workflows to produce FAIR and analysis-ready datasets
  Tier: data_management | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Enabled by Designs: RD007, RD008
  Realized through Protocols: P015
  Quote: "All three approaches involved digital field data collection workflows, improving research transparency and facilitating production of Findable, Access..."

[M011] Visiting known burial mounds to register location and condition
  Tier: data_collection | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Enabled by Designs: RD008
  Realized through Protocols: P016
  Quote: "(1) visiting known burial mounds, registering their location and condition"

[M012] Identifying changes in mound condition using satellite imagery
  Tier: monitoring | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Enabled by Designs: RD008
  Realized through Protocols: P017
  Quote: "(2) identifying changes in mound condition using satellite imagery"

[M013] Digitising mounds from Soviet military topographic maps followed by ground-truthing
  Tier: data_collection | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Enabled by Designs: RD008
  Realized through Protocols: P018, P019
  Quote: "(3) digitising mounds from over 20,000 sq km of Soviet military 1:50,000 topographic maps covering southeast Bulgaria, followed by ground-truthing (wh..."

[M014] Crowdsourcing map digitization using undergraduate field school participants
  Tier: data_collection | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Enabled by Designs: RD006, RD008
  Realized through Protocols: P020
  Quote: "This paper discusses the digitisation of mound symbols from maps using a crowdsourcing approach involving undergraduate students associated with the p..."

[M015] Leveraging field school downtime for auxiliary map digitization: concentrated work during adverse weather (rainy days) and when students remain at base
  Tier: opportunistic_data_collection | Status: explicit
  Location: Section: Approach | Subsection: 2.2 | Page: 4
  Enabled by Designs: RD006, RD009
  Realized through Protocols: P021, P038
  Quote: "Digitisation was undertaken as a secondary activity... In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days"
  [CONSOLIDATED from: M015, M025]

[M016] Stripping GIS functionality to essentials: layer selection, shape digitisation, annotation with validation and automation
  Tier: interface_simplification | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Enabled by Designs: RD010
  Realized through Protocols: P022
  Quote: "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validatio..."

[M017] Staff-controlled geospatial data preparation and management while volunteers focus on digitization
  Tier: division_of_labor | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Enabled by Designs: RD010, RD012
  Realized through Protocols: P023
  Quote: "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only min..."

[M018] Refinement approach: Iterate system design across field seasons based on experience
  Tier: iterative_development | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 3
  Enabled by Designs: RD010
  Realized through Protocols: P024
  Quote: "This approach was refined during the 2018 field season. The outcomes of both field seasons are discussed in this paper."

[M019] FAIMS Mobile platform customization via definition files for map digitization
  Tier: platform_adaptation | Status: explicit
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 2
  Enabled by Designs: RD011
  Realized through Protocols: P025, P026
  Quote: "Having decided to adopt a crowdsourced approach to produce VGI, we chose to customise FAIMS Mobile for map digitisation... Briefly, FAIMS Mobile is a ..."

[M020] Testing transferability of field data capture usability approaches to desk-based digitization
  Tier: usability_transfer | Status: explicit
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 2
  Enabled by Designs: RD011
  Realized through Protocols: P027
  Quote: "Third, it allowed us to test the idea that usability approaches from data capture during kinetic fieldwork were beneficially transferable to digitisat..."

[M021] Seven-stage implementation workflow dividing specialist and volunteer activities
  Tier: workflow_management | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 1
  Enabled by Designs: RD012
  Realized through Protocols: P028, P029, P030, P031, P032 ...
  Quote: "The stages of FAIMS Mobile implementation (Fig. 3) included: (1) project staff modelled the data and workflow to ensure that the final dataset met res..."

[M022] Multi-source time-on-task data collection combining programmer timesheets, device timestamps, and staff journals
  Tier: evaluation_data_collection | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Enabled by Designs: RD013
  Realized through Protocols: P035
  Quote: "To measure inputs, we collated the amount of time spent by various participants in the process, including the student programmer who instantiated the ..."

[M023] Random sampling for accuracy assessment of volunteer digitization work
  Tier: quality_assurance | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Enabled by Designs: RD013
  Realized through Protocols: P036
  Quote: "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors."

[M024] Application performance mitigation: Export data and instantiate fresh application when performance degrades
  Tier: performance_management | Status: explicit
  Location: Section: Results | Subsection: 3.4 Application performance | Page: 7 | Para: 2
  Enabled by Designs: RD013
  Realized through Protocols: P037
  Quote: "Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application. Since data structures were..."

[M026] Quality assurance by project staff: Review randomly selected digitisation work to characterise error patterns
  Tier: quality_assurance | Status: explicit
  Location: Section: Results | Subsection: 3.5.2 Digitisation errors | Page: 7 | Para: 2
  Enabled by Designs: RD013
  Realized through Protocols: P036
  Quote: "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors... a review by project staff of fou..."

[M027] Continuum analysis: Position approaches along setup cost vs ongoing expert involvement trade-off spectrum
  Tier: comparative_analysis | Status: explicit
  Location: Section: Discussion | Subsection: 4.1 Choosing an approach | Page: 9 | Para: 2
  Enabled by Designs: RD015
  Realized through Protocols: P042
  Quote: "These approaches fall along a continuum from the first, which requires the least setup cost, time, and technical support, but the most ongoing expert ..."

[M028] Staff time payoff calculation: Calculate feature count thresholds using digitization rates and staff hour investments
  Tier: threshold_analysis | Status: explicit
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 1
  Enabled by Designs: RD016
  Realized through Protocols: P043
  Quote: "After brief workspace setup, project staff with desktop GIS experience could digitise at a sustained rate of 60–75 features per staff-hour. At this ra..."

[M029] ML threshold extrapolation: Use Urban Occupations Project benchmark to estimate minimum ML payoff threshold
  Tier: threshold_analysis | Status: explicit
  Location: Section: Discussion | Subsection: 4.1.2 Machine learning versus crowdsourcing | Page: 10 | Para: 2
  Enabled by Designs: RD016
  Realized through Protocols: P044
  Quote: "A minimum threshold for automation can be extrapolated from our 2017-18 fieldwork and the Urban Occupations Project. We spent 44 staff hours customisi..."

[M030] Marginal cost analysis: Calculate per-feature staff support cost to assess scalability
  Tier: cost_analysis | Status: explicit
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 3
  Enabled by Designs: RD016
  Realized through Protocols: P045
  Quote: "Third, the marginal cost for each additional feature digitised is low. This figure includes in-field support and quality assurance (13 h), and transla..."


====================================================================================================
PROTOCOLS (40 items)
====================================================================================================

[P001] Programmer time measurement: timesheets from student programmer
  Tier: measurement | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Implements Method: M001
  Quote: "Project records provided much of this data (timesheets from the programmer"

[P002] Student time measurement: record creation timestamps from FAIMS Mobile system
  Tier: measurement | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Implements Method: M001
  Parameters: 2 defined
    • time_recorded: start and end times of feature creation as recorded by devices
    • time_metric: work time excluding pauses between records
  Quote: "record creation timestamps for students using the system"

[P003] Staff time measurement: time-on-task logging in field journals
  Tier: measurement | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Implements Method: M001
  Quote: "project staff logged time-on-task for activities in journals"

[P004] Feature counting: extract count from digitization application records
  Tier: measurement | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Implements Method: M002
  Quote: "We took the number of features digitised as the output."

[P005] Quality assurance sampling: review 4 randomly selected maps (7% of total) for error characterization
  Tier: validation | Status: explicit
  Location: Section: Results | Subsection: 3.5.2 Digitisation errors | Page: 8 | Para: 1
  Implements Method: M003
  Parameters: 3 defined
    • sample_size: 4 maps
    • sample_percentage: 7% of total maps
    • sampling_method: random selection
  Quote: "Second, a review by project staff of four randomly selected maps (7% of the total)"

[P006] System customization: student programmer creates definition files (35h in 2017, 1h in 2018)
  Tier: setup | Status: explicit
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 1
  Implements Method: M004
  Parameters: 3 defined
    • 2017_programmer_time: 35 hours
    • 2017_staff_time: 4 hours
    • 2018_programmer_time: 1 hour
  Quote: "For the first season of use (2017), creating the Map Digitisation customisation of FAIMS Mobile required 35 h from an undergraduate student programmer..."

[P007] Server setup and device configuration: 3h in 2017, 1h in 2018
  Tier: setup | Status: explicit
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 1
  Implements Method: M004
  Parameters: 2 defined
    • 2017_setup_time: 3 hours
    • 2018_setup_time: 1 hour
  Quote: "Setup of the server and configuration of the client devices in the field required 3 h from staff."

[P008] Map preparation: tiling and adding pyramids (1.5h in 2017, 0.5h in 2018)
  Tier: data_preparation | Status: explicit
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 1
  Implements Method: M004
  Parameters: 3 defined
    • 2017_map_prep_time: 1.5 hours
    • 2018_map_prep_time: 0.5 hours
    • procedure: tiling and adding pyramids to GeoTIFF files
  Quote: "Map preparation (tiling, adding pyramids) required about 1.5 h."

[P009] Volunteer training: minimal training, students begin digitizing after only minutes
  Tier: training | Status: explicit
  Location: Section: Approach | Subsection: 2.2 Crowdsourcing digitisation with field-school participants | Page: 4 | Para: 4
  Implements Method: M005
  Parameters: 2 defined
    • training_duration: minutes
    • staff_supervision: no more than half an hour across entire season
  Quote: "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only min..."

[P010] Interface design: toggle between map view (geospatial) and form view (attributes)
  Tier: interface_design | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 4
  Implements Method: M005
  Quote: "Volunteers could toggle between a map view for geospatial data interactions and a form view for attribute creation and editing."

[P011] Automated metadata: system records creation time, author, change history automatically
  Tier: automation | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 2
  Implements Method: M006
  Quote: "recorded creation time and author for each record, maintained a history of all changes to data"

[P012] Threshold calculation: divide staff hours by digitization rate to find break-even point
  Tier: calculation | Status: explicit
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 9 | Para: 2
  Implements Method: M007
  Parameters: 1 defined
    • calculation_formula: staff_hours × digitization_rate_per_hour = threshold_features
  Quote: "At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420–..."

[P013] Error categorization: classify as false positive, false negative, double-marked, or classification error
  Tier: analysis | Status: explicit
  Location: Section: Results | Subsection: 3.5.2 Digitisation errors | Page: 8 | Para: 1
  Implements Method: M008
  Parameters: 1 defined
    • error_types: ['false_positive', 'false_negative', 'double_marked', 'classification_error']
  Quote: "Forty-two of these errors were false negatives (symbols missed by students). Six were double-marked (Student C digitised a section of a map twice). St..."

[P014] System repurposing: adapt FAIMS Mobile from in-field legacy data verification to map digitization
  Tier: adaptation | Status: explicit
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 3
  Implements Method: M009
  Quote: "Reusing the platform for digitisation offered a consistent working environment for users, reduced administrative load on staff, leveraged our experien..."

[P015] FAIR data principles implementation: produce rich and plural metadata at time of data creation
  Tier: data_management | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 5
  Implements Method: M010
  Parameters: 2 defined
    • FAIR_principles_addressed: ['F2', 'R1.1', 'R1.2', 'R1.3']
    • metadata_timing: at time of data creation
  Quote: "Exported data was consistent and complete, ready for analysis with minimal cleaning. This data adhered to key elements of the FAIR data principles, es..."

[P016] Mound registration: visit known mounds, record GPS location and condition assessment
  Tier: data_collection | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Implements Method: M011
  Quote: "visiting known burial mounds, registering their location and condition"

[P017] Satellite monitoring: identify condition changes in mounds using satellite imagery comparison
  Tier: monitoring | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Implements Method: M012
  Quote: "identifying changes in mound condition using satellite imagery"

[P018] Map digitization: extract mound symbols from Soviet 1:50,000 topographic maps covering 20,000+ sq km
  Tier: data_collection | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Implements Method: M013
  Parameters: 3 defined
    • map_scale: 1:50,000
    • map_type: Soviet military topographic maps
    • coverage_area: over 20,000 sq km
  Quote: "digitising mounds from over 20,000 sq km of Soviet military 1:50,000 topographic maps covering southeast Bulgaria"

[P019] Ground-truthing: field verification of digitized mound locations (continued through 2022)
  Tier: validation | Status: explicit
  Location: Section: Introduction | Subsection: 1.1 The Tundzha Regional Archaeology Project | Page: 2 | Para: 2
  Implements Method: M013
  Parameters: 2 defined
    • validation_period: 2017-2022
    • validation_method: field verification of digitized locations
  Quote: "followed by ground-truthing (which continued through 2022)"

[P020] Undergraduate volunteers digitize map features using mobile application during field school
  Tier: data_collection | Status: explicit
  Location: Section: Introduction | Page: 1 | Para: 1
  Implements Method: M014
  Quote: "Undergraduates in the associated field school digitised data from maps using a system repurposed from other project activities."

[P021] Secondary activity scheduling: Digitization during rainy days and when students remain at field base
  Tier: scheduling | Status: explicit
  Location: Section: Results | Subsection: 3.2 Student-volunteer digitisation velocity and volume | Page: 7 | Para: 1
  Implements Method: M015
  Quote: "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days... In 2018, use was more sporadic; participants who stayed ..."

[P022] Essential GIS operations: Hide unnecessary features, expose only layer selection, shape digitization, attribute annotation controls
  Tier: interface_design | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 2
  Implements Method: M016
  Quote: "GIS features not needed for digitisation were hidden or eliminated. Digitisation and metadata creation required no GIS or computing skills. Students c..."

[P023] Staff insulation workflow: Staff handle setup, layer management, aggregation, export, backup; volunteers only digitize
  Tier: workflow_management | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 6 | Para: 1
  Implements Method: M017
  Quote: "Since project staff set up the infrastructure and pre-processed and loaded the required maps, volunteers were insulated from the friction of setup, la..."

[P024] 2018 refinements: Add validation for lat/long population, improve error handling based on 2017 experience
  Tier: iterative_improvement | Status: explicit
  Location: Section: Results | Subsection: 3.1 Project staff time for setup, support, and accuracy-checking | Page: 7 | Para: 2
  Implements Method: M018
  Quote: "For the second season, adding additional validation to ensure population of latitude and longitude from GPS (see 'Recoverable data omissions and incom..."

[P025] FAIMS Mobile customization: Create definition files interpreted by platform to generate Android data collection app
  Tier: software_development | Status: explicit
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 2
  Implements Method: M019
  Parameters: 3 defined
    • platform: FAIMS Mobile
    • customization_mechanism: definition files
    • output: Android application
  Quote: "Customisation is accomplished via definition files that can be shared, modified, and redeployed. FAIMS Mobile interprets the definition files to gener..."

[P026] Multi-device offline data collection with opportunistic network synchronization
  Tier: data_synchronization | Status: explicit
  Location: Section: Approach | Subsection: 2.3 Using a mobile application for map digitisation | Page: 4 | Para: 2
  Implements Method: M019
  Quote: "Data collection works offline, and can employ as many devices as necessary. It is later synchronised opportunistically, when a network is available."

[P027] Unobtrusive interface design: Minimize user interactions with recording mechanism, conform to workflow, automate metadata
  Tier: usability_design | Status: explicit
  Location: Section: Introduction | Subsection: 1.4 Sociotechnical barriers to collaborative map digitisation | Page: 3 | Para: 6
  Implements Method: M020
  Quote: "UIs for mobile data collection systems must allow the user to (1) focus on observations while minimising interactions with the recording mechanism, (2..."

[P028] Stages 1-2: Staff model data/workflow, then developer customizes system (2017: 35h+4h; 2018: 1h refinement)
  Tier: workflow_implementation | Status: explicit
  Location: Section: Approach | Subsection: 2.4 | Page: 5
  Implements Method: M021
  Parameters: 3 defined
    • 2017_staff_hours: 4
    • 2017_dev_hours: 35
    • 2018_hours: 1
  Quote: "(1) project staff modelled the data and workflow... (2) a junior software developer worked with project staff to customise the system"
  [CONSOLIDATED from: P028, P029]

[P030] Stage 3: Staff define spatial reference system and import preprocessed historical maps
  Tier: workflow_implementation | Status: explicit
  Location: Section: Approach | Subsection: 2.4 Design and implementation of the recording system | Page: 5 | Para: 1
  Implements Method: M021
  Parameters: 2 defined
    • map_format: georeferenced GeoTIFFs
    • preprocessing: tiling, adding pyramids
  Quote: "project staff defined a spatial reference system (SRS) and imported preprocessed historical maps"

[P031] Stages 4-5: Volunteers perform digitization - draw shapes at target locations, then transcribe attributes
  Tier: workflow_implementation | Status: explicit
  Location: Section: Approach | Subsection: 2.4 | Page: 5
  Implements Method: M021
  Quote: "(4) volunteers drew a shape (usually a point) wherever they saw a target symbol and (5) volunteers transcribed attributes from the map"
  [CONSOLIDATED from: P031, P032]

[P033] Stages 6-7: Staff post-processing - export data from server, then accuracy-checking
  Tier: workflow_implementation | Status: explicit
  Location: Section: Approach | Subsection: 2.4 | Page: 5
  Implements Method: M021
  Quote: "(6) project staff exported data using the FAIMS Mobile server, (7) project staff undertook a targeted accuracy-checking exercise"
  [CONSOLIDATED from: P033, P034]

[P035] Time tracking protocol: Combine programmer timesheets, device record timestamps, and staff journal logs
  Tier: evaluation_data_collection | Status: explicit
  Location: Section: Approach | Subsection: 2.5 Evaluating the digitisation approach | Page: 6 | Para: 2
  Implements Method: M022
  Parameters: 1 defined
    • data_sources: ['programmer timesheets', 'device record creation timestamps', 'staff time-on-task journals']
  Quote: "Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project s..."

[P036] Random map selection for staff re-digitization and error characterization
  Tier: quality_assurance | Status: explicit
  Location: Section: Results | Subsection: 3.5.2 Digitisation errors | Page: 7 | Para: 2
  Implements Method: M023
  Parameters: 3 defined
    • sample_size: 4 maps
    • sample_percentage: 7% of total maps
    • verification_method: staff re-digitization and comparison
  Quote: "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors... a review by project staff of fou..."

[P037] Performance degradation mitigation: Export all data, instantiate empty application, continue work, aggregate exports
  Tier: performance_management | Status: explicit
  Location: Section: Results | Subsection: 3.4 Application performance | Page: 7 | Para: 2
  Implements Method: M024
  Parameters: 2 defined
    • performance_threshold: approximately 2,500 records per device
    • degradation_symptom: lat/long extraction time increased from 3-5s to 30s
  Quote: "Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application. Since data structures were..."

[P038] Two-season execution: 2017 (125.8h, 8,343 feat, 54s avg) + 2018 (63.6h, 2,484 feat, 92s avg) = 189.4h, 10,827 feat total
  Tier: data_collection_execution | Status: explicit
  Location: Section: Results | Subsection: 3.2 | Page: 7
  Implements Method: M015
  Parameters: 3 defined
    • 2017: {'hours': 125.8, 'features': 8343, 'maps': 42, 'avg_s': 54, 'pattern': 'concentrated'}
    • 2018: {'hours': 63.6, 'features': 2484, 'maps': 16, 'avg_s': 92, 'pattern': 'sporadic'}
    • total: {'hours': 189.4, 'features': 10827, 'maps': 58, 'avg_s': 63}
  Quote: "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days, during which time 8,343 features were digitised... In 2018..."
  [CONSOLIDATED from: P038, P039]

[P040] Spatial data omission recovery: Re-extract latitude/longitude from preserved geodatabase geometries
  Tier: error_correction | Status: explicit
  Location: Section: Results | Subsection: 3.5.1 Recoverable data omissions and incomplete records | Page: 7 | Para: 1
  Implements Method: M026
  Parameters: 3 defined
    • 2017_spatial_errors: 192
    • 2018_spatial_errors: 13
    • unrecoverable: 2
  Quote: "Since the geodatabase preserved geometries, spatial omissions were corrected by re-extracting latitude and longitude; only two data points could not b..."

[P041] Error characterization: Random sample QA checking to identify error types (false positives, false negatives, double-marking, classification errors)
  Tier: quality_assurance | Status: explicit
  Location: Section: Results | Subsection: 3.5.2 Digitisation errors | Page: 7 | Para: 2
  Implements Method: M026
  Parameters: 9 defined
    • sample_size_maps: 4
    • sample_percentage: 7%
    • true_feature_count: 834
    ... and 6 more
  Quote: "a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error rate (see ..."

[P042] Trade-off visualization: Position approaches on continuum from fast-setup/high-touch to slow-setup/low-touch
  Tier: analytical_framework | Status: explicit
  Location: Section: Discussion | Subsection: 4.1 Choosing an approach | Page: 9 | Para: 2
  Implements Method: M027
  Quote: "These approaches fall along a continuum from the first, which requires the least setup cost, time, and technical support, but the most ongoing expert ..."

[P043] Comprehensive threshold framework: Expert GIS (3,420-4,275→4,500), Volunteer GIS (7,410-10,260→10,000), Crowdsourcing optimal (10,000-60,000), ML (>60,000)
  Tier: threshold_calculation | Status: explicit
  Location: Section: Discussion | Subsection: 4.1 | Page: 9
  Implements Method: M028
  Parameters: 4 defined
    • expert_GIS: {'rate': '60-75/h', 'threshold': '3,420-4,275', 'conservative': 4500}
    • volunteer_GIS: {'rate': '130-180/h', 'threshold': '7,410-10,260', 'conservative': 10000}
    • crowdsourcing: {'rate': '44.9/h', 'optimal_range': '10,000-60,000'}
    ... and 1 more
  Quote: "After brief workspace setup, project staff with desktop GIS experience could digitise at a sustained rate of 60–75 features per staff-hour... To summa..."
  [CONSOLIDATED from: P043, P044, P046]

[P045] Marginal cost calculation: Divide in-field support and QA hours by total features to determine per-feature cost
  Tier: cost_analysis | Status: explicit
  Location: Section: Discussion | Subsection: 4.1.1 Desktop GIS approaches versus crowdsourcing | Page: 10 | Para: 3
  Implements Method: M030
  Parameters: 5 defined
    • in_field_support_and_QA_hours: 13
    • marginal_staff_support_per_feature_seconds: 4.3
    • map_preparation_minutes: 6
    ... and 2 more
  Quote: "This figure includes in-field support and quality assurance (13 h), and translates to 4.3 s of staff support per additional feature. Thus, the larger ..."


====================================================================================================
EXTRACTION STATISTICS
====================================================================================================

Total Items: 275
  Claims: 78
  Evidence: 107
  Implicit Arguments: 6
  Research Designs: 15
  Methods: 29
  Protocols: 40

Claim Types:
  • methodological_argument: 30
  • interpretation: 27
  • background: 18
  • gap: 3

Evidence Types:
  • measurement: 55
  • observation: 52

Research Design Types:
  • evaluation_study: 2
  • intervention_design: 1
  • comparative_study: 1
  • case_study: 1
  • opportunistic_study: 1
  • interdisciplinary_study: 1
  • multi_method_study: 1
  • participatory_research: 1
  • usability_focused_design: 1
  • technology_selection: 1
  • workflow_design: 1
  • iterative_design: 1
  • comparative_framework: 1
  • comparative_evaluation: 1

Method Tiers:
  • data_collection: 6
  • data_management: 2
  • analysis: 2
  • quality_assurance: 2
  • threshold_analysis: 2
  • validation: 1
  • intervention: 1
  • adaptation: 1
  • monitoring: 1
  • opportunistic_data_collection: 1
  • interface_simplification: 1
  • division_of_labor: 1
  • iterative_development: 1
  • platform_adaptation: 1
  • usability_transfer: 1
  • workflow_management: 1
  • evaluation_data_collection: 1
  • performance_management: 1
  • comparative_analysis: 1
  • cost_analysis: 1

Protocol Tiers:
  • measurement: 4
  • workflow_implementation: 4
  • data_collection: 3
  • validation: 2
  • setup: 2
  • interface_design: 2
  • quality_assurance: 2
  • data_preparation: 1
  • training: 1
  • automation: 1
  • calculation: 1
  • analysis: 1
  • adaptation: 1
  • data_management: 1
  • monitoring: 1
  • scheduling: 1
  • workflow_management: 1
  • iterative_improvement: 1
  • software_development: 1
  • data_synchronization: 1
  • usability_design: 1
  • evaluation_data_collection: 1
  • performance_management: 1
  • data_collection_execution: 1
  • error_correction: 1
  • analytical_framework: 1
  • threshold_calculation: 1
  • cost_analysis: 1

====================================================================================================
END OF REPORT
====================================================================================================