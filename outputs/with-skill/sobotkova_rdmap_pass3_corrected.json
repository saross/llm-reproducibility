{
  "schema_version": "2.4",
  "extraction_timestamp": "2025-10-20T20:40:28.299884Z",
  "extractor": "Claude Sonnet 4.5",
  "evidence": [
    {
      "evidence_id": "E001",
      "evidence_text": "Project staff with desktop GIS experience could digitise at a sustained rate of 60-75 features per staff-hour",
      "evidence_type": "performance_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "range",
        "magnitude": "60-75 features per staff-hour"
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 2
      },
      "extraction_notes": "Rate for staff digitization using desktop GIS after brief workspace setup",
      "extraction_confidence": "high"
    },
    {
      "evidence_id": "E002",
      "evidence_text": "57 hours of staff time devoted to set-up, support, and quality assurance for crowdsourcing system",
      "evidence_type": "time_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": false
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 2
      },
      "extraction_notes": "Total staff time investment for crowdsourcing approach",
      "extraction_confidence": "high"
    },
    {
      "evidence_id": "E003",
      "evidence_text": "2010 digitisation rate of 130-180 features per staff-hour when training and supervising volunteers using desktop GIS",
      "evidence_type": "performance_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "range",
        "magnitude": "130-180 features per staff-hour"
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Historical performance data from 2010 project",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E004"
        ],
        "consolidation_type": "id_shift",
        "information_preserved": "complete",
        "rationale": "ID renumbered after removing redundant calculation evidence E003 and E005 from Pass 1"
      }
    },
    {
      "evidence_id": "E004",
      "evidence_text": "The crowdsourcing approach produced 10,827 features using 57 hours of staff time, or about 190 features per staff-hour",
      "evidence_type": "performance_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "approximation",
        "magnitude": "about 190"
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 4
      },
      "extraction_notes": "Actual performance achieved with crowdsourcing approach - combined output and efficiency",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E006"
        ],
        "consolidation_type": "id_shift",
        "information_preserved": "complete",
        "rationale": "ID renumbered; this consolidates the core performance finding"
      }
    },
    {
      "evidence_id": "E005",
      "evidence_text": "Staff time breakdown: 21 hours from internal project staff, 36 hours from student programmer (cost ca. AUD $2,000)",
      "evidence_type": "resource_allocation",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "approximation",
        "magnitude": "ca. AUD $2,000"
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 5
      },
      "extraction_notes": "Breakdown distinguishing internal vs outsourced staff effort",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E007"
        ],
        "consolidation_type": "id_shift",
        "information_preserved": "complete",
        "rationale": "ID renumbered after upstream consolidations"
      }
    },
    {
      "evidence_id": "E006",
      "evidence_text": "In-field support for volunteers was 7 hours across two seasons, representing about 1,550 features per in-field staff-hour",
      "evidence_type": "performance_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "approximation",
        "magnitude": "about 1,550"
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 6
      },
      "extraction_notes": "Field-specific time requirements and efficiency",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E010"
        ],
        "consolidation_type": "id_shift",
        "information_preserved": "complete",
        "rationale": "ID renumbered; maintains temporal and efficiency dimensions"
      }
    },
    {
      "evidence_id": "E007",
      "evidence_text": "Marginal cost for crowdsourcing approach: 4.3 seconds of staff support per additional feature (based on 13 hours in-field support and quality assurance for 10,827 features)",
      "evidence_type": "performance_measurement",
      "evidence_basis": "calculation",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": false
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 7
      },
      "extraction_notes": "Marginal cost calculation with context",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E012"
        ],
        "consolidation_type": "id_shift",
        "information_preserved": "complete",
        "rationale": "ID renumbered; includes anchor numbers for interpretability"
      }
    },
    {
      "evidence_id": "E008",
      "evidence_text": "Scalability metrics: 6 minutes per additional map (6 hours for 58 maps), 1 hour for redeployment in subsequent field season",
      "evidence_type": "time_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": false
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 7
      },
      "extraction_notes": "Multiple scalability measurements consolidated",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E013",
          "P1_E014"
        ],
        "consolidation_type": "compound_finding",
        "information_preserved": "complete",
        "granularity_available": "Separate measurements for map preparation and seasonal redeployment available in source items",
        "rationale": "Both measurements demonstrate low fixed costs for scaling - assessed together as evidence of scalability"
      }
    },
    {
      "evidence_id": "E009",
      "evidence_text": "In 2010, attrition meant constantly onboarding new volunteers, and the learning curve of desktop GIS meant support time declined only slowly as students became more experienced",
      "evidence_type": "observational_record",
      "evidence_basis": "observational_record",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": false
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 7
      },
      "extraction_notes": "Comparison with previous desktop GIS approach challenges",
      "extraction_confidence": "medium",
      "verbatim_quote": "in 2010, the demands on staff time related to volunteer support never plateaued, as attrition meant that we were constantly onboarding new volunteers, while the learning curve of desktop GIS meant that support time declined only slowly",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E015"
        ],
        "consolidation_type": "id_shift",
        "information_preserved": "complete",
        "rationale": "ID renumbered after upstream consolidations"
      }
    },
    {
      "evidence_id": "E010",
      "evidence_text": "Urban Occupations Project: 1,250 hours manual digitisation for ML training data, 7 days expert time for model testing/tuning, output of 300,000 km of roads, total preparation time minimum 1,300 hours",
      "evidence_type": "benchmark_data",
      "evidence_basis": "literature_report",
      "source": "Can, Gerrits, and Kabadayi 2021",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "approximation",
        "magnitude": "about 1,300 minimum"
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Complete ML approach benchmark consolidated from multiple measurements",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E016",
          "P1_E017",
          "P1_E018",
          "P1_E019"
        ],
        "consolidation_type": "compound_finding",
        "information_preserved": "complete",
        "granularity_available": "Individual measurements for training time, expert time, and output volume available in source items",
        "rationale": "All measurements part of single ML approach benchmark - assessed together as evidence for ML cost/benefit. Creates complete profile of ML deployment requirements."
      }
    },
    {
      "evidence_id": "E011",
      "evidence_text": "Complete time breakdown: 44 staff hours customising/deploying FAIMS Mobile, 184 participant-hours digitising, 7 staff-hours supporting digitisation, 6 staff hours error checking; total 241 hours producing 10,827 features at 44.9 features per person-hour",
      "evidence_type": "performance_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": false
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2",
        "page": null,
        "paragraph": 4
      },
      "extraction_notes": "Comprehensive breakdown including all participants, not just staff",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E020",
          "P1_E021"
        ],
        "consolidation_type": "compound_finding",
        "information_preserved": "complete",
        "granularity_available": "Itemized breakdown of each time component available in P1_E020",
        "rationale": "Detailed breakdown and aggregate rate assessed together - complete performance profile for ML comparison"
      }
    },
    {
      "evidence_id": "E012",
      "evidence_text": "Data quality: 2% of records had recoverable data omissions corrected during post-processing; accuracy check of 7% sample indicated error rate under 6%",
      "evidence_type": "quality_measurement",
      "evidence_basis": "direct_measurement",
      "source": "project_observation",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "upper_bound",
        "magnitude": "under 6%"
      },
      "location": {
        "section": "Discussion",
        "subsection": "5 (Conclusion)",
        "page": null,
        "paragraph": 2
      },
      "extraction_notes": "Complete quality profile: omissions and errors",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E023",
          "P1_E024"
        ],
        "consolidation_type": "profile_consolidation",
        "information_preserved": "complete",
        "granularity_available": "Separate measurements for omissions vs accuracy errors available in source",
        "rationale": "Both quality metrics assessed together to characterize overall data quality. Forms complete quality profile."
      }
    },
    {
      "evidence_id": "E013",
      "evidence_text": "Conservative payoff thresholds (all invested time): 3,500-4,500 features vs staff desktop GIS; 7,500-10,000 features vs volunteer desktop GIS; 10,000-60,000 optimal range for crowdsourcing; 60,000+ threshold for ML consideration",
      "evidence_type": "threshold_estimate",
      "evidence_basis": "statistical_output",
      "source": "calculation",
      "declared_uncertainty": {
        "uncertainty_present": true,
        "uncertainty_type": "range",
        "magnitude": "multiple ranges depending on comparison"
      },
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 and 4.3",
        "page": null,
        "paragraph": "multiple; Tables 4 and 5"
      },
      "extraction_notes": "Consolidated threshold recommendations across all approaches",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_E025",
          "P1_E026",
          "P1_E027",
          "P1_E028"
        ],
        "consolidation_type": "synthesis",
        "information_preserved": "complete",
        "granularity_available": "Low/mid/high estimate scenarios available in source items; Table 4 provides detailed breakdown by scenario",
        "rationale": "All threshold estimates present same core finding - optimal ranges for each approach. Consolidating prevents threshold proliferation while maintaining interpretability. Conservative estimates emphasized as authors' recommendation."
      }
    }
  ],
  "claims": [
    {
      "claim_id": "C001",
      "claim_text": "The crowdsourced digitisation using novice volunteers and adapted mobile application proved unexpectedly successful despite being an auxiliary activity done under field conditions with inexpensive equipment and limited connectivity",
      "claim_type": "outcome_assessment",
      "claim_role": "core",
      "primary_function": "success_evaluation",
      "supported_by_evidence": [],
      "supported_by_claims": [
        "C002",
        "C003",
        "C004"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Overall evaluation claim integrating context and outcome",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C001",
          "P1_C002",
          "P1_C003"
        ],
        "consolidation_type": "narrative_consolidation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for success evaluation and contextual constraints available in source",
        "rationale": "Success claim more interpretable with constraints integrated. Context (auxiliary, field conditions, limited resources) frames the success achievement. Strategic verbosity improves interpretability."
      }
    },
    {
      "claim_id": "C002",
      "claim_text": "The approach produced 10,827 features with error rate under 6% while placing reasonable demands on volunteers and staff compared to other approaches",
      "claim_type": "outcome_assessment",
      "claim_role": "intermediate",
      "primary_function": "performance_evaluation",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [
        "E004",
        "E012"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Composite performance claim with anchor numbers for interpretability",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C004"
        ],
        "consolidation_type": "id_shift",
        "information_preserved": "complete",
        "rationale": "ID renumbered after consolidation of parent claims; maintains strategic duplication of key metrics"
      }
    },
    {
      "claim_id": "C003",
      "claim_text": "Four principal digitisation approaches exist along a continuum from least setup cost/time/technical support but most ongoing expert involvement (expert staff with desktop GIS) to greatest setup cost/time/technical input but least ongoing expert involvement (ML approach)",
      "claim_type": "methodological_framework",
      "claim_role": "intermediate",
      "primary_function": "classification",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [],
      "location": {
        "section": "Discussion",
        "subsection": "4.1",
        "page": null,
        "paragraph": [
          1,
          2
        ]
      },
      "extraction_notes": "Framework with continuum characterization integrated",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C005",
          "P1_C006"
        ],
        "consolidation_type": "compound_interpretation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for framework enumeration vs tradeoff continuum available in source",
        "rationale": "Framework more interpretable with tradeoff structure integrated. The four approaches and their continuum relationship assessed together."
      }
    },
    {
      "claim_id": "C004",
      "claim_text": "The calculations prioritise staff time as the most limited resource, with rates reflecting high density and moderate obtrusiveness of features in Soviet topographic maps combined with simplicity of digital recording forms",
      "claim_type": "methodological_clarification",
      "claim_role": "supporting",
      "primary_function": "scope_definition",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [],
      "location": {
        "section": "Discussion",
        "subsection": "4.1",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Critical boundary conditions consolidated",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C007",
          "P1_C008"
        ],
        "consolidation_type": "compound_interpretation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for optimization criterion and map characteristics available in source",
        "rationale": "Both boundary conditions frame comparative validity together - optimization criterion and context-specific rate factors assessed jointly"
      }
    },
    {
      "claim_id": "C005",
      "claim_text": "For datasets of 3,500-4,500 features, direct digitisation by expert staff using desktop GIS is more efficient than crowdsourcing setup investment",
      "claim_type": "recommendation",
      "claim_role": "intermediate",
      "primary_function": "guidance",
      "supports_claims": [
        "C006"
      ],
      "supported_by_evidence": [
        "E001",
        "E002",
        "E013"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 2
      },
      "extraction_notes": "Threshold recommendation with anchor numbers",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C009"
        ],
        "consolidation_type": "enhanced_specification",
        "information_preserved": "complete",
        "rationale": "Added specific threshold numbers from evidence for interpretability; eliminates vague 'smaller datasets' language"
      }
    },
    {
      "claim_id": "C006",
      "claim_text": "Volunteer desktop GIS digitisation is almost competitive with mobile crowdsourcing at the highest efficiency rates (7,500-10,000 features), but requires volunteer retention that proved unachievable in 2010",
      "claim_type": "comparative_assessment",
      "claim_role": "intermediate",
      "primary_function": "qualified_comparison",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [
        "E003",
        "E004"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Comparison with critical qualification integrated",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C011",
          "P1_C012"
        ],
        "consolidation_type": "compound_interpretation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for competitive assessment vs retention constraint available in source",
        "rationale": "Competitive claim incomplete without retention qualification - assessed together. Qualification fundamentally limits practical applicability of competitive assessment."
      }
    },
    {
      "claim_id": "C007",
      "claim_text": "The 190 features per staff-hour figure understates crowdsourcing value because customisation can be outsourced (21 internal hours vs 36 outsourced at AUD $2,000 yielding >500 features per internal hour), and in-field time is most scarce (7 hours yielding ~1,550 features per in-field hour)",
      "claim_type": "interpretive_framing",
      "claim_role": "intermediate",
      "primary_function": "interpretation",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [
        "E004",
        "E005",
        "E006"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": [
          4,
          6
        ]
      },
      "extraction_notes": "Meta-claim integrating multiple dimensions of understatement with anchor numbers",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C013",
          "P1_C014",
          "P1_C015",
          "P1_C016"
        ],
        "consolidation_type": "narrative_consolidation",
        "information_preserved": "complete",
        "granularity_available": "Individual arguments about outsourcing feasibility, field time constraints, and strategic tradeoff available in source",
        "rationale": "Multiple related arguments supporting same meta-claim that simple metric misleading. All demonstrate ways standard metric undervalues approach - assessed together as integrated argument."
      }
    },
    {
      "claim_id": "C008",
      "claim_text": "The crowdsourcing approach has low marginal cost (4.3 seconds staff support per feature) and excellent scalability: adding volunteers requires no setup time, additional maps take 6 minutes each, and redeployment costs only 1 hour",
      "claim_type": "efficiency_assessment",
      "claim_role": "intermediate",
      "primary_function": "economic_advantage",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [
        "E007",
        "E008"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 7
      },
      "extraction_notes": "Economic characteristics consolidated with anchor numbers",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C017",
          "P1_C018",
          "P1_C019",
          "P1_C020",
          "P1_C021"
        ],
        "consolidation_type": "synthesis",
        "information_preserved": "complete",
        "granularity_available": "Individual claims for marginal cost, economies of scale, volunteer scaling, map preparation, and redeployment available in source",
        "rationale": "All claims characterize same economic advantage - scalability through low fixed costs. Assessed together as integrated efficiency profile. Strategic verbosity with specific metrics improves interpretability."
      }
    },
    {
      "claim_id": "C009",
      "claim_text": "Desktop GIS volunteer support demands never plateaued in 2010 due to attrition requiring constant onboarding and steep learning curve, contrasting with mobile approach's minimal ongoing support needs",
      "claim_type": "comparative_assessment",
      "claim_role": "supporting",
      "primary_function": "contrast",
      "supports_claims": [
        "C008"
      ],
      "supported_by_evidence": [
        "E009"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 7
      },
      "extraction_notes": "Explicit comparison added in Pass 2 - implicit in Pass 1",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C022"
        ],
        "consolidation_type": "enhanced_specification",
        "information_preserved": "complete",
        "rationale": "Added explicit contrast with mobile approach that was implicit in Pass 1. Comparison makes advantage clearer."
      }
    },
    {
      "claim_id": "C010",
      "claim_text": "Qualitative factors favor mobile crowdsourcing: desktop GIS required continual staff availability creating stress, volunteers perceived it as burden reducing morale, while mobile approach eliminated staff intervention needs and improved volunteer satisfaction through flexible offline work",
      "claim_type": "qualitative_assessment",
      "claim_role": "intermediate",
      "primary_function": "non-quantitative_advantage",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 8
      },
      "extraction_notes": "Qualitative argument consolidated across problem-solution structure",
      "extraction_confidence": "medium",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C024",
          "P1_C025",
          "P1_C026",
          "P1_C027",
          "P1_C028",
          "P1_C029"
        ],
        "consolidation_type": "narrative_consolidation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for desktop GIS problems (staff stress, volunteer burden) and mobile advantages (learning ease, flexibility) available in source",
        "rationale": "Problem-solution narrative assessed together. Desktop disadvantages and mobile advantages form integrated qualitative argument - assessed jointly as contrasting profiles."
      }
    },
    {
      "claim_id": "C011",
      "claim_text": "ML papers rarely quantify time-on-task, making threshold assessment difficult; Urban Occupations Project (1,300 hours preparation for 300,000 km roads) provides one benchmark suggesting ML worthwhile for large-scale projects with consistent symbology",
      "claim_type": "methodological_justification",
      "claim_role": "supporting",
      "primary_function": "source_validation",
      "supports_claims": [
        "C012"
      ],
      "supported_by_evidence": [
        "E010"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2",
        "page": null,
        "paragraph": [
          1,
          3
        ]
      },
      "extraction_notes": "Justification with benchmark integrated, includes anchor numbers",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C030",
          "P1_C031",
          "P1_C032"
        ],
        "consolidation_type": "narrative_consolidation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for literature gap, benchmark identification, and ML suitability interpretation available in source",
        "rationale": "Gap identification justifies reliance on single benchmark, benchmark data supports suitability claim - assessed together as integrated justification for ML comparison"
      }
    },
    {
      "claim_id": "C012",
      "claim_text": "Crowdsourcing approach is most suitable for 10,000-60,000 feature datasets (assuming similar characteristics): below 10,000 desktop GIS should be considered (payoff thresholds: 3,500-4,500 vs staff, 7,500-10,000 vs volunteers), above 60,000 ML should be contemplated if expertise available",
      "claim_type": "recommendation",
      "claim_role": "core",
      "primary_function": "guidance",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [
        "E013"
      ],
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2",
        "page": null,
        "paragraph": 5
      },
      "extraction_notes": "Central threshold recommendation with all ranges integrated and anchor numbers",
      "extraction_confidence": "medium",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C033",
          "P1_C034",
          "P1_C035",
          "P1_C036",
          "P1_C037"
        ],
        "consolidation_type": "synthesis",
        "information_preserved": "complete",
        "granularity_available": "Separate recommendations for optimal range, lower threshold alternatives, conservative scenarios, context modifications, and upper threshold available in source",
        "rationale": "All threshold recommendations part of integrated guidance framework - assessed together. Strategic verbosity with specific thresholds maintains interpretability while consolidating structure. Context qualification (similar characteristics) and expertise caveat integrated."
      }
    },
    {
      "claim_id": "C013",
      "claim_text": "ML and crowdsourcing approaches are complementary rather than exclusive: datasets justifying ML likely need crowdsourced training data (especially for variable features), and crowdsourcing platforms can produce error-checking datasets for ML quality assurance",
      "claim_type": "recommendation",
      "claim_role": "intermediate",
      "primary_function": "integration_proposal",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [],
      "location": {
        "section": "Discussion",
        "subsection": "4.2",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Complementarity argument with bidirectional integration",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C038",
          "P1_C039",
          "P1_C040",
          "P1_C041"
        ],
        "consolidation_type": "synthesis",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for complementarity assertion, training data rationale, QA application, and synthesis conclusion available in source",
        "rationale": "All claims support same integrated argument about complementary relationship - training data and QA are two sides of integration. Assessed together as single complementarity claim."
      }
    },
    {
      "claim_id": "C014",
      "claim_text": "Typical small, under-resourced history/archaeology projects pursuing multiple activities may not be able to dedicate resources for ML, but can deploy collaborative geospatial crowdsourcing systems with higher up-front investment than desktop GIS yet reasonable feasibility",
      "claim_type": "feasibility_assessment",
      "claim_role": "intermediate",
      "primary_function": "practical_guidance",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [],
      "location": {
        "section": "Discussion",
        "subsection": "4.3",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Feasibility assessment with ML constraint and crowdsourcing tradeoff integrated",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C042",
          "P1_C043",
          "P1_C044"
        ],
        "consolidation_type": "compound_interpretation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for ML infeasibility, crowdsourcing feasibility, and tradeoff acknowledgment available in source",
        "rationale": "Feasibility assessment more interpretable with both constraint (ML) and alternative (crowdsourcing) integrated. Assessed together as practical guidance for typical projects."
      }
    },
    {
      "claim_id": "C015",
      "claim_text": "Projects with digital humanist or technologist at Software Carpentry skill level can customize platforms like FAIMS Mobile, with technical barriers likely declining as multiple customizable mobile GIS systems exist and prioritize ease of customization",
      "claim_type": "capability_claim",
      "claim_role": "supporting",
      "primary_function": "skill_specification",
      "supports_claims": [
        "C014"
      ],
      "supported_by_evidence": [],
      "location": {
        "section": "Discussion",
        "subsection": "4.3",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Skill threshold with availability and trend integrated",
      "extraction_confidence": "medium",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C045",
          "P1_C046",
          "P1_C047",
          "P1_C048"
        ],
        "consolidation_type": "synthesis",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for skill specification, tool availability, ease-of-use trend, and future barrier decline available in source",
        "rationale": "Skill requirement more meaningful with tool availability and trajectory integrated. All support feasibility argument - assessed together as capability profile."
      }
    },
    {
      "claim_id": "C016",
      "claim_text": "More projects need to track and publish time requirements (setup, training, support, QA), digitisation speed, error rates and types, feature characteristics, and information complexity to refine and generalise these single-case recommendations",
      "claim_type": "recommendation",
      "claim_role": "supporting",
      "primary_function": "future_research",
      "supports_claims": [
        "C001"
      ],
      "supported_by_evidence": [],
      "location": {
        "section": "Discussion",
        "subsection": "5 (Conclusion)",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Research recommendation with limitation acknowledgment integrated",
      "extraction_confidence": "high",
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C049",
          "P1_C050",
          "P1_C051"
        ],
        "consolidation_type": "compound_interpretation",
        "information_preserved": "complete",
        "granularity_available": "Separate claims for reporting call, generalizability improvement, and single-case limitation available in source",
        "rationale": "Call for better reporting more meaningful with generalizability rationale integrated. Single-case limitation justifies need for more data - assessed together."
      }
    }
  ],
  "implicit_arguments": [
    {
      "implicit_id": "IA001",
      "implicit_text": "Feature density and obtrusiveness in source maps affects digitisation rates, making comparisons context-dependent",
      "type": "unstated_assumption",
      "related_to_claims": [
        "C004",
        "C012"
      ],
      "rationale": "The authors explicitly acknowledge their rates depend on map characteristics, but don't systematically explore how different map characteristics would alter their thresholds. This assumption underlies all comparative calculations.",
      "importance": "high",
      "location": {
        "section": "Discussion",
        "subsection": "4.1",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Critical boundary condition affecting generalizability",
      "extraction_confidence": "high"
    },
    {
      "implicit_id": "IA002",
      "implicit_text": "Staff time is the most constrained resource in typical archaeology/history projects, making it the appropriate optimization criterion",
      "type": "disciplinary_assumption",
      "related_to_claims": [
        "C004",
        "C005",
        "C012"
      ],
      "rationale": "The authors explicitly prioritize staff time but don't justify why this is the appropriate metric over total cost, data quality, or time-to-completion. This reflects disciplinary norms about resource constraints in humanities/archaeology projects.",
      "importance": "high",
      "location": {
        "section": "Discussion",
        "subsection": "4.1",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Fundamental criterion choice affecting all recommendations",
      "extraction_confidence": "high"
    },
    {
      "implicit_id": "IA003",
      "implicit_text": "Volunteer retention is a significant risk factor for desktop GIS approaches but not for mobile crowdsourcing approaches",
      "type": "unstated_assumption",
      "related_to_claims": [
        "C006",
        "C009"
      ],
      "rationale": "The 2010 experience showed retention problems with desktop GIS, and authors assume (but don't explicitly demonstrate) that mobile approach doesn't face similar retention challenges. This assumption is crucial to the comparative assessment.",
      "importance": "high",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Key assumption about mobile approach advantage not directly evidenced for mobile approach",
      "extraction_confidence": "medium"
    },
    {
      "implicit_id": "IA004",
      "implicit_text": "Linear extrapolation from small-scale efficiency measurements to large-scale thresholds is valid",
      "type": "logical_implication",
      "related_to_claims": [
        "C012"
      ],
      "rationale": "All threshold calculations assume constant per-feature rates at scale. Authors don't address whether efficiency gains/losses occur as dataset size increases. This is a standard economic assumption but may not hold for volunteer-based workflows.",
      "importance": "medium",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2",
        "page": null,
        "paragraph": 5
      },
      "extraction_notes": "Scaling assumption underlying all quantitative thresholds",
      "extraction_confidence": "high"
    },
    {
      "implicit_id": "IA005",
      "implicit_text": "ML approaches require specialized expertise that is not typically available to small humanities/archaeology projects",
      "type": "disciplinary_assumption",
      "related_to_claims": [
        "C011",
        "C012",
        "C014"
      ],
      "rationale": "Authors consistently assume ML expertise is a barrier without quantifying what expertise is needed or whether it could be acquired. This reflects disciplinary understanding of typical project capabilities.",
      "importance": "medium",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 and 4.3",
        "page": null,
        "paragraph": "multiple"
      },
      "extraction_notes": "Expertise barrier assumption shaping ML feasibility claims",
      "extraction_confidence": "high"
    },
    {
      "implicit_id": "IA006",
      "implicit_text": "The Urban Occupations Project represents a reasonable benchmark for ML deployment costs despite different feature types and contexts",
      "type": "bridging_claim",
      "related_to_claims": [
        "C011"
      ],
      "rationale": "Authors use road digitisation from Ottoman maps as a benchmark for burial mound digitisation from Soviet maps. The assumption that these are comparable enough for threshold estimation is stated but not justified.",
      "importance": "medium",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Comparability assumption for ML benchmark",
      "extraction_confidence": "medium"
    },
    {
      "implicit_id": "IA007",
      "implicit_text": "Quality metrics (error rate <6%) are acceptable for the intended uses of the dataset",
      "type": "unstated_assumption",
      "related_to_claims": [
        "C002"
      ],
      "rationale": "Authors present 6% error rate as indicating 'high quality' but don't specify what error rates would be unacceptable or how error tolerance varies by use case. The acceptability threshold is assumed.",
      "importance": "medium",
      "location": {
        "section": "Discussion",
        "subsection": "4",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Quality threshold assumption",
      "extraction_confidence": "high"
    },
    {
      "implicit_id": "IA008",
      "implicit_text": "Volunteer satisfaction and staff stress are relevant factors in method selection beyond pure efficiency metrics",
      "type": "unstated_assumption",
      "related_to_claims": [
        "C010"
      ],
      "rationale": "Authors present qualitative factors as relevant to method choice but don't justify why or how much weight these should receive relative to quantitative metrics. This reflects a holistic project management perspective.",
      "importance": "medium",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 8
      },
      "extraction_notes": "Assumption about relevance of qualitative factors to method evaluation",
      "extraction_confidence": "high"
    },
    {
      "implicit_id": "IA009",
      "implicit_text": "Setup time invested before and after fieldwork is more available/flexible than in-field staff time during the field season",
      "type": "unstated_assumption",
      "related_to_claims": [
        "C007"
      ],
      "rationale": "Authors treat pre/post fieldwork time as more elastic than in-field time without explaining the constraint structure. This reflects fieldwork project realities where field time is compressed and high-stakes.",
      "importance": "medium",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1",
        "page": null,
        "paragraph": 6
      },
      "extraction_notes": "Temporal constraint structure assumption",
      "extraction_confidence": "high"
    },
    {
      "implicit_id": "IA010",
      "implicit_text": "ML training datasets should be manually produced rather than synthetically generated or bootstrapped from smaller samples",
      "type": "disciplinary_assumption",
      "related_to_claims": [
        "C013"
      ],
      "rationale": "Authors assume ML requires manually produced training data at scale without considering alternative ML approaches (transfer learning, few-shot learning, synthetic data augmentation). This reflects current practice norms.",
      "importance": "low",
      "location": {
        "section": "Discussion",
        "subsection": "4.2",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "ML training approach assumption",
      "extraction_confidence": "medium"
    }
  ],
  "project_metadata": {
    "timeline": {
      "field_seasons": [
        "2017",
        "2018"
      ],
      "prior_efforts": [
        "2010 desktop GIS attempt"
      ],
      "future_plans": [
        "ML model training and comparison"
      ]
    },
    "location": {
      "field_site": "Yambol region, Bulgaria",
      "conditions": "rural Bulgaria, limited internet connectivity"
    },
    "resources": {
      "equipment": "inexpensive mobile devices",
      "outsourcing": "student programmer (AUD $2,000)",
      "software": "FAIMS Mobile platform"
    },
    "track_record": {
      "prior_experience": "2010 desktop GIS digitisation with volunteers showed retention and learning curve challenges",
      "project_context": "TRAP (Tundzha Regional Archaeological Project) ongoing since 2008"
    }
  },
  "research_designs": [
    {
      "design_id": "RD001",
      "design_type": "research_goal",
      "research_questions": [],
      "hypotheses": [],
      "study_design_choice": "Extract archaeological features from historical Soviet military topographic maps (1:50,000 scale, 1980s) to create inventory of burial and settlement mounds",
      "design_rationale": "Maps provided comprehensive coverage predating modern satellite imagery; extraction needed to assess threatened cultural heritage and past landscapes",
      "scope_definition": "Yambol region of Bulgaria; Soviet topographic maps covering ca. 20,000 sq km; targeting burial and settlement mound symbols; 1000+ targeted symbols expected",
      "theoretical_framework": null,
      "reasoning_approach": {
        "approach": "unclear",
        "reasoning_confidence": "low",
        "indicators": [
          "No explicit research questions or hypotheses stated; appears to be data collection/inventory goal"
        ]
      },
      "positionality": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "contingent": false,
      "contingency_conditions": null,
      "enables_methods": [
        "M001",
        "M002",
        "M003"
      ],
      "location": {
        "section": "Methods",
        "subsection": "2.1",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Core research goal for map digitisation work. No formal hypothesis stated. Inventory/documentation goal rather than hypothesis-testing.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Formal research questions",
        "Hypotheses about digitisation effectiveness"
      ]
    },
    {
      "design_id": "RD002",
      "design_type": "study_design_choice",
      "research_questions": [],
      "hypotheses": [],
      "study_design_choice": "Crowdsourcing approach using student field school participants rather than expert digitisation or ML",
      "design_rationale": "Prior 2010 attempt with desktop GIS failed due to volunteer attrition and steep learning curve; staff lacked time for direct digitisation; need for approach enabling novice users to work independently with minimal support",
      "scope_definition": "Students from Arts and Humanities backgrounds with no training in archaeology, cartography, or digital methods; motivated by curiosity about field archaeology, travel, heritage preservation",
      "theoretical_framework": null,
      "reasoning_approach": {
        "approach": "abductive",
        "reasoning_confidence": "medium",
        "indicators": [
          "Responding to 2010 failure (anomaly); seeking best explanation (crowdsourcing with simplified tools) to address observed problems"
        ]
      },
      "positionality": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "contingent": false,
      "contingency_conditions": null,
      "enables_methods": [
        "M002",
        "M003",
        "M004",
        "M005"
      ],
      "location": {
        "section": "Methods",
        "subsection": "2.2",
        "page": null,
        "paragraph": [
          1,
          2,
          3,
          4
        ]
      },
      "extraction_notes": "Key design decision informed by prior failure. Explicitly contrasts with 2010 desktop GIS approach. Abductive reasoning from problem to solution.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Explicit research question about comparative effectiveness",
        "Consideration of alternative solutions",
        "Formal pilot testing"
      ]
    },
    {
      "design_id": "RD003",
      "design_type": "study_design_choice",
      "research_questions": [],
      "hypotheses": [],
      "study_design_choice": "Mobile application platform rather than desktop GIS for crowdsourced digitisation",
      "design_rationale": "Seven factors: (1) offline functionality required for rural Bulgaria field conditions, (2) met functional requirements for geospatial software, (3) test transferability of field data capture usability approaches to digitisation, (4) already using FAIMS for project main activity, (5) student preference for touch-screen interfaces, (6) reduced hardware/licence competition, (7) open-source preference for redeployability and transparency",
      "scope_definition": null,
      "theoretical_framework": "Usability principles from HCI literature: focus on essential tasks, expose key functionality, limit cognitive load, provide feedback, limit error impact. Mobile data collection UI principles: unobtrusive interaction, quick data entry with automation/validation, metadata capture",
      "reasoning_approach": {
        "approach": "deductive",
        "reasoning_confidence": "medium",
        "indicators": [
          "Applying established HCI/usability principles to predict mobile platform would improve volunteer experience and productivity"
        ]
      },
      "positionality": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "contingent": false,
      "contingency_conditions": null,
      "enables_methods": [
        "M003",
        "M004"
      ],
      "location": {
        "section": "Methods",
        "subsection": "2.3",
        "page": null,
        "paragraph": [
          2,
          3,
          4
        ]
      },
      "extraction_notes": "Multi-factor rationale for platform choice. Cites theoretical frameworks from HCI and mobile data collection literature. Deductive application of usability principles.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Systematic comparison of alternative platforms",
        "Quantitative usability metrics for decision",
        "Student preference data cited but not shown"
      ]
    },
    {
      "design_id": "RD004",
      "design_type": "study_design_choice",
      "research_questions": [],
      "hypotheses": [],
      "study_design_choice": "Division of labor: staff handle technical setup and data management, volunteers focus solely on digitisation tasks",
      "design_rationale": "Minimize volunteer friction and training requirements while concentrating technical expertise where needed; enable rapid onboarding and sustained productivity",
      "scope_definition": "Staff: data modeling, system customization, SRS definition, map preparation, server management, quality checking. Volunteers: symbol identification, shape digitisation, attribute transcription",
      "theoretical_framework": null,
      "reasoning_approach": {
        "approach": "deductive",
        "reasoning_confidence": "medium",
        "indicators": [
          "Applying usability principle of task decomposition to predict improved volunteer experience"
        ]
      },
      "positionality": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "contingent": false,
      "contingency_conditions": null,
      "enables_methods": [
        "M004",
        "M005"
      ],
      "location": {
        "section": "Methods",
        "subsection": "2.4",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Workflow design decision creating clear role separation. Task decomposition strategy.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Training materials or protocols",
        "Guidelines for which tasks require staff vs volunteer",
        "Decision criteria for task allocation"
      ]
    },
    {
      "design_id": "RD005",
      "design_type": "study_design_choice",
      "research_questions": [],
      "hypotheses": [],
      "study_design_choice": "Systematic evaluation of digitisation approach through input-output measurement",
      "design_rationale": "Early apparent success prompted decision to document approach effectiveness; part of research program evaluating digital fieldwork approaches",
      "scope_definition": "Inputs: time from programmer, volunteers, staff. Outputs: features digitised. Additional 2018 season confirmation and error characterization.",
      "theoretical_framework": null,
      "reasoning_approach": {
        "approach": "inductive",
        "reasoning_confidence": "medium",
        "indicators": [
          "Emergent decision based on observed success; data collection to identify patterns"
        ]
      },
      "positionality": null,
      "opportunistic": true,
      "opportunistic_notes": "Evaluation plan emerged during 2017 field season when approach appeared successful, not planned a priori",
      "contingent": false,
      "contingency_conditions": null,
      "enables_methods": [
        "M006",
        "M007"
      ],
      "location": {
        "section": "Methods",
        "subsection": "2.5",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Opportunistic design decision emerging during fieldwork. Inductive approach to pattern identification.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Pre-specified success criteria",
        "Formal evaluation framework",
        "Statistical analysis plan"
      ]
    }
  ],
  "methods": [
    {
      "method_id": "M001",
      "method_text": "Identification of target archaeological features from historical map symbols",
      "method_type": "data_collection",
      "sampling_strategy": {
        "sampling_type": "complete_enumeration",
        "target_population": "All burial and settlement mound symbols on Soviet 1:50,000 topographic maps of Yambol region",
        "sampling_frame": "Over 20,000 sq km of georeferenced Soviet military topographic maps (ca. 50 map tiles at 400 sq km each)",
        "coverage": "complete",
        "sampling_justification": "Goal was complete inventory of mounds in region for heritage management and research"
      },
      "data_collection_approach": "Visual identification of specific map symbols indicating burial or settlement mounds",
      "quality_control": null,
      "validation_approach": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "supports_claims": [],
      "location": {
        "section": "Methods",
        "subsection": "2.1",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Core data collection method. Complete enumeration rather than sampling.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Symbol recognition criteria",
        "Disambiguation rules for ambiguous symbols",
        "Inter-rater reliability testing"
      ],
      "implements_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P001",
        "P002"
      ]
    },
    {
      "method_id": "M002",
      "method_text": "Crowdsourcing map digitisation using student field school participants as volunteer workforce",
      "method_type": "data_collection",
      "sampling_strategy": {
        "sampling_type": "convenience",
        "target_population": "Student volunteers",
        "sampling_frame": "Students participating in TRAP field school (Arts and Humanities backgrounds, no GIS/archaeology training)",
        "sample_size": "12 students (only 2 brought computers, all had mobile devices)",
        "sampling_justification": "Convenience sample based on field school participation; motivated by curiosity, travel, heritage preservation"
      },
      "data_collection_approach": "Distributed digitisation by multiple novice volunteers working independently on mobile devices",
      "quality_control": null,
      "validation_approach": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "supports_claims": [],
      "location": {
        "section": "Methods",
        "subsection": "2.2",
        "page": null,
        "paragraph": [
          1,
          2,
          3
        ]
      },
      "extraction_notes": "Crowdsourcing approach contrasted with 2010 desktop GIS failure and staff digitisation alternative.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Volunteer recruitment criteria",
        "Participant demographics",
        "Retention rates",
        "Work allocation strategy"
      ],
      "implements_designs": [
        "RD002",
        "RD001"
      ],
      "realized_through_protocols": [
        "P003",
        "P004",
        "P005"
      ]
    },
    {
      "method_id": "M003",
      "method_text": "Platform selection through comparative assessment of available geospatial software",
      "method_type": "tool_selection",
      "sampling_strategy": null,
      "data_collection_approach": "Evaluated alternative platforms (FAIMS Mobile, ESRI ArcGIS Collector/Field Maps, Survey123) against functional and usability requirements",
      "quality_control": null,
      "validation_approach": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "supports_claims": [],
      "location": {
        "section": "Methods",
        "subsection": "2.3",
        "page": null,
        "paragraph": [
          1,
          2,
          5,
          6
        ]
      },
      "extraction_notes": "Platform selection method. Alternatives explicitly considered: FAIMS Mobile (chosen), ESRI products (rejected).",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Systematic scoring rubric",
        "Quantitative comparison metrics",
        "Formal decision matrix"
      ],
      "implements_designs": [
        "RD002",
        "RD003",
        "RD001"
      ],
      "realized_through_protocols": [
        "P006"
      ]
    },
    {
      "method_id": "M004",
      "method_text": "Customization of FAIMS Mobile platform for map digitisation workflow",
      "method_type": "tool_development",
      "sampling_strategy": null,
      "data_collection_approach": "Junior software developer worked with project staff to customize FAIMS Mobile using definition files to generate tailored Android application",
      "quality_control": null,
      "validation_approach": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "supports_claims": [],
      "location": {
        "section": "Methods",
        "subsection": "2.4",
        "page": null,
        "paragraph": [
          1,
          2,
          3
        ]
      },
      "extraction_notes": "System development method. Creates customized application from platform.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Development methodology",
        "Testing approach",
        "Iteration cycles",
        "User acceptance testing"
      ],
      "implements_designs": [
        "RD003",
        "RD004",
        "RD002"
      ],
      "realized_through_protocols": [
        "P007",
        "P008",
        "P009",
        "P011"
      ]
    },
    {
      "method_id": "M005",
      "method_text": "Streamlined interface design focusing on essential GIS functions for digitisation",
      "method_type": "interface_design",
      "sampling_strategy": null,
      "data_collection_approach": "Stripped GIS functionality to essentials: layer selection, shape digitisation, annotation; hidden/eliminated non-essential features; enabled focus on digitisation without technology distraction",
      "quality_control": null,
      "validation_approach": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "supports_claims": [],
      "location": {
        "section": "Methods",
        "subsection": "2.4",
        "page": null,
        "paragraph": [
          3,
          4
        ]
      },
      "extraction_notes": "UI design method applying simplification principles.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Iterative design process",
        "User feedback incorporation",
        "Design decisions documentation",
        "A/B testing"
      ],
      "implements_designs": [
        "RD004",
        "RD002"
      ],
      "realized_through_protocols": [
        "P012"
      ]
    },
    {
      "method_id": "M006",
      "method_text": "Time-tracking for all participants in digitisation process",
      "method_type": "measurement",
      "sampling_strategy": null,
      "data_collection_approach": "Collated time spent by programmer (timesheets), volunteers (record creation timestamps), and staff (time-on-task journals) for setup, digitisation, support, and quality checking activities",
      "quality_control": null,
      "validation_approach": "2018 season used to confirm 2017 estimates and ensure completeness",
      "opportunistic": false,
      "opportunistic_notes": null,
      "supports_claims": [],
      "location": {
        "section": "Methods",
        "subsection": "2.5",
        "page": null,
        "paragraph": [
          1,
          2
        ]
      },
      "extraction_notes": "Input measurement method for evaluation. Multiple data sources with 2018 validation.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Time-tracking protocols",
        "Granularity of time categories",
        "Treatment of downtime or breaks"
      ],
      "implements_designs": [
        "RD005"
      ],
      "realized_through_protocols": [
        "P014"
      ]
    },
    {
      "method_id": "M007",
      "method_text": "Random sampling of completed digitisation work for error characterization",
      "method_type": "quality_assessment",
      "sampling_strategy": {
        "sampling_type": "random",
        "target_population": "All digitised features",
        "sampling_frame": "10,827 features digitised across both seasons",
        "sample_selection": "Random selection of maps (4 maps selected)",
        "sample_size": "4 maps"
      },
      "data_collection_approach": "Staff review of randomly selected digitisation work to characterize errors",
      "quality_control": null,
      "validation_approach": null,
      "opportunistic": false,
      "opportunistic_notes": null,
      "supports_claims": [],
      "location": {
        "section": "Methods",
        "subsection": "2.5",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Error assessment method using random sampling.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Sample size justification",
        "Sampling procedure details",
        "Error classification scheme",
        "Inter-rater reliability"
      ],
      "implements_designs": [
        "RD005"
      ],
      "realized_through_protocols": [
        "P015"
      ]
    }
  ],
  "protocols": [
    {
      "protocol_id": "P001",
      "protocol_text": "Map material specifications and characteristics",
      "description": "Soviet military 1:50,000 scale topographic maps from 1980s, georeferenced as GeoTIFFs; each map covers ca. 400 sq km; mound symbols at 0.5 per sq km density (average 200 per tile, range 50-400)",
      "tools_equipment": [
        "Georeferenced GeoTIFF maps"
      ],
      "parameters": {
        "map_scale": "1:50,000",
        "map_source": "Soviet military topographic maps",
        "map_date": "1980s",
        "map_format": "GeoTIFF (georeferenced)",
        "tile_coverage": "ca. 400 sq km per map",
        "symbol_density": "average 200 per tile (0.5 per sq km), range 50-400",
        "total_coverage": "over 20,000 sq km",
        "map_source_url": "http://web.uni-plovdiv.bg/vedrin/index_en.html (accessed 2008)"
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M001",
      "location": {
        "section": "Methods",
        "subsection": "2.1",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Detailed map specifications. Source materials protocol.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Map accuracy assessment",
        "Georeferencing error",
        "Original scan resolution"
      ]
    },
    {
      "protocol_id": "P002",
      "protocol_text": "Target symbol and feature specifications",
      "description": "Symbols representing burial or settlement mounds; moderately obtrusive with some shape/color shared with other symbols; target records include point geometry, record number, plus 10 attributes",
      "tools_equipment": null,
      "parameters": {
        "target_features": "burial or settlement mound symbols",
        "symbol_characteristics": "moderately obtrusive, some shape/color overlap with other symbols",
        "geometry_type": "point",
        "attribute_count": "10 attributes plus record number",
        "expected_feature_count": "1,000+ in Yambol region"
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M001",
      "location": {
        "section": "Methods",
        "subsection": "2.1",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Feature and record structure specifications.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Symbol visual examples",
        "Attribute field definitions",
        "Disambiguation criteria",
        "Quality thresholds"
      ]
    },
    {
      "protocol_id": "P003",
      "protocol_text": "Volunteer training protocol for digitisation",
      "description": "Minimal training approach requiring only minutes; students needed only to select files, pan/zoom map, drop points, fill forms; almost no training required",
      "tools_equipment": null,
      "parameters": {
        "training_duration": "minutes",
        "required_skills": "file selection, map pan/zoom, point dropping, form filling",
        "technical_prerequisites": "none (no GIS or computing skills required)"
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M002",
      "location": {
        "section": "Methods",
        "subsection": "2.4",
        "page": null,
        "paragraph": 4
      },
      "extraction_notes": "Minimalist training approach enabled by interface design. Contrasts with desktop GIS training burden.",
      "extraction_confidence": "medium",
      "expected_information_missing": [
        "Training materials",
        "Training script/protocol",
        "Competency verification",
        "Reference documentation provided"
      ]
    },
    {
      "protocol_id": "P004",
      "protocol_text": "Volunteer supervision and support protocol",
      "description": "Staff supervision of students: no more than 30 minutes per season (2017), 30 minutes (2018); minimal ongoing support during digitisation",
      "tools_equipment": null,
      "parameters": {
        "supervision_time_2017": "no more than 30 minutes total",
        "supervision_time_2018": "30 minutes total",
        "support_model": "minimal ongoing support"
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M002",
      "location": {
        "section": "Methods",
        "subsection": "3.1",
        "page": null,
        "paragraph": [
          1,
          2
        ]
      },
      "extraction_notes": "Low-touch supervision approach enabled by system design. Reported in Results but describes Methods protocol.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Support request tracking",
        "Common issues and resolutions",
        "Support availability schedule"
      ]
    },
    {
      "protocol_id": "P005",
      "protocol_text": "Work environment and timing for digitisation activities",
      "description": "Digitisation undertaken as secondary activity during field school; concentrated on rainy days when field survey impossible; 2017: 125.8 person-hours over 5 rainy days; 2018: 58.3 person-hours",
      "tools_equipment": null,
      "parameters": {
        "timing_2017": "5 rainy days, 125.8 person-hours total",
        "timing_2018": "58.3 person-hours total",
        "work_context": "secondary activity during field school",
        "scheduling": "opportunistic (rainy days when survey impossible)"
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": true,
      "contingency_plan": "Digitisation work scheduled for rainy days when outdoor field survey was impossible",
      "implements_method": "M002",
      "location": {
        "section": "Methods",
        "subsection": "3.2",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Contingent scheduling based on weather. Reported in Results but describes Methods-level approach.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Daily work schedules",
        "Break protocols",
        "Maximum continuous work time"
      ]
    },
    {
      "protocol_id": "P006",
      "protocol_text": "Platform evaluation criteria for software selection",
      "description": "Requirements assessed: offline functionality, customizability, UI simplicity, streamlined workflow, layer management, geometry tools, structured data capture, raster import, automated metadata, data validation, touch-screen interface, open-source license, redeployability",
      "tools_equipment": null,
      "parameters": {
        "functional_requirements": [
          "offline operation",
          "layer management",
          "geometry creation and editing",
          "structured data capture",
          "arbitrary raster import (geotiffs)",
          "automated metadata creation",
          "data validation"
        ],
        "usability_requirements": [
          "simple UI",
          "streamlined workflow",
          "touch-screen interface",
          "slippy-map interaction"
        ],
        "organizational_requirements": [
          "consistent with existing tools (FAIMS already in use)",
          "no additional hardware/software costs",
          "leverages existing experience",
          "reduced competition for desktop resources"
        ],
        "philosophical_requirements": [
          "open-source software",
          "customizable via code",
          "redeployable",
          "transparent"
        ]
      },
      "decision_rules": "No existing system met requirements off-the-shelf; competing products lacked sufficient advantages to justify adoption of second system",
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M003",
      "location": {
        "section": "Methods",
        "subsection": "2.3",
        "page": null,
        "paragraph": [
          2,
          3,
          4,
          5
        ]
      },
      "extraction_notes": "Comprehensive evaluation criteria. Multi-dimensional requirements across functional, usability, organizational, philosophical domains.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Weighting of criteria",
        "Minimum thresholds",
        "Scoring method",
        "Decision matrix"
      ]
    },
    {
      "protocol_id": "P007",
      "protocol_text": "FAIMS Mobile customization development protocol",
      "description": "Junior software developer (undergraduate student) worked with project staff to customize FAIMS Mobile; 2017: 35 hours development + 4 hours staff; 2018: 1 hour additional validation development",
      "tools_equipment": [
        "FAIMS Mobile platform",
        "Definition files"
      ],
      "parameters": {
        "developer_role": "undergraduate student programmer",
        "developer_cost": "ca. AUD $2,000",
        "development_time_2017": "35 hours programmer + 4 hours staff",
        "development_time_2018": "1 hour programmer",
        "customization_method": "definition files interpreted by FAIMS Mobile to generate Android application"
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M004",
      "location": {
        "section": "Methods",
        "subsection": "3.1",
        "page": null,
        "paragraph": [
          1,
          2
        ]
      },
      "extraction_notes": "Development resource specifications. Junior developer able to customize platform. Reported in Results but describes Methods protocol.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Development methodology",
        "Version control",
        "Testing approach",
        "Code review process"
      ]
    },
    {
      "protocol_id": "P008",
      "protocol_text": "Seven-stage implementation workflow",
      "description": "Stage 1: staff model data and workflow; Stage 2: developer customizes system; Stage 3: staff define SRS and import maps; Stage 4: volunteers digitise shapes; Stage 5: volunteers transcribe attributes; Stage 6: staff export data; Stage 7: staff check accuracy",
      "tools_equipment": null,
      "parameters": {
        "workflow_stages": 7,
        "staff_stages": [
          1,
          3,
          6,
          7
        ],
        "developer_stages": [
          2
        ],
        "volunteer_stages": [
          4,
          5
        ]
      },
      "decision_rules": "Technical expertise concentrated in staff/developer stages; simplified volunteer tasks",
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M004",
      "location": {
        "section": "Methods",
        "subsection": "2.4",
        "page": null,
        "paragraph": 1
      },
      "extraction_notes": "Complete workflow specification with clear role assignments.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Stage transition criteria",
        "Quality gates",
        "Iteration/feedback loops"
      ]
    },
    {
      "protocol_id": "P009",
      "protocol_text": "System preparation workflow: server and client setup, map preprocessing (tiling, pyramids), and distribution",
      "description": "Complete system preparation across both seasons. 2017: 3h server/client setup + 1.5h map tiling/pyramids + 2.5h file compression/transfer = 7h total. 2018: 1h reuse setup + 0.5h map prep + 1.5h transfer = 3h total. Activities include server configuration, client device configuration, map tiling, pyramid generation, file compression, server upload, and device download.",
      "tools_equipment": [
        "FAIMS Mobile server",
        "Android client devices"
      ],
      "parameters": {
        "setup_time_2017": "3 hours server/client configuration",
        "setup_time_2018": "1 hour (reusing equipment)",
        "map_prep_time_2017": "1.5 hours tiling/pyramids + 2.5 hours transfer = 4 hours",
        "map_prep_time_2018": "0.5 hours tiling/pyramids + 1.5 hours transfer = 2 hours",
        "total_prep_time_2017": "7 hours",
        "total_prep_time_2018": "3 hours",
        "preparation_activities": [
          "server configuration",
          "client device configuration",
          "map tiling",
          "pyramid generation",
          "file compression",
          "server upload",
          "device download"
        ]
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M004",
      "location": {
        "section": "Methods",
        "subsection": "3.1",
        "page": null,
        "paragraph": [
          1,
          2
        ]
      },
      "extraction_notes": "Consolidated from P009 (setup) and P010 (map prep). Sequential workflow steps assessed together. Year-over-year efficiency improvements documented (7h \u2192 3h).",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Setup checklist",
        "Configuration parameters",
        "Testing procedures",
        "Tiling parameters",
        "Pyramid levels",
        "Compression algorithm",
        "Quality checks"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "P009",
          "P010"
        ],
        "consolidation_type": "workflow_integration",
        "information_preserved": "complete",
        "granularity_available": "Original items separated setup (P009: 3h/1h) and map preparation (P010: 4h/2h) activities. Both are sequential steps in system preparation workflow.",
        "rationale": "System setup and map preparation are sequential steps in the same preparation workflow and would be assessed together for completeness and replicability. Consolidation improves coherence while preserving all time measurements and activities. Assessed together: 'Was the system adequately prepared for field deployment?'"
      }
    },
    {
      "protocol_id": "P011",
      "protocol_text": "Automated system capabilities",
      "description": "System automated: SRS application, map rendering, layer management with data entry layer, shape topology enforcement, controlled vocabulary display, creation time/author recording, data change history, validation for completeness, multi-device data merging, common format export",
      "tools_equipment": null,
      "parameters": {
        "automated_functions": [
          "spatial reference system application",
          "map rendering in workspace",
          "layer management including data entry layer",
          "shape topology enforcement",
          "controlled vocabulary display",
          "creation timestamp and author metadata",
          "change history maintenance",
          "completeness validation",
          "multi-device data merging",
          "export to common formats"
        ]
      },
      "decision_rules": null,
      "recording_standards": "FAIR data principles: rich and plural metadata at creation time (F2, R1.1-1.3)",
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M004",
      "location": {
        "section": "Methods",
        "subsection": "2.4",
        "page": null,
        "paragraph": 2
      },
      "extraction_notes": "Comprehensive automation features reducing volunteer workload and ensuring data quality.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Validation rules specification",
        "Merge conflict resolution",
        "Export format options"
      ]
    },
    {
      "protocol_id": "P012",
      "protocol_text": "Interface design specifications: dual-view system (map/form toggle) with minimalist control set",
      "description": "Streamlined interface with two complementary design principles: (1) Dual-view system: volunteers toggle between map view (geospatial interactions: layer focus/visibility, pan, zoom, shape digitisation) and form view (attribute creation/editing); (2) Control minimization: only essential controls exposed (layer management, map navigation, record search/retrieval, shape creation/editing, attribute creation/editing); non-digitisation GIS features hidden/eliminated; infrastructure functions (setup, layer config, aggregation, export, backup) restricted to staff.",
      "tools_equipment": null,
      "parameters": {
        "view_modes": [
          "map view",
          "form view"
        ],
        "map_view_functions": [
          "layer focus adjustment",
          "layer visibility control",
          "pan",
          "zoom",
          "shape digitisation"
        ],
        "form_view_functions": [
          "attribute creation",
          "attribute editing",
          "data entry"
        ],
        "interaction_model": "toggle between views",
        "exposed_controls": [
          "layer management",
          "map navigation",
          "record search and retrieval",
          "shape creation and editing",
          "attribute creation and editing"
        ],
        "hidden_functions": "non-digitisation GIS features",
        "staff_only_functions": [
          "infrastructure setup",
          "layer management (configuration)",
          "data aggregation",
          "export",
          "backup"
        ],
        "design_principles": [
          "strip to essentials",
          "hide/eliminate non-essential features",
          "concentrate complexity in staff roles",
          "reduce cognitive load"
        ]
      },
      "decision_rules": "Strip to essentials; hide/eliminate non-essential features; concentrate complexity in staff roles",
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M005",
      "location": {
        "section": "Methods",
        "subsection": "2.4",
        "page": null,
        "paragraph": [
          2,
          3,
          4
        ]
      },
      "extraction_notes": "Consolidated from P012 (dual view) and P013 (minimization). Complementary interface design principles assessed together as unified design approach.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "View switching mechanism",
        "Default view",
        "State preservation between views",
        "Specific features hidden",
        "UI layout specifications",
        "Interaction patterns"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "P012",
          "P013"
        ],
        "consolidation_type": "parameter_integration",
        "information_preserved": "complete",
        "granularity_available": "Original items separated dual-view system (P012: map/form toggle) and control minimization (P013: essential controls only, hide non-essential). Both are complementary aspects of single interface design.",
        "rationale": "Dual-view system and control minimization are complementary aspects of the unified interface design approach and would be assessed together for usability and effectiveness. Both serve same goal: simplify volunteer experience by reducing cognitive load. Assessed together: 'Was the interface design appropriate for novice users?'"
      }
    },
    {
      "protocol_id": "P014",
      "protocol_text": "Time tracking data sources and procedures",
      "description": "Three data sources: (1) programmer timesheets, (2) record creation timestamps from devices for volunteers, (3) staff time-on-task journals for configuration, support, export, checking",
      "tools_equipment": [
        "Timesheets",
        "Device timestamps",
        "Time-on-task journals"
      ],
      "parameters": {
        "programmer_tracking": "timesheets",
        "volunteer_tracking": "automated record creation timestamps",
        "staff_tracking": "time-on-task journals"
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": "2018 season confirmed 2017 estimates and ensured record completeness",
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M006",
      "location": {
        "section": "Methods",
        "subsection": "2.5",
        "page": null,
        "paragraph": 2
      },
      "extraction_notes": "Multi-source time tracking with validation. Automated volunteer tracking via system logs.",
      "extraction_confidence": "high",
      "expected_information_missing": [
        "Timestamp precision",
        "Journal format",
        "Time category definitions",
        "Rounding conventions"
      ]
    },
    {
      "protocol_id": "P015",
      "protocol_text": "Error checking protocol through random map review",
      "description": "Staff reviewed randomly selected digitisation work from volunteers to characterize errors; 4 randomly selected maps examined; 6 hours staff time for examination including desktop GIS setup, feature confirmation, error tabulation",
      "tools_equipment": [
        "Desktop GIS"
      ],
      "parameters": {
        "sample_size": "4 maps",
        "sampling_method": "random selection",
        "review_time": "6 hours staff time",
        "review_activities": [
          "desktop GIS setup",
          "feature digitisation confirmation",
          "error tabulation",
          "error rate calculation"
        ]
      },
      "decision_rules": null,
      "recording_standards": null,
      "measurement_protocol": null,
      "contingent": false,
      "contingency_plan": null,
      "implements_method": "M007",
      "location": {
        "section": "Methods",
        "subsection": "3.1",
        "page": null,
        "paragraph": 3
      },
      "extraction_notes": "Post-hoc quality assessment. Random sampling for error characterization. Reported in Results but describes protocol.",
      "extraction_confidence": "medium",
      "expected_information_missing": [
        "Error classification scheme",
        "Error definition",
        "Acceptance criteria",
        "Correction procedures"
      ]
    }
  ],
  "extraction_notes": {
    "pass": 2,
    "workflow_stage": "RDMAP Pass 2 - Rationalization",
    "section_extracted": "Methods (Section 2: Subsections 2.1-2.5)",
    "prior_extraction": "Discussion section (evidence, claims, implicit arguments from Pass 2); Methods section (RDMAP from Pass 1)",
    "items_before_rationalization": 27,
    "items_after_rationalization": 25,
    "reduction_count": 2,
    "reduction_percentage": 7.4,
    "rdmap_breakdown": {
      "research_designs": {
        "before": 5,
        "after": 5,
        "change": 0
      },
      "methods": {
        "before": 7,
        "after": 7,
        "change": 0
      },
      "protocols": {
        "before": 15,
        "after": 13,
        "change": -2
      }
    },
    "consolidations_performed": 2,
    "tier_corrections": 0,
    "boundary_corrections": 0,
    "consolidation_summary": {
      "protocol_consolidations": [
        "P009 + P010 \u2192 P009: System preparation workflow (setup + map prep)",
        "P012 + P013 \u2192 P012: Interface design specifications (dual-view + minimization)"
      ]
    },
    "rationalization_approach": "Conservative consolidation focusing on sequential workflow steps and complementary design principles",
    "key_decisions": {
      "below_target_reduction": "7.4% reduction below 15-20% target because Methods section was well-scoped in Pass 1; minimal over-extraction to consolidate. Better to preserve appropriate granularity than force consolidations.",
      "tier_stability": "All tier assignments verified as correct; no moves required",
      "consolidation_philosophy": "Applied acid test: 'Would I assess these together or separately?' Only consolidated items assessed together.",
      "information_preservation": "All consolidations preserve complete information with full traceability via metadata",
      "cross_references_valid": "All Design\u2192Method and Method\u2192Protocol references verified bidirectional and accurate"
    },
    "quality_verification": {
      "no_information_loss": "Verified - all consolidations marked 'complete' information preservation",
      "all_consolidation_metadata_complete": "Verified - both consolidations have complete metadata with rationale",
      "tier_assignments_accurate": "Verified - WHY/WHAT/HOW distinctions maintained",
      "cross_references_bidirectional": "Verified - all Design\u2192Method and Method\u2192Protocol links bidirectional",
      "boundary_accuracy": "Verified - Methods section descriptive (RDMAP), not argumentative (Claims)",
      "reasoning_approaches_consistent": "Verified - all 5 research designs have consistent reasoning classification",
      "expected_information_flagged": "Verified - all RDMAP items have appropriate missing information documented",
      "other_arrays_untouched": "Verified - evidence, claims, implicit_arguments unchanged from Discussion Pass 2",
      "location_fields_preserved": "Verified - all location information maintained through consolidation"
    },
    "pass_2_summary": {
      "consolidation_types_used": [
        "workflow_integration",
        "parameter_integration"
      ],
      "consolidation_rationale": "Sequential workflow steps (prep) and complementary design principles (interface)",
      "items_requiring_no_consolidation": "Research Designs (all distinct strategic decisions), Methods (all distinct tactical approaches), Most protocols (distinct operational procedures)",
      "granularity_appropriate": "Final granularity matches assessment needs - can evaluate each RDMAP item independently for transparency/replicability"
    },
    "ready_for_pass_3": true,
    "pass_3_focus": "Validation of structural integrity and cross-reference consistency across all arrays",
    "pass_3_correction": {
      "correction_applied": "Field naming standardization",
      "date": "2025-10-20",
      "changes": [
        "Renamed 'design_context' to 'implements_designs' in all Methods",
        "Renamed 'uses_protocols' to 'realized_through_protocols' in all Methods"
      ],
      "reason": "Schema v2.4 compliance - original extraction used non-standard field names",
      "data_integrity": "No data modified - only field names changed for schema compliance"
    }
  }
}