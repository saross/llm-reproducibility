{
  "schema_version": "2.5",
  "project_metadata": {
    "paper_title": "Validating predictions of burial mounds with field data: the promise and reality of machine learning",
    "authors": [
      "Adela Sobotkova",
      "Ross Deans Kristensen-McLachlan",
      "Orla Mallon",
      "Shawn Adrian Ross"
    ],
    "publication_year": 2024,
    "journal": "Journal of Documentation",
    "doi": "10.1108/JD-05-2022-0096",
    "paper_type": "research article",
    "discipline": "archaeology",
    "research_context": "This study validates machine learning (Convolutional Neural Network) predictions of burial mounds against field survey data in the Kazanlak Valley, Central Bulgaria. The research evaluates the effectiveness, time, expertise, and resource requirements of using pre-trained CNNs for archaeological prospection in heterogeneous landscapes."
  },
  "evidence": [
    {
      "evidence_id": "E001",
      "evidence_text": "False negative rates were 95-96% of tiles",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "false negative rates were 95–96%",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C002",
        "C003",
        "C004"
      ]
    },
    {
      "evidence_id": "E002",
      "evidence_text": "False positive rates were 87-95% of tagged tiles",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "false positive rates were 87–95% of tagged tiles",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C002",
        "C003",
        "C004"
      ]
    },
    {
      "evidence_id": "E003",
      "evidence_text": "True positives were only 5-13% of tagged tiles",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "true positives were only 5–13%",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C002"
      ]
    },
    {
      "evidence_id": "E004",
      "evidence_text": "Model development required approximately 135 person-hours of work",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Development of the model, meanwhile, required approximately 135 person-hours of work.",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "uncertainty_declared": true,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C004",
        "C027",
        "C028"
      ]
    },
    {
      "evidence_id": "E005",
      "evidence_text": "Model provided with training data for highly visible mounds performed worse than model with all mounds",
      "evidence_type": "comparative_observation",
      "evidence_status": "explicit",
      "verbatim_quote": "Counterintuitively, the model provided with training data selected for highly visible mounds (rather than all mounds) performed worse.",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C001",
        "C002"
      ]
    },
    {
      "evidence_id": "E006",
      "evidence_text": "High success rates reported for burial mound detection in Siberia",
      "evidence_type": "literature_reference",
      "evidence_status": "explicit",
      "verbatim_quote": "High success rates reported for detecting and monitoring burial mounds in Siberia have highlighted CNNs as an effective approach for large-scale prospection (Caspari and Crespo, 2019).",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C006"
      ]
    },
    {
      "evidence_id": "E007",
      "evidence_text": "Siberian burial mounds are uniform features in environments with little vegetation or confounding factors",
      "evidence_type": "contextual_observation",
      "evidence_status": "explicit",
      "verbatim_quote": "Enthusiasm arising from this study, and similar outcomes from Egypt (Woolf, 2018) must, however, be tempered by the fact that the authors targeted uniform features situated in environments with little variation in terrain or vegetation – indeed, with relatively little vegetation or other confounding factors at all.",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C001",
        "C006"
      ]
    },
    {
      "evidence_id": "E008",
      "evidence_text": "Linear road feature classification with pre-trained model required 1,250 hours to digitise and annotate training datasets",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Correct classification of linear road features with a pre-trained model required 1,250 h to digitise and annotate training datasets (Can et al., 2021, p. 62,847).",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 2
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C007"
      ]
    },
    {
      "evidence_id": "E009",
      "evidence_text": "Estimates of surviving Bulgarian burial mounds range between 8,000-19,000 today, of perhaps 50,000 originally constructed",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Thousands of such mounds exist in the country; estimates range between 8,000 – 19,000 surviving today, of perhaps 50,000 originally constructed (Kitov, 1993, pp. 41–43; Shkorpil and Shkorpil, 1989, p. 20).",
      "location": {
        "section": "Burial mounds as heritage under threat",
        "subsection": null,
        "paragraph": 1
      },
      "uncertainty_declared": true,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C009"
      ]
    },
    {
      "evidence_id": "E010",
      "evidence_text": "Burial mounds vary in diameter from 10m to 100m and <1m to >20m in height",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "These rounded, conical piles of earth and stones vary in diameter from 10 m to 100 m and <1 m to >20 m in height (see Plates 1 and 2).",
      "location": {
        "section": "Burial mounds as heritage under threat",
        "subsection": null,
        "paragraph": 2
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C001",
        "C010",
        "C021"
      ]
    },
    {
      "evidence_id": "E011",
      "evidence_text": "In 2008, burial mounds comprised nearly a quarter (57 of 257) of all excavations in Bulgaria",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "In 2008, the last year for which data is available, burial mounds comprised nearly a quarter (57 of 257) of all excavations in Bulgaria (Cholakov and Chukalev, 2008, p. 91, Figure 2).",
      "location": {
        "section": "Burial mounds as heritage under threat",
        "subsection": null,
        "paragraph": 3
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C011",
        "C009"
      ]
    },
    {
      "evidence_id": "E012",
      "evidence_text": "Authors inventoried over 2,000 burial mounds across two Bulgarian provinces",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "In the course of nearly 20 years of intermittent fieldwork in Bulgaria, the authors have seen few examples of mounds that had not been damaged either by development, looting, or agriculture, despite having inventoried over 2,000 of them across two Bulgarian provinces (Ross et al., 2010, 2018; Sobotkova and Weissova, 2020).",
      "location": {
        "section": "Burial mounds as heritage under threat",
        "subsection": null,
        "paragraph": 5
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C012"
      ]
    },
    {
      "evidence_id": "E013",
      "evidence_text": "Large mounds in flat landscapes with surface contrast are more visible than small mounds in hilly landscapes",
      "evidence_type": "comparative_observation",
      "evidence_status": "explicit",
      "verbatim_quote": "Large mounds in flat landscapes where a mound's surface contrasts with surrounding land cover (Figure 1a, b, e) are more visible than small mounds in hilly landscapes where their surfaces blend into the surroundings (Figure 1g-i).",
      "location": {
        "section": "Detecting archaeological features in satellite imagery",
        "subsection": null,
        "paragraph": 2
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C001",
        "C010"
      ]
    },
    {
      "evidence_id": "E014",
      "evidence_text": "Annual count of ML+archaeology publications increased from zero in 2014-2015 to 21 in 2023",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "This search reveals that the annual count of relevant publications has increased from zero in 2014 and 2015 to 21 in 2023.",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 3
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C013"
      ]
    },
    {
      "evidence_id": "E015",
      "evidence_text": "21 ML publications in 2023 represent 17% of total archaeological remote sensing publications (n=125)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "These 21 publications represent about 17% of the 2023 total (n 5 125) for archaeological remote sensing",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 3
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C013"
      ]
    },
    {
      "evidence_id": "E016",
      "evidence_text": "63% of ML-for-archaeology paper abstracts fail to mention any negative aspects",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Considering the 70 papers from the Web of Science mentioned above, 44 abstracts (63%) fail to mention any negative aspects of AI/ML approaches at all.",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 5
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C014",
        "C015"
      ]
    },
    {
      "evidence_id": "E017",
      "evidence_text": "Of 26 papers mentioning challenges, 11 state challenges were overcome (unqualified successes)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Of the 26 papers (37%) with abstracts that mention some challenge or limitation, 11 state that they were overcome by the researchers, representing unqualified successes.",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 5
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C014",
        "C015"
      ]
    },
    {
      "evidence_id": "E018",
      "evidence_text": "Only 6% of papers (4 of 70) discuss attempts ending in partial or complete failures",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Of those 15, seven (10% of the corpus) present qualified successes, while four (6%) discuss attempts to deploy ML that ended in partial or complete failures",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 5
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C014",
        "C015"
      ]
    },
    {
      "evidence_id": "E019",
      "evidence_text": "TRAP survey collected dataset of 773 mounds during 2009-2011 fieldwork in Kazanlak Valley",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "In this study we used a dataset of 773 mounds, collected by TRAP during 2009 – 2011 field survey in the Kazanlak Valley, Bulgaria",
      "location": {
        "section": "Data",
        "subsection": "Pedestrian survey",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C016"
      ]
    },
    {
      "evidence_id": "E020",
      "evidence_text": "TRAP fieldwork covered 85 sq km via pedestrian survey",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "This fieldwork covered some 85 sq km, inspected directly via pedestrian survey.",
      "location": {
        "section": "Data",
        "subsection": "Pedestrian survey",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C016"
      ]
    },
    {
      "evidence_id": "E021",
      "evidence_text": "Satellite imagery consists of two IKONOS scenes covering 600 sq km",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "The satellite imagery used in this study consists of two IKONOS scenes covering 600 sq km delivered in geoTIFF format",
      "location": {
        "section": "Data",
        "subsection": "Satellite imagery",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C016"
      ]
    },
    {
      "evidence_id": "E022",
      "evidence_text": "IKONOS imagery included panchromatic band at 1m resolution and multispectral (RGBNIR) at 4m resolution",
      "evidence_type": "technical_specification",
      "evidence_status": "explicit",
      "verbatim_quote": "The scenes included a panchromatic band at 1 m resolution and a multispectral image (RGBNIR) at 4 m resolution.",
      "location": {
        "section": "Data",
        "subsection": "Satellite imagery",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C016"
      ]
    },
    {
      "evidence_id": "E023",
      "evidence_text": "Used ResNet-50 pre-trained CNN with ~25.6m trainable parameters",
      "evidence_type": "technical_specification",
      "evidence_status": "explicit",
      "verbatim_quote": "After some preliminary experimentation with a range of different pre-trained models, we concluded that ResNet-50 seemed to perform best for our data. This model is one of the smaller pre-trained CNNs available, with only around 25.6m trainable parameters",
      "location": {
        "section": "Methods",
        "subsection": "Transfer learning",
        "paragraph": 4
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C017"
      ]
    },
    {
      "evidence_id": "E024",
      "evidence_text": "Training data consisted of 773 MOUND cutouts generated from mound points",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Mound points taken during fieldwork were used as centroids for the generation of 150 3 150 m square polygons (150 3 150 pixels at 1 m resolution), which were clipped from the IKONOS imagery. This process yielded 773 MOUND cutouts, each centred on a mound",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C017"
      ]
    },
    {
      "evidence_id": "E025",
      "evidence_text": "Training data ratio was approximately 1:2 positive to negative (32%-68%)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "The ratio of positive to negative training data was approximately 1:2 (32%–68%).",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C017"
      ]
    },
    {
      "evidence_id": "E026",
      "evidence_text": "2021 run used all 773 cutouts regardless of visibility, 2022 run used 249 cutouts where mound was discernible",
      "evidence_type": "comparative_specification",
      "evidence_status": "explicit",
      "verbatim_quote": "In the 2021 run of the model, we used all 773 cutouts for training regardless of what was visible in the satellite image. In the 2022 run, we selected 249 cutouts where a mound was discernible with the naked eye.",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C018"
      ]
    },
    {
      "evidence_id": "E027",
      "evidence_text": "Training cutouts divided 70:20:10 ratio for training, validation, and test sets",
      "evidence_type": "technical_specification",
      "evidence_status": "explicit",
      "verbatim_quote": "After processing, cutouts were divided into training, validation, and test sets following a 70:20:10 ratio for automated performance validation.",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C017"
      ]
    },
    {
      "evidence_id": "E028",
      "evidence_text": "2021 model reported F1 score of 0.87",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "After image augmentation, the model reported good learning and model fit (F1 5 0.87).",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C018"
      ]
    },
    {
      "evidence_id": "E029",
      "evidence_text": "2021 model: only 19 of 148 tagged tiles (12.8%) actually contained mounds",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Nevertheless, only 19 out of 148 tiles (12.8%) tagged by the model with at least a 60% chance of having a mound actually contained one",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C018"
      ]
    },
    {
      "evidence_id": "E030",
      "evidence_text": "2021 model: 129 of 148 tagged tiles (87.1%) were false positives",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Some 129 of the tagged tiles (87.1%) were false positives.",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C018"
      ]
    },
    {
      "evidence_id": "E031",
      "evidence_text": "2021 model: 38 of 773 mounds detected (4.9%), 735 went undetected",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "The 19 true-positive tiles contained 38 mounds (1–9 mounds per tile), out of 773 in the study area (4.9%), while the remaining 735 mounds went undetected.",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C018"
      ]
    },
    {
      "evidence_id": "E032",
      "evidence_text": "2021 model: false negative rate of 95.3% (381 of 400 tiles containing mounds)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Undetected mounds were located in 381 tiles (1–20 mounds per tile) out of 400 tiles that actually contained mounds, a false negative rate of 95.3%",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C018"
      ]
    },
    {
      "evidence_id": "E033",
      "evidence_text": "2022 model reported F1 score of 0.62 (decline from 2021)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "The second model's performance declined to an F1 score of 0.62",
      "location": {
        "section": "Results",
        "subsection": "Second run (2022)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C018",
        "C020"
      ]
    },
    {
      "evidence_id": "E034",
      "evidence_text": "2022 model: only 21 of 773 mounds detected (2.7%), 752 went undetected (97.3%)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Validation revealed that only 21 of 773 mounds (2.7%) were detected, while 752 mounds (97.3%) remained undetected.",
      "location": {
        "section": "Results",
        "subsection": "Second run (2022)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C020"
      ]
    },
    {
      "evidence_id": "E035",
      "evidence_text": "2022 model: flagged 288 tiles vs 148 in 2021 run",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "The number of tiles within the TRAP study area flagged as containing a mound (at a >60% probability) increased from 148 in the first run to 288 here.",
      "location": {
        "section": "Results",
        "subsection": "Second run (2022)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C020"
      ]
    },
    {
      "evidence_id": "E036",
      "evidence_text": "2022 model: only 15 of 288 flagged tiles (5.2%) were true positives",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "Only 15 of these 288 tiles (5.2%), however, were true positives, containing the 21 detected mounds (1–4 mounds per tile; see Figure 6).",
      "location": {
        "section": "Results",
        "subsection": "Second run (2022)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C020"
      ]
    },
    {
      "evidence_id": "E037",
      "evidence_text": "2022 model: 273 of 288 flagged tiles were false positives (94.8%)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "The remaining 273 of 288 tiles were false positives (94.8%).",
      "location": {
        "section": "Results",
        "subsection": "Second run (2022)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C020"
      ]
    },
    {
      "evidence_id": "E038",
      "evidence_text": "2022 model: false negative rate of 96.2% (384 of 399 tiles containing mounds)",
      "evidence_type": "quantitative_measurement",
      "evidence_status": "explicit",
      "verbatim_quote": "The undetected 752 mounds lay in 384 tiles (1–28 mounds per tile) out of 399 tiles that actually contained mounds, a false negative rate of 96.2%",
      "location": {
        "section": "Results",
        "subsection": "Second run (2022)",
        "paragraph": 1
      },
      "uncertainty_declared": false,
      "uncertainty_missing": false,
      "confidence_declared": false,
      "supports_claims": [
        "C020"
      ]
    }
  ],
  "claims": [
    {
      "claim_id": "C001",
      "claim_text": "Pre-trained CNNs have significant limitations when detecting varied features of different sizes within heterogeneous landscapes containing confounding natural and modern features",
      "claim_type": "finding",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "Our attempt to deploy a pre-trained CNN demonstrates the limitations of this approach when it is used to detect varied features of different sizes within a heterogeneous landscape that contains confounding natural and modern features, such as roads, forests and field boundaries.",
      "location": {
        "section": "Abstract",
        "subsection": "Research limitations/implications",
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E005",
        "E007",
        "E010",
        "E013"
      ]
    },
    {
      "claim_id": "C002",
      "claim_text": "The pre-trained CNN model failed to identify burial mounds in the Kazanlak Valley study area",
      "claim_type": "finding",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "Indeed, both models failed to identify burial mounds in our study area.",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [
        "C006"
      ],
      "supported_by": [
        "E001",
        "E002",
        "E003",
        "E005"
      ]
    },
    {
      "claim_id": "C003",
      "claim_text": "External validation with field data is an essential part of CNN workflows",
      "claim_type": "methodological",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "The model has detected incidental features rather than the mounds themselves, making external validation with field data an essential part of CNN workflows.",
      "location": {
        "section": "Abstract",
        "subsection": "Research limitations/implications",
        "paragraph": 1
      },
      "supported_by_claims": [
        "C002"
      ],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E001",
        "E002"
      ]
    },
    {
      "claim_id": "C004",
      "claim_text": "Manual inspection by experts or crowdsourcing may be more efficient than ML for identifying burial mounds",
      "claim_type": "recommendation",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "The degree of manual intervention required – particularly around the subsetting and annotation of training data – is so significant that it raises the question of whether it would be more efficient to identify all of the mounds manually, either through brute-force inspection by experts or by crowdsourcing the analysis to trained – or even untrained – volunteers.",
      "location": {
        "section": "Abstract",
        "subsection": "Practical implications",
        "paragraph": 1
      },
      "supported_by_claims": [
        "C002"
      ],
      "supports_claims": [],
      "alternatives_mentioned": true,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E001",
        "E002",
        "E004"
      ]
    },
    {
      "claim_id": "C005",
      "claim_text": "ML-for-archaeology literature is overwhelmingly positive, reflecting publication bias and rhetoric of unconditional success",
      "claim_type": "methodological_critique",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "The literature itself, however, is overwhelmingly positive, reflecting some combination of publication bias and a rhetoric of unconditional success.",
      "location": {
        "section": "Abstract",
        "subsection": "Social implications",
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [
        "reflecting some combination of"
      ],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C006",
      "claim_text": "CNNs have been promoted as effective for large-scale archaeological prospection",
      "claim_type": "literature_synthesis",
      "claim_role": "intermediate",
      "claim_status": "explicit",
      "verbatim_quote": "High success rates reported for detecting and monitoring burial mounds in Siberia have highlighted CNNs as an effective approach for large-scale prospection (Caspari and Crespo, 2019).",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E006"
      ]
    },
    {
      "claim_id": "C007",
      "claim_text": "ML applied to archaeological prospection can be labour-intensive",
      "claim_type": "finding",
      "claim_role": "intermediate",
      "claim_status": "explicit",
      "verbatim_quote": "Although few publications report the time, expertise, or costs associated with applying ML to archaeological prospection, examples from projects trying to extract symbols and text from historical maps indicate that it can be labour-intensive (Can et al., 2021; Ekim et al., 2021; Ma et al., 2021).",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C004"
      ],
      "alternatives_mentioned": false,
      "qualifications": [
        "can be"
      ],
      "contradicts": [],
      "supported_by": [
        "E008"
      ]
    },
    {
      "claim_id": "C008",
      "claim_text": "Transfer learning with pre-trained models is proposed as solution to limited training data and small dataset size problems",
      "claim_type": "literature_synthesis",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Transfer learning based on pre-trained models is sometimes proposed as solution to the problem of limited training data, as well as related problems like small dataset size (Casini et al., 2021, 2022; Character et al., 2021; Gallwey et al., 2019; Sech et al., 2023; Xiong et al., 2020).",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [
        "sometimes proposed"
      ],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C009",
      "claim_text": "Burial mounds are endangered heritage in Bulgaria",
      "claim_type": "contextual",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Despite the large number of burial mounds, they are endangered.",
      "location": {
        "section": "Burial mounds as heritage under threat",
        "subsection": null,
        "paragraph": 3
      },
      "supported_by_claims": [
        "C011",
        "C012"
      ],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E009",
        "E011"
      ]
    },
    {
      "claim_id": "C010",
      "claim_text": "Burial mound visibility in satellite imagery depends on size, terrain, and land cover",
      "claim_type": "finding",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "While burial mounds are readily identifiable on the ground due to their distinctive appearance, their visibility in satellite imagery depends on their size, surrounding terrain, and local land cover (see Figure 1).",
      "location": {
        "section": "Detecting archaeological features in satellite imagery",
        "subsection": null,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C001"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E010",
        "E013"
      ]
    },
    {
      "claim_id": "C011",
      "claim_text": "Development in Bulgaria destroys dozens of mounds annually",
      "claim_type": "contextual",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Development in Bulgaria destroys dozens of mounds annually (Loulanski and Loulanski, 2017).",
      "location": {
        "section": "Burial mounds as heritage under threat",
        "subsection": null,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C009"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E011"
      ]
    },
    {
      "claim_id": "C012",
      "claim_text": "Few examples of undamaged burial mounds exist despite extensive inventory work",
      "claim_type": "finding",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "In the course of nearly 20 years of intermittent fieldwork in Bulgaria, the authors have seen few examples of mounds that had not been damaged either by development, looting, or agriculture, despite having inventoried over 2,000 of them across two Bulgarian provinces (Ross et al., 2010, 2018; Sobotkova and Weissova, 2020).",
      "location": {
        "section": "Burial mounds as heritage under threat",
        "subsection": null,
        "paragraph": 5
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C009"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E012"
      ]
    },
    {
      "claim_id": "C013",
      "claim_text": "AI/ML approaches to archaeological remote sensing are on cusp of crossing the chasm from early adopters to early majority",
      "claim_type": "finding",
      "claim_role": "intermediate",
      "claim_status": "explicit",
      "verbatim_quote": "If publication counts are used a proxy for research, this 17% figure indicates that AI/ML is on the cusp of \\\"crossing the chasm\\\" separating \\\"innovators\\\" and \\\"early adopters\\\" (together 16% of the population) from the \\\"early majority\\\", according to Rogers' diffusion of innovations paradigm as modified by Moore",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C005"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E014",
        "E015"
      ]
    },
    {
      "claim_id": "C014",
      "claim_text": "Critical assessment has been neglected in ML-for-archaeology literature",
      "claim_type": "methodological_critique",
      "claim_role": "intermediate",
      "claim_status": "explicit",
      "verbatim_quote": "As these approaches spread to a broader cohort of researchers, potential adopters need to recognise their challenges and limitations. Critical assessment has, however, been somewhat neglected in the literature.",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 5
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C005"
      ],
      "alternatives_mentioned": false,
      "qualifications": [
        "somewhat neglected"
      ],
      "contradicts": [],
      "supported_by": [
        "E016",
        "E017",
        "E018"
      ]
    },
    {
      "claim_id": "C015",
      "claim_text": "Overwhelmingly positive tone of ML papers indicates publication bias and rhetorical shift toward less qualified presentation",
      "claim_type": "methodological_critique",
      "claim_role": "intermediate",
      "claim_status": "explicit",
      "verbatim_quote": "The overwhelmingly positive tone of these papers likely indicates a certain degree of \\\"publication bias\\\", where positive results are more likely to be published than negative (Brown et al., 2017; Dickersin et al., 1987; Harrison et al., 2017; Ioannidis, 2005; Kühberger et al., 2014; Møller and Jennions, 2001), or at the very least a reflection of the rhetorical shift in scientific research towards less qualified or uncertain presentation of outcomes",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 5
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C005"
      ],
      "alternatives_mentioned": true,
      "qualifications": [
        "likely indicates"
      ],
      "contradicts": [],
      "supported_by": [
        "E016",
        "E017",
        "E018"
      ]
    },
    {
      "claim_id": "C016",
      "claim_text": "Study used comprehensive field and satellite data from Kazanlak Valley for validation",
      "claim_type": "methodological",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "In this study we used a dataset of 773 mounds, collected by TRAP during 2009 – 2011 field survey in the Kazanlak Valley, Bulgaria",
      "location": {
        "section": "Data",
        "subsection": "Pedestrian survey",
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C003"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E019",
        "E020",
        "E021",
        "E022"
      ]
    },
    {
      "claim_id": "C017",
      "claim_text": "Transfer learning with pre-trained ResNet-50 CNN was adopted to leverage large-scale pre-training",
      "claim_type": "methodological",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Rather than training our own model from scratch, we used a pre-trained CNN, a technique known as transfer learning",
      "location": {
        "section": "Methods",
        "subsection": "Transfer learning",
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C001",
        "C002"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E023",
        "E024",
        "E025",
        "E027"
      ]
    },
    {
      "claim_id": "C018",
      "claim_text": "First model run (2021) had high false positive (87.1%) and false negative (95.3%) rates despite good F1 score (0.87), demonstrating that F1 improvement over previous model did not translate to real-world performance",
      "claim_type": "finding",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "After image augmentation, the model reported good learning and model fit (F1 5 0.87). This F1 score indicated that the use of a pre-trained model improved performance by 0.05 compared to a previous, manually trained model. Nevertheless, only 19 out of 148 tiles (12.8%) tagged by the model with at least a 60% chance of having a mound actually contained one",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C002",
        "C003"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C018",
          "P1_C019"
        ],
        "consolidation_type": "compound_interpretation",
        "information_preserved": "complete",
        "rationale": "C019 (F1 improvement didn't translate) is supporting detail of C018's broader finding about model failure. Consolidated to eliminate redundancy while preserving both the performance metrics and the interpretation that internal metrics were misleading."
      },
      "supported_by": [
        "E028",
        "E029",
        "E030",
        "E031",
        "E032"
      ]
    },
    {
      "claim_id": "C020",
      "claim_text": "Second model run (2022, visible mounds only) performed worse with lower F1 (0.62) and higher false positive (94.8%) and false negative (96.2%) rates",
      "claim_type": "finding",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "The second model's performance declined to an F1 score of 0.62 (Kristensen-McLachlan and Mallon, 2022). Validation revealed that only 21 of 773 mounds (2.7%) were detected, while 752 mounds (97.3%) remained undetected.",
      "location": {
        "section": "Results",
        "subsection": "Second run (2022)",
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C001",
        "C002"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": [
        "E033",
        "E034",
        "E035",
        "E036",
        "E037",
        "E038"
      ]
    },
    {
      "claim_id": "C021",
      "claim_text": "Fixed 150x150m tile size was inappropriate for varied mound diameters (10-100m)",
      "claim_type": "methodological_critique",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "In retrospect, a fixed 150 3 150 m tile size was probably inappropriate for training data, given that mound diameters ranged from 10 to 100 m",
      "location": {
        "section": "Discussion",
        "subsection": "Limitations and challenges of pre-trained CNNs",
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C001",
        "C002"
      ],
      "alternatives_mentioned": false,
      "qualifications": [
        "probably"
      ],
      "contradicts": [],
      "supported_by": [
        "E010"
      ]
    },
    {
      "claim_id": "C022",
      "claim_text": "Pre-trained weights introduce biases from ImageNet that don't transfer well to satellite imagery",
      "claim_type": "methodological_critique",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Pre-trained weights bring with them biases that depend on the content of the pre-training dataset – in our case ImageNet. These biases do not transfer particularly well to satellite imagery.",
      "location": {
        "section": "Discussion",
        "subsection": "Limitations and challenges of pre-trained CNNs",
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C001",
        "C002"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C023",
      "claim_text": "Model was detecting modern features (field boundaries, roads, tree lines) rather than mounds",
      "claim_type": "finding",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Inspection of tiles tagged by the model indicated that it was detecting features other than mounds, such as field boundaries, roads, and tree lines",
      "location": {
        "section": "Discussion",
        "subsection": "Limitations and challenges of pre-trained CNNs",
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C001",
        "C003"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C024",
      "claim_text": "Alternative tile sizes, higher resolution, different training data, and custom models might improve performance",
      "claim_type": "recommendation",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Better results might be achieved by using alternative tile sizes, higher resolution imagery, different training data, or custom models",
      "location": {
        "section": "Discussion",
        "subsection": "Building a better model",
        "paragraph": 1
      },
      "supported_by_claims": [
        "C021",
        "C022",
        "C023"
      ],
      "supports_claims": [],
      "alternatives_mentioned": true,
      "qualifications": [
        "might"
      ],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C025",
      "claim_text": "Training custom model would require substantially more time, expertise, and computational resources",
      "claim_type": "methodological",
      "claim_role": "intermediate",
      "claim_status": "explicit",
      "verbatim_quote": "Training a custom model would require substantially more time, expertise, and computational resources",
      "location": {
        "section": "Discussion",
        "subsection": "Building a better model",
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C004"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C026",
      "claim_text": "Determining correct tile size, bands, resolution, and augmentation strategy requires extensive experimentation",
      "claim_type": "methodological",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "Determining the correct tile size, which image bands and resolution to use, and how to augment images would require a significant amount of experimentation",
      "location": {
        "section": "Discussion",
        "subsection": "Building a better model",
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C025",
        "C004"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C027",
      "claim_text": "Cost-benefit analysis suggests ML approach not worthwhile for this application",
      "claim_type": "recommendation",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "This cost-benefit analysis suggests that deploying ML for our particular application was not worthwhile",
      "location": {
        "section": "Discussion",
        "subsection": "Is it worth it?",
        "paragraph": 2
      },
      "supported_by_claims": [
        "C025",
        "C026"
      ],
      "supports_claims": [
        "C004"
      ],
      "alternatives_mentioned": false,
      "qualifications": [
        "for our particular application"
      ],
      "contradicts": [],
      "supported_by": [
        "E004"
      ]
    },
    {
      "claim_id": "C028",
      "claim_text": "Manual processing of 5,000 tiles at 30 seconds each would take approximately 42 hours, less than model development time of 135 hours",
      "claim_type": "comparative_analysis",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "With approximately 5,000 150 3 150 m tiles in our 600 sq km study area, and with an experienced operator able to make an assessment in ~30 s, manual processing would have taken approximately 42 h. Meanwhile, as reported above, simply developing the model required about 135 h",
      "location": {
        "section": "Discussion",
        "subsection": "Is it worth it?",
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C027",
        "C004"
      ],
      "alternatives_mentioned": false,
      "qualifications": [
        "approximately"
      ],
      "contradicts": [],
      "consolidation_metadata": {
        "consolidated_from": [
          "P1_C028",
          "P1_C029"
        ],
        "consolidation_type": "compound_interpretation",
        "information_preserved": "complete",
        "rationale": "C029 (comparison) depends entirely on C028 (manual time estimate). These form a single argumentative unit for cost-benefit analysis. Consolidated to eliminate redundancy while preserving both the time estimate and the comparison."
      },
      "supported_by": [
        "E004"
      ]
    },
    {
      "claim_id": "C030",
      "claim_text": "Manual validation work is required regardless of whether ML is used",
      "claim_type": "methodological",
      "claim_role": "supporting",
      "claim_status": "explicit",
      "verbatim_quote": "In either case, a trained operator would need to inspect and validate imagery to confirm or deny the presence of mounds",
      "location": {
        "section": "Discussion",
        "subsection": "Is it worth it?",
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supports_claims": [
        "C027",
        "C003"
      ],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C031",
      "claim_text": "Study demonstrates value of reporting negative results in ML research",
      "claim_type": "meta-research",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "We have shown that reporting negative results contributes to a more balanced and realistic understanding of the current capabilities and limitations of ML in archaeological research",
      "location": {
        "section": "Conclusion",
        "subsection": null,
        "paragraph": 2
      },
      "supported_by_claims": [
        "C005",
        "C014",
        "C015"
      ],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": []
    },
    {
      "claim_id": "C032",
      "claim_text": "Transfer learning and pre-trained CNNs are not universally applicable solutions",
      "claim_type": "finding",
      "claim_role": "core",
      "claim_status": "explicit",
      "verbatim_quote": "Our experience demonstrates that transfer learning and pre-trained CNNs are not universally applicable solutions to the problem of limited training data in archaeological contexts",
      "location": {
        "section": "Conclusion",
        "subsection": null,
        "paragraph": 2
      },
      "supported_by_claims": [
        "C001",
        "C002",
        "C018",
        "C020"
      ],
      "supports_claims": [],
      "alternatives_mentioned": false,
      "qualifications": [],
      "contradicts": [],
      "supported_by": []
    }
  ],
  "implicit_arguments": [
    {
      "implicit_argument_id": "IA001",
      "implicit_argument_text": "Self-reported model performance metrics (F1 scores) are insufficient for assessing real-world ML efficacy without field validation",
      "implicit_argument_type": "unstated_assumption",
      "trigger_text": [
        "Validation of results against field data showed that self-reported success rates were misleadingly high, and that the model was misidentifying most features.",
        "The model has detected incidental features rather than the mounds themselves, making external validation with field data an essential part of CNN workflows."
      ],
      "trigger_locations": [
        {
          "section": "Abstract",
          "subsection": "Findings",
          "paragraph": 1
        },
        {
          "section": "Abstract",
          "subsection": "Research limitations/implications",
          "paragraph": 1
        }
      ],
      "inference_reasoning": "The paper contrasts 'self-reported success rates' (internal model metrics) with 'field validation' outcomes, asserting the former were 'misleadingly high'. This implicitly argues that standard ML performance metrics alone cannot reliably assess real-world detection efficacy, requiring the unstated assumption that field validation is necessary to reveal actual performance. Without stating this assumption explicitly, the authors position field validation as essential—implying internal metrics are systematically inadequate for assessment.",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "supports_claims": [
        "C002",
        "C003"
      ],
      "assessment_implication": "Critical for assessing transparency. Papers reporting only internal ML metrics without field validation may overstate real-world performance. This assumption affects interpretation of success claims in ML-for-archaeology literature."
    },
    {
      "implicit_argument_id": "IA002",
      "implicit_argument_text": "More curation of training data does not necessarily improve model performance when fundamental approach limitations exist",
      "implicit_argument_type": "logical_implication",
      "trigger_text": [
        "Counterintuitively, the model provided with training data selected for highly visible mounds (rather than all mounds) performed worse.",
        "Despite increased effort in the selection of training data, the second run of the model reported a lower F1 score (0.62) and at >60% probability produced even more false positives (94.8%) and false negatives (96.2%)."
      ],
      "trigger_locations": [
        {
          "section": "Abstract",
          "subsection": "Findings",
          "paragraph": 1
        },
        {
          "section": "Introduction",
          "subsection": null,
          "paragraph": 4
        }
      ],
      "inference_reasoning": "The paper reports that additional curation (selecting only highly visible mounds) led to worse performance. This counterintuitive outcome implies that when core methodological limitations exist (fixed tile size, heterogeneous backgrounds), data curation cannot compensate. The logical implication is that training data quality improvements have limits—fundamental approach constraints must be addressed first. This challenges the common ML assumption that better training data improves performance.",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "supports_claims": [
        "C001",
        "C002"
      ],
      "assessment_implication": "Affects assessment of methodological adequacy. Reveals that data curation is insufficient when detection approach is mismatched to feature characteristics. Challenges reproducibility if similar projects assume data quality is primary constraint."
    },
    {
      "implicit_argument_id": "IA003",
      "implicit_argument_text": "Computational infrastructure and technical expertise requirements exclude most cultural heritage practitioners from implementing effective ML",
      "implicit_argument_type": "bridging_claim",
      "trigger_text": [
        "Correcting the model would require refining the training data as well as adopting different approaches to model choice and execution, raising the computational requirements beyond the level of most cultural heritage practitioners.",
        "The degree of manual intervention required – particularly around the subsetting and annotation of training data – is so significant that it raises the question of whether it would be more efficient to identify all of the mounds manually"
      ],
      "trigger_locations": [
        {
          "section": "Abstract",
          "subsection": "Research limitations/implications",
          "paragraph": 1
        },
        {
          "section": "Abstract",
          "subsection": "Practical implications",
          "paragraph": 1
        }
      ],
      "inference_reasoning": "The paper bridges from evidence (135 person-hours, need for specialists, computational requirements) to recommendation (manual approaches may be preferable) via an unstated claim about practitioner capacity. The bridge is: 'most cultural heritage practitioners lack' the resources/expertise/infrastructure to implement corrections. Without this assumption, the leap from 'model needs improvement' to 'manual may be better' is incomplete. The bridging claim makes the recommendation logical.",
      "location": {
        "section": "Abstract",
        "subsection": "Practical implications",
        "paragraph": 1
      },
      "supports_claims": [
        "C004"
      ],
      "assessment_implication": "Critical for assessing applicability. If most practitioners cannot implement these methods effectively, generalisability of successful ML approaches is limited. Affects transparency about accessibility of methods."
    },
    {
      "implicit_argument_id": "IA004",
      "implicit_argument_text": "Publication bias in favour of positive ML results systematically misrepresents technology effectiveness to potential adopters",
      "implicit_argument_type": "logical_implication",
      "trigger_text": [
        "The literature itself, however, is overwhelmingly positive, reflecting some combination of publication bias and a rhetoric of unconditional success.",
        "This paper presents the failure of a good-faith attempt to utilise these approaches as a counterbalance and cautionary tale to potential adopters of the technology."
      ],
      "trigger_locations": [
        {
          "section": "Abstract",
          "subsection": "Social implications",
          "paragraph": 1
        },
        {
          "section": "Abstract",
          "subsection": "Social implications",
          "paragraph": 1
        }
      ],
      "inference_reasoning": "The paper identifies 'overwhelmingly positive' literature and positions their failure report as 'counterbalance' and 'cautionary tale'. This implies that positive bias systematically misrepresents effectiveness—potential adopters receive skewed information affecting their technology decisions. Without stating this explicitly, the authors argue that failure to report negative outcomes causes systematic misinformation about ML efficacy, affecting adoption decisions. This is a logical implication of publication bias: if failures are underreported, success rates appear higher than reality.",
      "location": {
        "section": "Abstract",
        "subsection": "Social implications",
        "paragraph": 1
      },
      "supports_claims": [
        "C005"
      ],
      "assessment_implication": "Affects assessment of literature credibility and technology adoption guidance. Suggests systematic bias in evidence base affects reproducibility expectations and resource allocation decisions."
    },
    {
      "implicit_argument_id": "IA005",
      "implicit_argument_text": "Successful ML applications in uniform environments do not generalise to heterogeneous landscapes",
      "implicit_argument_type": "unstated_assumption",
      "trigger_text": [
        "Enthusiasm arising from this study, and similar outcomes from Egypt (Woolf, 2018) must, however, be tempered by the fact that the authors targeted uniform features situated in environments with little variation in terrain or vegetation",
        "Fewer studies explore the challenges presented by more difficult environments where cultural heritage lies in diverse or thick vegetation, surrounded by obtrusive natural and artificial features"
      ],
      "trigger_locations": [
        {
          "section": "Introduction",
          "subsection": null,
          "paragraph": 1
        },
        {
          "section": "Introduction",
          "subsection": null,
          "paragraph": 1
        }
      ],
      "inference_reasoning": "The paper distinguishes 'uniform features' in simple environments (Siberia, Egypt successes) from 'more difficult environments' with 'diverse vegetation' and 'obtrusive features' (their case). The tempering caveat implies that success in uniform settings provides limited evidence for heterogeneous settings. This unstated assumption—that environmental complexity fundamentally affects ML transferability—underlies their methodological positioning. Without stating this explicitly, they argue Siberian success does not predict Bulgarian performance due to landscape differences.",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 1
      },
      "supports_claims": [
        "C001",
        "C006"
      ],
      "assessment_implication": "Critical for assessing methodological transferability. Success claims from simple environments may not apply to complex settings. Affects reproducibility expectations and comparative assessment."
    },
    {
      "implicit_argument_id": "IA006",
      "implicit_argument_text": "Pre-trained CNN approach was reasonable to attempt despite ultimately failing",
      "implicit_argument_type": "unstated_assumption",
      "trigger_text": [
        "This paper offers a cautionary tale about the challenges, limitations, and demands of ML applied to archaeological prospection.",
        "We set out to detect burial mounds in the Kazanlak Valley, Bulgaria, using IKONOS high-resolution satellite imagery. We developed a pre-trained CNN that was further trained using two datasets"
      ],
      "trigger_locations": [
        {
          "section": "Introduction",
          "subsection": null,
          "paragraph": 4
        },
        {
          "section": "Introduction",
          "subsection": null,
          "paragraph": 4
        }
      ],
      "inference_reasoning": "The paper positions their attempt as a 'cautionary tale' rather than methodological error, and describes their approach in neutral terms ('we set out to', 'we developed'). This framing implicitly assumes the approach was reasonable and well-intentioned despite failure—i.e., failure resulted from inherent limitations, not poor execution. Without this assumption, the paper could be read as documenting researcher error rather than technology limitation. The unstated assumption legitimises the attempt, making failure informative rather than simply mistaken.",
      "location": {
        "section": "Introduction",
        "subsection": null,
        "paragraph": 4
      },
      "supports_claims": [
        "C001",
        "C002"
      ],
      "assessment_implication": "Affects assessment of methodological adequacy. Positions failure as informative about technology limits rather than execution problems. Supports credibility of negative findings."
    },
    {
      "implicit_argument_id": "IA007",
      "implicit_argument_text": "Widespread ML adoption will occur despite limited critical literature unless failures are documented",
      "implicit_argument_type": "logical_implication",
      "trigger_text": [
        "If publication counts are used a proxy for research, this 17% figure indicates that AI/ML is on the cusp of \\\"crossing the chasm\\\"",
        "As these approaches spread to a broader cohort of researchers, potential adopters need to recognise their challenges and limitations.",
        "In this context, it is important to document unsuccessful attempts to apply ML techniques to archaeological remote sensing"
      ],
      "trigger_locations": [
        {
          "section": "Automated approaches to remotely sensed data",
          "subsection": null,
          "paragraph": 3
        },
        {
          "section": "Automated approaches to remotely sensed data",
          "subsection": null,
          "paragraph": 5
        },
        {
          "section": "Automated approaches to remotely sensed data",
          "subsection": null,
          "paragraph": 5
        }
      ],
      "inference_reasoning": "The paper connects adoption trajectory ('crossing the chasm') with need for critical information ('potential adopters need to recognise challenges') and documentation imperative ('important to document failures'). The implicit argument is that adoption will proceed regardless—crossing the chasm is presented as inevitable or already occurring—therefore failure documentation becomes urgent. Without stating this explicitly, the paper implies that technology diffusion momentum makes critical literature time-sensitive: if early majority adopt based on incomplete information, systematic problems may be replicated at scale.",
      "location": {
        "section": "Automated approaches to remotely sensed data",
        "subsection": null,
        "paragraph": 5
      },
      "supports_claims": [
        "C013",
        "C014",
        "C015"
      ],
      "assessment_implication": "Affects urgency assessment. Suggests timing matters—documentation of limitations must occur before widespread adoption embeds problematic practices. Relevant for assessing whether early-stage critical assessment is adequate."
    },
    {
      "implicit_argument_id": "IA008",
      "implicit_argument_text": "Manual inspection by trained operators is sufficiently reliable to serve as validation standard without documented quality control",
      "implicit_argument_type": "unstated_assumption",
      "trigger_text": [
        "In either case, a trained operator would need to inspect and validate imagery to confirm or deny the presence of mounds",
        "With approximately 5,000 150 3 150 m tiles in our 600 sq km study area, and with an experienced operator able to make an assessment in ~30 s"
      ],
      "trigger_locations": [
        {
          "section": "Discussion",
          "subsection": "Is it worth it?",
          "paragraph": 2
        },
        {
          "section": "Discussion",
          "subsection": "Is it worth it?",
          "paragraph": 2
        }
      ],
      "inference_reasoning": "The paper positions manual inspection as both validation method (for assessing ML) and alternative approach, with specific time estimates (30s per tile). This assumes trained operators produce sufficiently reliable judgments without discussing inter-operator reliability, quality control protocols, or error rates. The cost-benefit comparison treats manual assessment as having known, stable performance, but this reliability is assumed rather than demonstrated. Without this assumption, the 42h estimate lacks validity (could vary significantly by operator or require QC overhead).",
      "location": {
        "section": "Discussion",
        "subsection": "Is it worth it?",
        "paragraph": 2
      },
      "supports_claims": [
        "C027",
        "C028",
        "C030"
      ],
      "assessment_implication": "Critical for assessing transparency. Cost-benefit comparison depends on unstated assumptions about manual method reliability. Affects credibility of efficiency claims if manual approach has undocumented variability or error rates."
    },
    {
      "implicit_argument_id": "IA009",
      "implicit_argument_text": "Study area and application scope are representative enough that findings generalise to inform ML adoption decisions",
      "implicit_argument_type": "unstated_assumption",
      "trigger_text": [
        "This cost-benefit analysis suggests that deploying ML for our particular application was not worthwhile",
        "We have shown that reporting negative results contributes to a more balanced and realistic understanding of the current capabilities and limitations of ML in archaeological research"
      ],
      "trigger_locations": [
        {
          "section": "Discussion",
          "subsection": "Is it worth it?",
          "paragraph": 2
        },
        {
          "section": "Conclusion",
          "subsection": null,
          "paragraph": 2
        }
      ],
      "inference_reasoning": "The paper qualifies cost-benefit finding as specific ('our particular application') but then positions results as contributing to 'understanding of ML capabilities and limitations' generally. This implicit argument bridges from single-case negative result to broader implications: the case must be representative or transferable enough to inform others' adoption decisions. Without this assumption, the study would be purely local—interesting but not actionable for other researchers. The assumption that this failure case has broader relevance is necessary for the study's positioning as 'cautionary tale' to potential adopters.",
      "location": {
        "section": "Conclusion",
        "subsection": null,
        "paragraph": 2
      },
      "supports_claims": [
        "C027",
        "C031",
        "C032"
      ],
      "assessment_implication": "Critical for assessing generalisability. If study context (Bulgaria burial mounds, IKONOS imagery, heterogeneous landscape) is too specific, findings may not transfer to other archaeological applications. Affects utility of negative results for informing adoption decisions."
    }
  ],
  "research_designs": [
    {
      "design_id": "RD001",
      "design_text": "External validation design comparing ML model predictions against comprehensive field survey data",
      "design_status": "explicit",
      "verbatim_quote": "In this study we used a dataset of 773 mounds, collected by TRAP during 2009 – 2011 field survey in the Kazanlak Valley, Bulgaria, to validate the performance of a pre-trained CNN",
      "location": {
        "section": "Data",
        "subsection": "Pedestrian survey",
        "paragraph": 1
      },
      "design_rationale": "Field data serves as ground truth for assessing ML detection accuracy",
      "alternative_designs_considered": [],
      "linked_methods": [
        "M001",
        "M002",
        "M003",
        "M006"
      ],
      "expected_information_missing": [
        "Why Kazanlak Valley chosen",
        "Sample size justification"
      ],
      "implemented_by_methods": [
        "M001",
        "M002",
        "M003",
        "M004",
        "M005",
        "M006",
        "M007"
      ]
    },
    {
      "design_id": "RD002",
      "design_text": "Comparative two-run design testing impact of training data curation on model performance",
      "design_status": "explicit",
      "verbatim_quote": "In the 2021 run of the model, we used all 773 cutouts for training regardless of what was visible in the satellite image. In the 2022 run, we selected 249 cutouts where a mound was discernible with the naked eye.",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "design_rationale": "Test hypothesis that curated training data (visible mounds only) improves model performance",
      "alternative_designs_considered": [],
      "linked_methods": [
        "M002"
      ],
      "expected_information_missing": [
        "Hypothesis stated explicitly",
        "Statistical test design"
      ],
      "implemented_by_methods": [
        "M002"
      ]
    },
    {
      "design_id": "RD003",
      "design_text": "Negative results documentation design to counterbalance publication bias in ML-for-archaeology literature",
      "design_status": "explicit",
      "verbatim_quote": "This paper presents the failure of a good-faith attempt to utilise these approaches as a counterbalance and cautionary tale to potential adopters of the technology.",
      "location": {
        "section": "Abstract",
        "subsection": "Social implications",
        "paragraph": 1
      },
      "design_rationale": "Address identified gap in literature where negative results underreported (63% of papers mention no challenges)",
      "alternative_designs_considered": [],
      "linked_methods": [],
      "expected_information_missing": [
        "Peer review process for negative results",
        "Target audience specification"
      ]
    },
    {
      "design_id": "RD004",
      "design_text": "Cost-benefit analysis design comparing ML development time against manual processing alternative",
      "design_status": "explicit",
      "verbatim_quote": "With approximately 5,000 150 3 150 m tiles in our 600 sq km study area, and with an experienced operator able to make an assessment in ~30 s, manual processing would have taken approximately 42 h. Meanwhile, as reported above, simply developing the model required about 135 h",
      "location": {
        "section": "Discussion",
        "subsection": "Is it worth it?",
        "paragraph": 2
      },
      "design_rationale": "Assess whether ML approach justified given resource investment compared to manual alternative",
      "alternative_designs_considered": [
        "Crowdsourcing approach mentioned"
      ],
      "linked_methods": [
        "M001",
        "M002"
      ],
      "expected_information_missing": [
        "Manual processing accuracy rates",
        "Cost of false negatives not quantified"
      ],
      "implemented_by_methods": [
        "M001",
        "M002"
      ]
    }
  ],
  "methods": [
    {
      "method_id": "M001",
      "method_text": "Transfer learning using pre-trained ResNet-50 convolutional neural network",
      "method_status": "explicit",
      "verbatim_quote": "Rather than training our own model from scratch, we used a pre-trained CNN, a technique known as transfer learning. After some preliminary experimentation with a range of different pre-trained models, we concluded that ResNet-50 seemed to perform best for our data.",
      "location": {
        "section": "Methods",
        "subsection": "Transfer learning",
        "paragraph": 1
      },
      "method_category": "computational_analysis",
      "linked_protocols": [
        "P001",
        "P002",
        "P003"
      ],
      "expected_information_missing": [
        "Criteria for 'best performance'",
        "Other models tested",
        "Pre-training dataset characteristics"
      ],
      "implements_designs": [
        "RD001",
        "RD004"
      ],
      "realized_through_protocols": [
        "P001",
        "P002",
        "P003",
        "P007",
        "P010"
      ],
      "implemented_by_protocols": [
        "P001",
        "P002",
        "P003",
        "P007",
        "P010"
      ]
    },
    {
      "method_id": "M002",
      "method_text": "Additional CNN training using domain-specific burial mound imagery",
      "method_status": "explicit",
      "verbatim_quote": "Although pre-trained models have already been exposed to millions of images and have developed weights that respond to low-level features, they still need to be trained with domain-specific data.",
      "location": {
        "section": "Methods",
        "subsection": "Transfer learning",
        "paragraph": 3
      },
      "method_category": "computational_analysis",
      "linked_protocols": [
        "P002",
        "P003",
        "P004"
      ],
      "expected_information_missing": [
        "Training hyperparameters",
        "Stopping criteria",
        "Overfitting prevention strategy"
      ],
      "implements_designs": [
        "RD001",
        "RD002",
        "RD004"
      ],
      "realized_through_protocols": [
        "P002",
        "P003",
        "P004",
        "P005"
      ],
      "implemented_by_protocols": [
        "P002",
        "P003",
        "P004",
        "P005"
      ]
    },
    {
      "method_id": "M003",
      "method_text": "Binary classification approach distinguishing tiles containing mounds from tiles without mounds",
      "method_status": "explicit",
      "verbatim_quote": "The CNN was trained to identify 150 3 150 m tiles that contained mounds (MOUND) and those that did not (NO MOUND).",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "method_category": "computational_analysis",
      "linked_protocols": [
        "P004",
        "P005"
      ],
      "expected_information_missing": [
        "Decision threshold selection",
        "Multi-mound tile handling strategy"
      ],
      "implements_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P004"
      ],
      "implemented_by_protocols": [
        "P004"
      ]
    },
    {
      "method_id": "M004",
      "method_text": "Image augmentation to expand training dataset",
      "method_status": "explicit",
      "verbatim_quote": "After image augmentation, the model reported good learning and model fit",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "method_category": "data_preparation",
      "linked_protocols": [],
      "expected_information_missing": [
        "Augmentation techniques used",
        "Augmentation factor",
        "Rationale for augmentation strategy"
      ],
      "implements_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P011"
      ],
      "implemented_by_protocols": [
        "P011"
      ]
    },
    {
      "method_id": "M005",
      "method_text": "Automated model performance evaluation using held-out test set",
      "method_status": "explicit",
      "verbatim_quote": "After processing, cutouts were divided into training, validation, and test sets following a 70:20:10 ratio for automated performance validation.",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "method_category": "validation",
      "linked_protocols": [
        "P008"
      ],
      "expected_information_missing": [
        "Metrics used beyond F1",
        "Stratification strategy",
        "Cross-validation"
      ],
      "implements_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P006",
        "P008"
      ],
      "implemented_by_protocols": [
        "P006",
        "P008"
      ]
    },
    {
      "method_id": "M006",
      "method_text": "Field-based external validation comparing model predictions against surveyed ground truth",
      "method_status": "explicit",
      "verbatim_quote": "Validation of results against field data showed that self-reported success rates were misleadingly high",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "method_category": "validation",
      "linked_protocols": [
        "P009"
      ],
      "expected_information_missing": [
        "Validation protocol details",
        "False positive/negative classification criteria",
        "Inter-rater reliability"
      ],
      "implements_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P009"
      ],
      "implemented_by_protocols": [
        "P009"
      ]
    },
    {
      "method_id": "M007",
      "method_text": "Probability thresholding at >60% for positive mound detection",
      "method_status": "explicit",
      "verbatim_quote": "Nevertheless, only 19 out of 148 tiles (12.8%) tagged by the model with at least a 60% chance of having a mound actually contained one",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "method_category": "computational_analysis",
      "linked_protocols": [],
      "expected_information_missing": [
        "Threshold selection rationale",
        "Threshold sensitivity analysis",
        "Alternative thresholds tested"
      ],
      "implements_designs": [
        "RD001"
      ]
    }
  ],
  "protocols": [
    {
      "protocol_id": "P001",
      "protocol_text": "ResNet-50 CNN model selection with ~25.6m trainable parameters",
      "protocol_status": "explicit",
      "verbatim_quote": "After some preliminary experimentation with a range of different pre-trained models, we concluded that ResNet-50 seemed to perform best for our data. This model is one of the smaller pre-trained CNNs available, with only around 25.6m trainable parameters",
      "location": {
        "section": "Methods",
        "subsection": "Transfer learning",
        "paragraph": 4
      },
      "linked_evidence": [
        "E023"
      ],
      "execution_context": {
        "computational_requirements": "Lower than larger models",
        "implementation": "Pre-trained model available"
      },
      "expected_information_missing": [
        "Hardware specifications",
        "Training time",
        "Framework/library used (TensorFlow, PyTorch?)"
      ],
      "implements_methods": [
        "M001"
      ]
    },
    {
      "protocol_id": "P002",
      "protocol_text": "Training cutout generation: 150x150m square polygons centred on mound points, clipped from IKONOS imagery",
      "protocol_status": "explicit",
      "verbatim_quote": "Mound points taken during fieldwork were used as centroids for the generation of 150 3 150 m square polygons (150 3 150 pixels at 1 m resolution), which were clipped from the IKONOS imagery.",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "linked_evidence": [
        "E024"
      ],
      "execution_context": {
        "tools": "GIS software (unspecified)",
        "resolution": "1m IKONOS panchromatic"
      },
      "expected_information_missing": [
        "Edge case handling",
        "Tile overlap strategy",
        "GIS software/tools used"
      ],
      "implements_methods": [
        "M001",
        "M002"
      ]
    },
    {
      "protocol_id": "P003",
      "protocol_text": "NO MOUND training data generation by randomly sampling tiles without known mounds",
      "protocol_status": "explicit",
      "verbatim_quote": "NO MOUND cutouts were created by randomly sampling the landscape within the TRAP survey area, at places where there were no known mounds.",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "linked_evidence": [],
      "execution_context": {
        "sampling": "Random within survey area"
      },
      "expected_information_missing": [
        "Minimum distance from mounds",
        "Sampling density",
        "Seed for reproducibility"
      ],
      "implements_methods": [
        "M001",
        "M002"
      ]
    },
    {
      "protocol_id": "P004",
      "protocol_text": "Training data composition: 1:2 positive to negative ratio (32%-68%)",
      "protocol_status": "explicit",
      "verbatim_quote": "The ratio of positive to negative training data was approximately 1:2 (32%–68%).",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "linked_evidence": [
        "E025"
      ],
      "execution_context": {
        "class_balance": "Imbalanced toward negatives"
      },
      "expected_information_missing": [
        "Rationale for 1:2 ratio",
        "Class weighting or resampling",
        "Impact on decision threshold"
      ],
      "implements_methods": [
        "M002",
        "M003"
      ]
    },
    {
      "protocol_id": "P005",
      "protocol_text": "2022 run training data curation: Visual selection of 249 cutouts where mound discernible",
      "protocol_status": "explicit",
      "verbatim_quote": "In the 2022 run, we selected 249 cutouts where a mound was discernible with the naked eye.",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "linked_evidence": [
        "E026"
      ],
      "execution_context": {
        "selection": "Manual visual inspection",
        "operator": "Trained researcher (implied)"
      },
      "expected_information_missing": [
        "Inter-rater reliability",
        "Selection criteria documentation",
        "Rejected cutout characteristics"
      ],
      "implements_methods": [
        "M002"
      ]
    },
    {
      "protocol_id": "P006",
      "protocol_text": "Training/validation/test split: 70:20:10 ratio",
      "protocol_status": "explicit",
      "verbatim_quote": "After processing, cutouts were divided into training, validation, and test sets following a 70:20:10 ratio",
      "location": {
        "section": "Methods",
        "subsection": "Additional CNN training",
        "paragraph": 1
      },
      "linked_evidence": [
        "E027"
      ],
      "execution_context": {
        "split_method": "Unspecified"
      },
      "expected_information_missing": [
        "Stratification",
        "Random seed",
        "Spatial autocorrelation handling"
      ],
      "implements_methods": [
        "M005"
      ]
    },
    {
      "protocol_id": "P007",
      "protocol_text": "Model application to 600 sq km study area covering ~5,000 tiles",
      "protocol_status": "explicit",
      "verbatim_quote": "With approximately 5,000 150 3 150 m tiles in our 600 sq km study area",
      "location": {
        "section": "Discussion",
        "subsection": "Is it worth it?",
        "paragraph": 2
      },
      "linked_evidence": [],
      "execution_context": {
        "scale": "Full valley coverage"
      },
      "expected_information_missing": [
        "Processing time",
        "Tile overlap handling",
        "Edge tile treatment"
      ],
      "implements_methods": [
        "M001"
      ]
    },
    {
      "protocol_id": "P008",
      "protocol_text": "F1 score calculation for model performance assessment",
      "protocol_status": "explicit",
      "verbatim_quote": "After image augmentation, the model reported good learning and model fit (F1 5 0.87).",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "linked_evidence": [
        "E028",
        "E033"
      ],
      "execution_context": {
        "metric": "F1 score (harmonic mean of precision and recall)"
      },
      "expected_information_missing": [
        "Precision/recall individually",
        "Confusion matrix",
        "ROC curve"
      ],
      "implements_methods": [
        "M005"
      ]
    },
    {
      "protocol_id": "P009",
      "protocol_text": "Field validation by manual inspection of model-tagged tiles against ground truth mound locations",
      "protocol_status": "explicit",
      "verbatim_quote": "Validation of results against field data showed that self-reported success rates were misleadingly high, and that the model was misidentifying most features.",
      "location": {
        "section": "Abstract",
        "subsection": "Findings",
        "paragraph": 1
      },
      "linked_evidence": [
        "E029",
        "E030",
        "E031",
        "E032",
        "E034",
        "E035",
        "E036",
        "E037",
        "E038"
      ],
      "execution_context": {
        "ground_truth": "773 surveyed mounds",
        "comparison": "Tile-by-tile"
      },
      "expected_information_missing": [
        "Validation team size",
        "Blind validation",
        "Quality control procedures",
        "Ambiguous case resolution"
      ],
      "implements_methods": [
        "M006"
      ]
    },
    {
      "protocol_id": "P010",
      "protocol_text": "Preliminary experimentation procedure for comparing pre-trained model performance",
      "protocol_status": "implicit",
      "trigger_text": [
        "After some preliminary experimentation with a range of different pre-trained models, we concluded that ResNet-50 seemed to perform best for our data."
      ],
      "trigger_locations": [
        {
          "section": "Methods",
          "subsection": "Transfer learning",
          "paragraph": 4
        }
      ],
      "inference_reasoning": "Paper mentions 'preliminary experimentation' and 'range of different pre-trained models' but provides no procedural details about how models were compared, what performance metrics were used, how many models were tested, or what constituted 'best' performance. This experimentation clearly occurred but the selection methodology is undocumented.",
      "location": {
        "section": "Methods",
        "subsection": "Transfer learning",
        "paragraph": 4
      },
      "linked_evidence": [],
      "execution_context": {
        "models_tested": "Multiple (unspecified)",
        "comparison_basis": "Performance (unspecified metrics)"
      },
      "implicit_metadata": {
        "basis_for_inference": "Procedure mentioned but not described",
        "expected_information_missing": [
          "Models tested",
          "Performance metrics used",
          "Test dataset",
          "Comparison criteria"
        ],
        "assessment_implication": "Cannot assess appropriateness of model selection or reproduce selection process. Critical for reproducibility."
      },
      "implements_methods": [
        "M001"
      ]
    },
    {
      "protocol_id": "P011",
      "protocol_text": "Image augmentation procedures applied to training data",
      "protocol_status": "implicit",
      "trigger_text": [
        "After image augmentation, the model reported good learning and model fit (F1 5 0.87)."
      ],
      "trigger_locations": [
        {
          "section": "Results",
          "subsection": "First run (2021)",
          "paragraph": 1
        }
      ],
      "inference_reasoning": "Results section confirms 'image augmentation' was performed before model training, but no description of augmentation techniques, parameters, or rationale appears in Methods. Common techniques include rotation, flipping, scaling, but paper doesn't specify which were used or why.",
      "location": {
        "section": "Results",
        "subsection": "First run (2021)",
        "paragraph": 1
      },
      "linked_evidence": [],
      "execution_context": {
        "augmentation_applied": "Yes (techniques unspecified)"
      },
      "implicit_metadata": {
        "basis_for_inference": "Procedure mentioned in Results but not described in Methods",
        "expected_information_missing": [
          "Augmentation techniques",
          "Augmentation factor",
          "Parameter ranges",
          "Rationale"
        ],
        "assessment_implication": "Cannot assess whether augmentation appropriate for satellite imagery or evaluate potential artifacts. Critical for reproducibility and bias assessment."
      },
      "implements_methods": [
        "M004"
      ]
    },
    {
      "protocol_id": "P012",
      "protocol_text": "Manual time estimation procedure for cost-benefit analysis",
      "protocol_status": "implicit",
      "trigger_text": [
        "with an experienced operator able to make an assessment in ~30 s"
      ],
      "trigger_locations": [
        {
          "section": "Discussion",
          "subsection": "Is it worth it?",
          "paragraph": 2
        }
      ],
      "inference_reasoning": "Paper provides specific time estimate (30 seconds per tile) for manual processing but doesn't describe how this estimate was derived. Was it measured empirically? Estimated from experience? Averaged across operators? The precision of cost-benefit comparison depends on validity of this estimate, but estimation methodology is undocumented.",
      "location": {
        "section": "Discussion",
        "subsection": "Is it worth it?",
        "paragraph": 2
      },
      "linked_evidence": [],
      "execution_context": {
        "operator_experience": "Experienced (unspecified criteria)",
        "timing_basis": "Estimate (methodology undocumented)"
      },
      "implicit_metadata": {
        "basis_for_inference": "Specific timing value provided without methodology",
        "expected_information_missing": [
          "Timing measurement protocol",
          "Sample size",
          "Operator variability",
          "Empirical vs estimated"
        ],
        "assessment_implication": "Cost-benefit conclusion depends on accuracy of this estimate. Without methodology, cannot assess reliability or variability. Affects validity of efficiency claims."
      },
      "implements_methods": []
    }
  ],
  "extraction_metadata": {
    "extraction_date": "2025-10-30",
    "extractor": "Claude Code with research-assessor skill",
    "extraction_version": "RUN-10",
    "extraction_notes": [
      {
        "pass0_metadata": {
          "completion_date": "2025-10-30T09:15:00Z",
          "primary_source": "publisher PDF header",
          "author_name_format": "full names",
          "doi_present": true,
          "notes": "Paper published in Emerald journal. Volume, issue, and page numbers not visible on title page (online-first publication). DOI clearly printed. All four authors listed with full names and institutional affiliations."
        }
      },
      {
        "pass1_section1": {
          "section_group": "Abstract + Introduction + Background",
          "word_count_estimate": 2400,
          "sections_combined": [
            "Abstract",
            "Introduction",
            "Burial mounds as heritage under threat",
            "Detecting archaeological features in satellite imagery"
          ],
          "extraction_date": "2025-10-30",
          "items_extracted": {
            "evidence": 13,
            "claims": 12,
            "implicit_arguments": 6
          },
          "core_claims_identified": 5,
          "implicit_argument_scan_completed": true,
          "notes": "Liberal extraction applied. Systematic 4-type implicit argument scan completed for all 5 core claims (C001-C005). All evidence and claims have verbatim_quote sourcing. All implicit arguments have trigger_text arrays with proper inference_reasoning."
        }
      },
      {
        "pass1_section2": {
          "section_group": "Automated approaches + Data",
          "word_count_estimate": 1500,
          "sections_combined": [
            "Automated approaches to remotely sensed data",
            "Data (Pedestrian survey, Satellite imagery)"
          ],
          "extraction_date": "2025-10-30",
          "items_extracted": {
            "evidence": 9,
            "claims": 4,
            "implicit_arguments": 1
          },
          "core_claims_identified": 0,
          "intermediate_claims": 4,
          "implicit_argument_scan_completed": true,
          "notes": "Liberal extraction applied. Quantitative publication analysis evidence extracted. Implicit argument IA007 identified through systematic scan connecting adoption trajectory with documentation urgency."
        }
      },
      {
        "pass1_section3": {
          "section_group": "Methods + Results",
          "word_count_estimate": 2200,
          "sections_combined": [
            "Methods (Transfer learning, Additional CNN training, Assessment)",
            "Results (First run 2021, Second run 2022)"
          ],
          "extraction_date": "2025-10-30",
          "items_extracted": {
            "evidence": 16,
            "claims": 4,
            "implicit_arguments": 0
          },
          "notes": "Liberal extraction applied to quantitative results. Dense with performance metrics and validation statistics. 16 evidence items capturing model specifications and performance measurements. 4 claims including 2 core claims (C018, C020) about model failures."
        }
      },
      {
        "pass1_section4": {
          "section_group": "Discussion + Conclusion",
          "word_count_estimate": 2500,
          "sections_combined": [
            "Discussion (Limitations and challenges, Building a better model, Is it worth it?)",
            "Conclusion"
          ],
          "extraction_date": "2025-10-30",
          "items_extracted": {
            "evidence": 0,
            "claims": 12,
            "implicit_arguments": 2
          },
          "core_claims_identified": 3,
          "implicit_argument_scan_completed": true,
          "notes": "Liberal extraction applied to discussion and conclusion. Claims-dense section with limitations, recommendations, and cost-benefit analysis. 12 claims including 3 new core claims (C027, C031, C032). 2 implicit arguments identified supporting cost-benefit and generalisability claims."
        }
      },
      {
        "pass2_rationalization": {
          "pass_date": "2025-10-30",
          "starting_counts": {
            "evidence": 38,
            "claims": 32,
            "implicit_arguments": 9,
            "total": 79
          },
          "ending_counts": {
            "evidence": 38,
            "claims": 30,
            "implicit_arguments": 9,
            "total": 77
          },
          "reduction": {
            "items": 2,
            "percentage": 2.5
          },
          "consolidations_performed": [
            {
              "type": "claims",
              "consolidated_from": [
                "C018",
                "C019"
              ],
              "consolidated_to": "C018",
              "rationale": "C019 (F1 improvement interpretation) is supporting detail of C018 (model failure). Compound interpretation consolidation."
            },
            {
              "type": "claims",
              "consolidated_from": [
                "C028",
                "C029"
              ],
              "consolidated_to": "C028",
              "rationale": "C029 (time comparison) depends on C028 (manual time). Single argumentative unit. Compound interpretation consolidation."
            }
          ],
          "rationale_for_low_reduction": "Quantitative validation paper with well-differentiated performance metrics and technical specifications. Evidence items represent distinct measurements required for assessment. Low consolidation rate (2.5%) is appropriate for this paper type, consistent with other technical papers (eftimoski 2%, sobotkova-2021 6.25%).",
          "notes": "Conservative rationalization applied. Evidence items preserved as all represent distinct, independently assessable measurements. Claims consolidation focused on removing redundant supporting detail. Cross-references updated for consolidated items."
        }
      },
      {
        "pass3_rdmap_extraction": {
          "pass_date": "2025-10-30",
          "items_extracted": {
            "research_designs": 4,
            "methods": 7,
            "protocols": 9,
            "total": 20
          },
          "equal_attention_applied": true,
          "sections_covered": {
            "research_designs": [
              "Abstract",
              "Data",
              "Methods",
              "Discussion"
            ],
            "methods": [
              "Methods",
              "Results"
            ],
            "protocols": [
              "Methods",
              "Results",
              "Discussion"
            ]
          },
          "notes": "Liberal RDMAP extraction with equal attention to all sections. Research designs found in Abstract (RD003 - negative results documentation), Data (RD001 - external validation), Methods (RD002 - comparative design), and Discussion (RD004 - cost-benefit analysis). All items have verbatim_quote sourcing. Expected information documented for transparency assessment."
        }
      },
      {
        "pass4_implicit_rdmap": {
          "pass_date": "2025-10-30",
          "items_extracted": {
            "implicit_protocols": 3,
            "implicit_methods": 0,
            "implicit_designs": 0,
            "total": 3
          },
          "implicit_percentage": "13.0%",
          "notes": "Systematic scan for mentioned-but-undocumented procedures. Found 3 implicit protocols: model selection experimentation (P010), image augmentation (P011), and manual timing estimation (P012). No implicit methods or designs identified - all strategic and tactical approaches were explicitly documented. Implicit rate of 13.0% (3/23 total RDMAP) is within expected range."
        }
      },
      {
        "pass5_rdmap_rationalization": {
          "pass_date": "2025-10-30",
          "starting_counts": {
            "designs": 4,
            "methods": 7,
            "protocols": 12,
            "total": 23
          },
          "ending_counts": {
            "designs": 4,
            "methods": 7,
            "protocols": 12,
            "total": 23
          },
          "reduction": {
            "items": 0,
            "percentage": 0.0
          },
          "consolidations_performed": [],
          "rationale_for_zero_reduction": "Methods-focused validation paper with well-differentiated RDMAP items. All strategic decisions, analytical methods, and operational protocols are distinct and independently assessable. RDMAP hierarchy properly structured. Zero consolidation rate is appropriate for this technical paper type, consistent with eftimoski-et-al-2017 (0% RDMAP reduction).",
          "notes": "Conservative rationalization review completed. No consolidation opportunities identified. All RDMAP items represent distinct, independently documentable procedures. Hierarchy links verified."
        }
      },
      {
        "pass6_validation": {
          "validation_date": "2025-10-30",
          "overall_status": "FAIL",
          "checks_performed": 4,
          "issues_found": 2,
          "warnings": 0,
          "notes": "Comprehensive validation completed. All schema compliance, sourcing, cross-reference, and metadata checks performed."
        }
      },
      {
        "pass6_repair": {
          "repair_date": "2025-10-30",
          "repairs_performed": [
            {
              "issue": "E028 and E029 referenced consolidated claim C019",
              "action": "Removed C019, verified C018 reference present",
              "rationale": "C019 was consolidated into C018 in Pass 2, references not updated in evidence"
            }
          ],
          "notes": "Cross-reference repair completed. Evidence items now correctly reference C018."
        }
      },
      {
        "pass6_validation": {
          "validation_date": "2025-10-30",
          "overall_status": "PASS",
          "checks_performed": 5,
          "issues_found": 0,
          "warnings": 0,
          "notes": "Comprehensive validation completed. All schema compliance, sourcing, cross-reference, and metadata checks performed."
        }
      }
    ]
  },
  "extraction_notes": {
    "field_migration": {
      "migrated_at": "2025-11-02T14:42:02.282132",
      "script_version": "1.0",
      "changes_applied": 6,
      "canonical_schema_version": "2.5"
    }
  },
  "reproducibility_infrastructure": {
    "persistent_identifiers": {
      "paper_doi": {
        "doi": "10.1108/JD-05-2022-0096",
        "resolves": null,
        "url": "https://doi.org/10.1108/JD-05-2022-0096",
        "verified_date": null,
        "location": "page header, line 59"
      },
      "author_orcids": [],
      "orcid_coverage": {
        "authors_with_orcid": 0,
        "total_authors": 4,
        "coverage_percentage": 0,
        "coverage_category": "none",
        "notes": "ORCIDs not visible in PDF text; may be present in online version at Emerald Insight"
      },
      "dataset_pids": [],
      "software_pids": [
        {
          "software_name": "CNN testing - Training data preparation and validation",
          "repository": "GitHub",
          "doi": null,
          "url": "https://github.com/adivea/cnn-testing",
          "version": null,
          "location": "Code statement, lines 53-55"
        },
        {
          "software_name": "Burial mounds - 2021 CNN classifier",
          "repository": "GitHub",
          "doi": null,
          "url": "https://github.com/centre-for-humanities-computing/burial-mounds",
          "version": "2021",
          "location": "Code statement, lines 55-56"
        },
        {
          "software_name": "MoundDetection - 2022 CNN classifier",
          "repository": "GitHub",
          "doi": null,
          "url": "https://github.com/centre-for-humanities-computing/MoundDetection",
          "version": "2022",
          "location": "Code statement, lines 57-59"
        }
      ],
      "sample_pids": [],
      "project_pid": null,
      "vocabulary_pids": [],
      "pid_graph_summary": {
        "connectivity_score": 4,
        "connectivity_rating": "good",
        "rationale": "Paper DOI (1) + 3 software GitHub repositories (3) = 4. No author ORCIDs visible, no dataset PIDs (historical data from previous project), no sample/project PIDs."
      }
    },
    "funding": [
      {
        "funder": "Aarhus University Digital Literacy Initiative",
        "grant_number": null,
        "grant_url": null,
        "location": "Funding acknowledgement, line 44"
      },
      {
        "funder": "Australian Research Council (ARC)",
        "grant_number": "LP0989901",
        "grant_type": "Linkage Projects",
        "grant_url": null,
        "location": "Data acquisition acknowledgement, lines 46-47",
        "notes": "Historical funding for Tundzha Regional Archaeological Project (2009-2011) data acquisition"
      },
      {
        "funder": "University of Michigan",
        "grant_number": null,
        "grant_type": "International Grant",
        "grant_url": null,
        "location": "Data acquisition acknowledgement, lines 47-48",
        "notes": "Historical funding for TRAP data acquisition"
      },
      {
        "funder": "GeoEye Foundation",
        "grant_number": null,
        "grant_type": "Grant",
        "grant_url": null,
        "location": "Data acquisition acknowledgement, line 48",
        "notes": "Provided satellite imagery for TRAP"
      }
    ],
    "data_availability": {
      "statement_present": false,
      "statement_type": "implicit",
      "verbatim_text": null,
      "location": null,
      "repositories": [],
      "machine_actionability": {
        "rating": "low",
        "rationale": "No explicit data availability statement. Historical field data from TRAP (2009-2011) mentioned but not deposited. Training data and CNN predictions presumably available via GitHub repositories but not explicitly stated."
      },
      "notes": "Paper uses historical field survey data from Tundzha Regional Archaeological Project (2009-2011) and satellite imagery from GeoEye Foundation. No explicit data availability statement. GitHub repositories contain code but unclear if training data/predictions are included."
    },
    "code_availability": {
      "statement_present": true,
      "statement_type": "available",
      "verbatim_text": "Code: Data processing and analysis was performed using R and Python and the scripts are available in public repositories: (1) Training data preparation and CNN prediction validation can be found in https://github.com/adivea/cnn-testing (2) 2021 CNN classifier training and mound prediction is implemented in https://github.com/centre-for-humanities-computing/burial-mounds (3) 2022 CNN classifier training and mound prediction is implemented in https://github.com/centre-for-humanities-computing/MoundDetection",
      "location": "Code statement, lines 53-59",
      "repositories": [
        {
          "name": "GitHub",
          "url": "https://github.com/adivea/cnn-testing",
          "repository_type": "version_control",
          "access_conditions": "open",
          "licence": null,
          "software": [
            {
              "description": "Training data preparation and CNN prediction validation",
              "version": null,
              "doi": null
            }
          ]
        },
        {
          "name": "GitHub",
          "url": "https://github.com/centre-for-humanities-computing/burial-mounds",
          "repository_type": "version_control",
          "access_conditions": "open",
          "licence": null,
          "software": [
            {
              "description": "2021 CNN classifier training and mound prediction",
              "version": "2021",
              "doi": null
            }
          ]
        },
        {
          "name": "GitHub",
          "url": "https://github.com/centre-for-humanities-computing/MoundDetection",
          "repository_type": "version_control",
          "access_conditions": "open",
          "licence": null,
          "software": [
            {
              "description": "2022 CNN classifier training and mound prediction",
              "version": "2022",
              "doi": null
            }
          ]
        }
      ],
      "machine_actionability": {
        "rating": "high",
        "rationale": "Three GitHub repositories explicitly listed with clear descriptions of functionality. Code available in R and Python. Good transparency about computational workflow."
      }
    },
    "author_contributions": {
      "statement_present": false,
      "format": null,
      "verbatim_text": null,
      "location": null,
      "contributions": [
        {
          "author_name": "Adela Sobotkova",
          "credit_roles": [],
          "description": "First author (inferred lead researcher, field data from TRAP project)"
        },
        {
          "author_name": "Ross Deans Kristensen-McLachlan",
          "credit_roles": [],
          "description": "Second author (Center for Humanities Computing - inferred ML implementation)"
        },
        {
          "author_name": "Orla Mallon",
          "credit_roles": [],
          "description": "Third author (Center for Humanities Computing - inferred ML implementation)"
        },
        {
          "author_name": "Shawn Adrian Ross",
          "credit_roles": [],
          "description": "Fourth author (inferred conceptualization, field data from TRAP project)"
        }
      ],
      "notes": "No explicit author contributions statement. Affiliations suggest Sobotkova and Ross provided field data and archaeological expertise (TRAP project), while Kristensen-McLachlan and Mallon provided ML/computational expertise (Center for Humanities Computing)."
    },
    "conflicts_of_interest": {
      "statement_present": false,
      "conflicts_declared": null,
      "verbatim_text": null,
      "location": null,
      "type": "not_stated",
      "notes": "Emerald journal; competing interests statements not always included. No obvious conflicts apparent from author affiliations or acknowledgements."
    },
    "ethics_approval": {
      "statement_present": false,
      "approval_obtained": "not_applicable",
      "verbatim_text": null,
      "location": null,
      "ethics_body": null,
      "approval_number": null,
      "jurisdiction": null,
      "human_subjects_consent": null,
      "animal_welfare": null,
      "notes": "Computational archaeology paper using historical field survey data and satellite imagery. No human subjects research requiring ethics approval. Archaeological fieldwork from TRAP (2009-2011) would have had permits but not detailed in this ML methods paper."
    },
    "permits_and_authorizations": {
      "statement_present": false,
      "permits": [],
      "notes": "Paper uses historical data from Tundzha Regional Archaeological Project (2009-2011) which would have required Bulgarian archaeological permits, but these are not detailed in this methods paper focused on ML validation."
    },
    "preregistration": {
      "statement_present": false,
      "preregistered": false,
      "platform": null,
      "registration_id": null,
      "registration_url": null,
      "registration_date": null,
      "notes": "Not applicable for retrospective ML methods paper analyzing 2021-2022 CNN implementations against historical field data from 2009-2011"
    },
    "supplementary_materials": {
      "statement_present": false,
      "files": [],
      "notes": "No supplementary materials mentioned. Code available via GitHub repositories instead."
    },
    "references_completeness": {
      "doi_usage": "very_high",
      "doi_percentage_estimate": 95,
      "notes": "Extensive references section with very high DOI coverage for contemporary publications. Consistent DOI formatting throughout reference list.",
      "rationale": "2024 Emerald journal article with exemplary reference DOI coverage"
    },
    "fair_assessment": {
      "assessed": true,
      "assessment_date": "2025-11-03",
      "assessor": "claude-sonnet-4-5",
      "publication_year": 2024,
      "discipline": "computational_archaeology/digital_methods",
      "findable": {
        "score": 3,
        "max_score": 4,
        "rationale": "F1: Paper has DOI = 1. F2: Rich metadata = 1. F3: Code on GitHub with clear descriptions = 1. F4: No dataset PIDs (historical field data not deposited) = 0.",
        "criteria_met": [
          "F1-paper_doi",
          "F2-rich_metadata",
          "F3-code_repositories"
        ],
        "criteria_not_met": [
          "F4-dataset_pid"
        ]
      },
      "accessible": {
        "score": 3,
        "max_score": 4,
        "rationale": "A1: Paper accessible via DOI with HTTPS = 1. A1.1: CC BY 4.0 open access = 1. A1.2: No authentication required = 1. A2: Dataset persistence unclear (historical data not deposited) = 0.",
        "criteria_met": [
          "A1-standard_protocol",
          "A1.1-open_access_cc_by",
          "A1.2-no_auth_required"
        ],
        "criteria_not_met": [
          "A2-dataset_metadata_persistent"
        ]
      },
      "interoperable": {
        "score": 3,
        "max_score": 4,
        "rationale": "I1: Code uses structured formats (Python, R, GitHub) = 1. I2: No controlled vocabularies mentioned = 0. I3: References other work via DOIs extensively = 1. Standard ML/CNN frameworks and satellite imagery formats = 1.",
        "criteria_met": [
          "I1-structured_format",
          "I3-qualified_references",
          "Standard_ML_formats"
        ],
        "criteria_not_met": [
          "I2-controlled_vocabularies"
        ]
      },
      "reusable": {
        "score": 3,
        "max_score": 4,
        "rationale": "R1: Rich metadata and detailed methods = 1. R1.1: CC BY 4.0 license for paper, code license not stated = 0.5 (rounded up to 1). R1.2: Good provenance (data from TRAP 2009-2011, computation on UCloud HPC) = 1. R1.3: Uses standard ML/remote sensing community practices = 1.",
        "criteria_met": [
          "R1-rich_metadata",
          "R1.1-cc_by_paper",
          "R1.2-provenance",
          "R1.3-community_standards"
        ],
        "criteria_not_met": [
          "R1.1-explicit_code_licence"
        ]
      },
      "total_fair_score": 12,
      "max_total_score": 16,
      "fair_percentage": 75.0,
      "fair_rating": "highly_fair",
      "machine_actionability": {
        "rating": "moderate",
        "rationale": "Code on GitHub is machine-actionable. Paper metadata well-structured. Missing: dataset deposition, explicit data availability statement, code licences. Three distinct GitHub repositories provide good computational transparency."
      },
      "pid_graph_completeness": {
        "connectivity_score": 4,
        "connectivity_rating": "good",
        "rationale": "Paper DOI + 3 code repositories. Missing: author ORCIDs, dataset PIDs, project PID. Good code sharing but incomplete PID graph."
      },
      "discipline_context": {
        "publication_year_expectations": "2024: High expectations for FAIR data, open code, ORCIDs. Emerald supports open access.",
        "discipline_baseline": "Computational archaeology/ML: Strong tradition of code sharing (GitHub), satellite imagery often proprietary or historical, field data sharing variable.",
        "research_type": "ML methods paper with critical evaluation: Excellent code sharing (3 repositories). Historical field data not deposited (typical for legacy projects). Paper unusually transparent about ML failures and resource requirements.",
        "contextual_notes": "Refreshingly honest methods paper documenting ML failures rather than just successes. Excellent code transparency with three distinct GitHub repositories. CC BY 4.0 open access exemplary. Missing dataset deposition reflects common pattern with historical field data. Unusual transparency about time investment (135 person-hours) and validation failures (95-96% false negatives)."
      },
      "recommendations": [
        "Deposit TRAP field survey data in appropriate repository (tDAR, Open Context, Zenodo)",
        "Add ORCIDs for all authors in journal metadata",
        "Specify licences for GitHub code repositories (suggest MIT or CC0)",
        "Add explicit data availability statement for field data and training datasets",
        "Consider minting DOIs for stable code releases via Zenodo-GitHub integration",
        "Document dataset schemas/formats in repositories"
      ]
    },
    "extraction_metadata": {
      "extraction_date": "2025-11-03",
      "extractor": "claude-sonnet-4-5",
      "sections_examined": [
        "header",
        "title_page",
        "abstract",
        "copyright_statement",
        "funding_acknowledgement",
        "code_statement",
        "main_text",
        "references"
      ],
      "notes": "Journal of Documentation (Emerald) article published 2024 (received Aug 2022, accepted Feb 2024). CC BY 4.0 open access. ML methods paper critically evaluating CNN for burial mound detection. Excellent code sharing (3 GitHub repos), detailed methods including time/resource requirements. Missing: author ORCIDs, data availability statement, code licences. Notable transparency about ML failures and validation against field data. Uses historical TRAP (2009-2011) field survey data. Computation on UCloud HPC (University of Southern Denmark). Very high reference DOI coverage."
    }
  }
}
