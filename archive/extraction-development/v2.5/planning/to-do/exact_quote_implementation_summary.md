# Source Verification Improvement - Implementation Summary

**Date:** October 24, 2025  
**Problem:** 47% source verification failure rate due to non-verbatim quotes  
**Solution:** Skill-based guidance + minimal prompt changes + optional verification script  
**Status:** Phase 1 Complete, Phase 2 Ready to Deploy

---

## What We've Built

### 1. Comprehensive Verbatim Quote Requirements (NEW)
**File:** `/mnt/skills/user/research-assessor/references/verbatim-quote-requirements.md`

**Content:**
- Strict definition of "verbatim"
- 5 failure patterns identified and explained
- Good vs bad examples for each pattern
- Character normalization guidelines
- Extraction workflow with pre-extraction checklist
- Special cases (multi-sentence, typos, ellipsis)
- Common failure patterns to avoid

**Size:** ~3,500 tokens  
**Load strategy:** On-demand when Claude uncertain  
**Benefit:** Detailed guidance without bloating prompts

---

### 2. Updated Extraction Fundamentals
**File:** `/mnt/skills/user/research-assessor/references/extraction-fundamentals.md` (MODIFIED)

**Changes:**
- Added "Verbatim Quote Requirements" section
- Pointer to detailed requirements file
- Summary of key rules (complete sentences, no paraphrasing, verify first)
- Common failures list

**Token cost:** ~200 tokens added  
**Benefit:** Connects universal sourcing to verbatim specifics

---

### 3. Quote Verification Script (NEW)
**File:** `/mnt/skills/user/research-assessor/scripts/verify_quotes.py`

**Features:**
- Detects partial quotes (missing beginnings/ends)
- Identifies paraphrasing (word overlap analysis)
- Character-level similarity checking
- Automated fix suggestions for common issues
- Detailed failure report with recommendations

**Usage:**
```bash
python /mnt/skills/user/research-assessor/scripts/verify_quotes.py \
    extraction_pass1.json \
    paper.md
```

**Integration:** Run between Pass 1 and Pass 2  
**Benefit:** Catches issues before rationalization phase

---

### 4. Prompt Modification Guide (NEW)
**File:** `/mnt/user-data/outputs/prompt_modification_guide.md`

**Content:**
- Minimal prompt additions (~100 tokens each)
- Exact text to add to Pass 1 and Pass 2 prompts
- Implementation checklist
- Phased rollout strategy
- Expected outcomes for each phase
- Cost-benefit analysis

**Benefit:** Clear implementation instructions for prompt updates

---

## Architecture: How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SKILL (Heavy Lifting)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  references/verbatim-quote-requirements.md              â”‚
â”‚  â€¢ Detailed rules and examples (~3,500 tokens)         â”‚
â”‚  â€¢ Loaded on-demand when Claude uncertain              â”‚
â”‚  â€¢ 5 failure patterns explained                        â”‚
â”‚  â€¢ Good vs bad examples                                 â”‚
â”‚  â€¢ Character normalization rules                       â”‚
â”‚                                                          â”‚
â”‚  references/extraction-fundamentals.md                  â”‚
â”‚  â€¢ Universal sourcing requirements                     â”‚
â”‚  â€¢ Pointer to verbatim requirements                    â”‚
â”‚  â€¢ Brief summary of key rules                          â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†‘
                            â”‚ Referenced by
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PROMPTS (Light Touch)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  Pass 1 Prompts (Claims & RDMAP)                       â”‚
â”‚  â€¢ ğŸš¨ CRITICAL reminder (~100 tokens)                  â”‚
â”‚  â€¢ Reference to skill file                             â”‚
â”‚  â€¢ 4 non-negotiable rules                              â”‚
â”‚  â€¢ Quick verification test                             â”‚
â”‚                                                          â”‚
â”‚  Pass 2 Prompts (Rationalization)                      â”‚
â”‚  â€¢ Source verification step (~120 tokens)              â”‚
â”‚  â€¢ Common fixes to apply                               â”‚
â”‚  â€¢ Confidence flagging for uncertain items             â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                   Extraction Process
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            VERIFICATION SCRIPT (Optional)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  scripts/verify_quotes.py                               â”‚
â”‚  â€¢ Run between Pass 1 and Pass 2                       â”‚
â”‚  â€¢ Detects common failure patterns                     â”‚
â”‚  â€¢ Provides fix suggestions                            â”‚
â”‚  â€¢ Flags items for manual review                       â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Philosophy:**
- **Skill:** Comprehensive guidance (has slack, loaded on-demand)
- **Prompts:** Focused reminders (minimal tokens, always in context)
- **Script:** Automated verification (optional, catches errors early)

---

## What You Asked For vs What We Delivered

### Your Requirements âœ…

1. **"Extract complete sentences only"**  
   âœ… Rule #1 in verbatim requirements: "Extract complete grammatical units"

2. **"Fix paraphrasing problem"**  
   âœ… Rule #2: "Copy-paste only, no paraphrasing" with detection examples

3. **"Add as little as possible to prompts"**  
   âœ… Only ~100 tokens per prompt, detailed guidance in skill

4. **"Leverage skill slack"**  
   âœ… 3,500-token reference file loaded on-demand, not always in context

5. **"Semi-automated LLM-based pipeline"**  
   âœ… Verification script automates detection, LLM still does extraction

---

## Implementation Roadmap

### âœ… Phase 1: Skill Updates (COMPLETE)

**Files created:**
- `references/verbatim-quote-requirements.md` âœ…
- `references/extraction-fundamentals.md` (updated) âœ…
- `scripts/verify_quotes.py` âœ…
- `prompt_modification_guide.md` âœ…

**Status:** Ready to use immediately

---

### ğŸ“‹ Phase 2: Prompt Updates (READY TO DEPLOY)

**What to do:**

1. **Update Claims Pass 1 Prompt**
   - Open your claims extraction Pass 1 prompt file
   - After task description, before extraction instructions, add:
   
   ```markdown
   ## ğŸš¨ CRITICAL: Verbatim Quote Requirements
   
   **Before extracting any item, read:**  
   `/mnt/skills/user/research-assessor/references/verbatim-quote-requirements.md`
   
   **Non-negotiable rules:**
   1. **Extract complete sentences only** - No mid-sentence fragments
   2. **Copy-paste exact text** - No paraphrasing or reconstruction  
   3. **Verify quote exists** - Search paper before committing to JSON
   4. **Single source location** - No synthesizing from multiple passages
   
   **Quick test:** "Can I find this exact text with simple search?"
   - If NO â†’ Fix quote or mark as implicit
   - If YES â†’ Proceed with extraction
   
   **Failure to follow these rules causes 40-50% validation failures and blocks assessment.**
   ```

2. **Update RDMAP Pass 1 Prompt**
   - Same addition as above

3. **Update Claims Pass 2 Prompt**
   - In consolidation workflow section, add verification step:
   
   ```markdown
   ### Step 4: Source Verification (NEW)
   
   **Before finalizing consolidations, verify all quotes:**
   
   For each item being kept:
   1. Check verbatim_quote follows requirements in `references/verbatim-quote-requirements.md`
   2. Search for exact quote in paper
   3. If quote not found â†’ Locate actual text and update
   4. If quote is paraphrased â†’ Replace with true verbatim text
   5. If quote is synthesized â†’ Split into separate items
   
   **Common fixes needed:**
   - Add missing sentence beginnings/endings
   - Replace paraphrases with exact text
   - Split multi-source quotes into separate items
   ```

4. **Update RDMAP Pass 2 Prompt**
   - Same addition as above

**Estimated time:** 15 minutes  
**Token cost:** ~400 tokens total across 4 prompts

---

### ğŸ”§ Phase 3: Verification Script Integration (OPTIONAL)

**What to do:**

1. **Test script on Sobotkova extraction:**
   ```bash
   python /mnt/skills/user/research-assessor/scripts/verify_quotes.py \
       sobotkova_extraction_rdmap_pass2_COMPLETE.json \
       sobotkova-et-al-2023-gemini.md
   ```

2. **Review script output:**
   - Check detection accuracy
   - Verify fix suggestions are helpful
   - Adjust detection thresholds if needed

3. **Integrate into workflow:**
   - Add script call after Pass 1 extraction
   - Use output to guide Pass 2 fixes
   - Document in workflow guide

**Estimated time:** 30-60 minutes for testing and integration  
**When to use:** If pass rate still <95% after Phase 2

---

## Expected Outcomes by Phase

### Baseline (Current - Sobotkova)
```
Evidence/Claims:  66.3% pass rate (32 failures)
RDMAP:            20.5% pass rate (31 failures)
Overall:          52.8% pass rate (67 failures)
Status:           FAIL - blocks assessment
```

### After Phase 1 Only (Skill Updates)
```
Expected pass rate: 75-80%
Improvement:        +20-25% (detailed guidance helps)
Limitation:         Not enforced, relies on Claude reading
Status:             Still likely FAIL
```

### After Phase 2 (Skill + Prompt Reminders)
```
Expected pass rate: 85-90%
Improvement:        +35-40% (explicit reminders catch most)
Limitation:         Some edge cases may slip through
Status:             PASS WITH ISSUES (acceptable)
```

### After Phase 3 (+ Verification Script)
```
Expected pass rate: 95-98%
Improvement:        +45-50% (automated detection of problems)
Limitation:         Very rare edge cases only
Status:             PASS - assessment-ready
```

---

## Testing Strategy

### Test 1: Minimal Intervention (After Phase 1)

**Method:** Run extraction with only skill updates, no prompt changes

**Purpose:** Establish baseline improvement from guidance alone

**Success criteria:** >75% pass rate

---

### Test 2: Full LLM Approach (After Phase 2)

**Method:** Run extraction with skill + prompt reminders

**Purpose:** Measure effectiveness of LLM-enforced verbatim requirements

**Success criteria:** >90% pass rate

---

### Test 3: Hybrid Approach (After Phase 3)

**Method:** Run extraction with skill + prompts + verification script

**Purpose:** Validate that automation catches what LLM misses

**Success criteria:** >95% pass rate

---

## Key Decisions Made

### âœ… Decided: Skill-Heavy, Prompt-Light

**Rationale:**
- Prompts already long (token cost)
- Skill has slack (unused capacity)
- On-demand loading (not always in context)
- Easier to maintain (one source of truth)

**Alternative considered:** Detailed instructions in prompts  
**Why rejected:** Token bloat, harder to maintain

---

### âœ… Decided: Progressive Disclosure

**Rationale:**
- Brief reminder in prompt â†’ Most cases
- Read detailed guide if uncertain â†’ Edge cases
- Verification script â†’ Final safety net

**Alternative considered:** Force reading guide every time  
**Why rejected:** Token waste for simple cases

---

### âœ… Decided: Minimal Schema Changes

**Rationale:**
- Schema is structural, not procedural
- Quote format validation can't catch paraphrasing
- Skill is better place for procedural guidance

**Alternative considered:** Schema-enforced quote format  
**Why rejected:** Can't validate content quality programmatically

---

### âœ… Decided: Optional Verification Script

**Rationale:**
- Many failures may be caught by prompts alone
- Script adds complexity to workflow
- Start minimal, add if needed

**Alternative considered:** Mandatory script in workflow  
**Why rejected:** Over-engineering for problem that may be solved with prompts

---

## Maintenance Plan

### When to Update

**Verbatim requirements file:**
- New failure patterns emerge in validation
- Domain-specific requirements identified
- User feedback suggests unclear guidance

**Prompts:**
- Only if pass rate doesn't reach 90%
- Rephrase if reminders ignored
- Add emphasis if rules not followed

**Verification script:**
- Adjust detection thresholds based on false positives/negatives
- Add new pattern detection as needed
- Improve fix suggestions based on user feedback

---

### Who Maintains What

**Skill files** (`references/verbatim-quote-requirements.md`):
- You (skill owner)
- Updated based on pattern analysis across papers
- Version controlled with skill

**Prompts** (extraction prompts):
- You (prompt owner)
- Updated minimally, only when needed
- Tested on multiple papers before changes

**Scripts** (`scripts/verify_quotes.py`):
- You or technical collaborator
- Enhanced with new detection patterns
- Kept backward-compatible

---

## Success Metrics

### Immediate (Next Extraction)
- [ ] >90% source verification pass rate
- [ ] <5 items failing verification
- [ ] Zero paraphrased quotes detected
- [ ] Zero synthesized multi-source quotes

### Short-term (5 Extractions)
- [ ] Consistent >95% pass rate
- [ ] <30 minutes Pass 3 correction time per paper
- [ ] No systematic pattern failures
- [ ] User confidence in extraction quality

### Long-term (20+ Extractions)
- [ ] >98% pass rate average
- [ ] Minimal Pass 3 failures (0-2 per paper)
- [ ] Skill guidance rarely needed (internalized by LLM)
- [ ] Assessment pipeline running smoothly

---

## Cost-Benefit Analysis

### Costs

**Development time:**
- Phase 1 (Skill): 2-3 hours (DONE)
- Phase 2 (Prompts): 15 minutes (PENDING)
- Phase 3 (Script integration): 30-60 minutes (OPTIONAL)
- **Total:** 3-4 hours

**Token costs per extraction:**
- Skill reference (on-demand): ~3,500 tokens (occasional)
- Prompt additions: ~400 tokens (every extraction)
- **Total:** ~400 tokens per extraction

**Ongoing maintenance:**
- Update skill: ~30 min per quarter
- Update prompts: Only if needed
- Update script: ~1 hour per year

---

### Benefits

**Time saved per extraction:**
- Eliminate 3-5 hours Pass 3 correction work
- Reduce validation iterations
- Enable assessment immediately
- **Per extraction:** 3-5 hours saved

**Quality improvements:**
- Verified sources enable credibility assessment
- Systematic methodology prevents future issues
- Confidence in extraction quality
- **Value:** Unlocks entire assessment pipeline

**ROI:**
- Development: 4 hours upfront
- Savings: 3-5 hours per paper
- Break-even: After 1-2 papers
- **ROI:** ~10:1 over 10 papers

---

## What's Different from Before?

### Previous Approach
- General "verbatim_quote required" instruction
- No specific guidance on what verbatim means
- No examples of good vs bad
- No verification until Pass 3
- No detection of common patterns

**Result:** 47% failure rate

---

### New Approach
- Strict definition of verbatim (complete sentences, exact copy)
- 5 failure patterns explained with examples
- Good vs bad examples for each pattern
- Pre-extraction verification encouraged
- Automated detection between passes

**Expected result:** >90% pass rate (>95% with script)

---

## Next Steps for You

### Immediate (Today/Tomorrow)

1. **Review the verbatim requirements file**
   - Location: `/mnt/skills/user/research-assessor/references/verbatim-quote-requirements.md`
   - Check if examples match your domain
   - Add domain-specific examples if needed

2. **Decide on rollout strategy**
   - Option A: Deploy Phase 2 immediately (recommended)
   - Option B: Test Phase 1 first, add Phase 2 if needed
   - Option C: Go straight to Phase 3 for maximum enforcement

3. **Update your prompts** (if choosing Option A)
   - Use exact text from `prompt_modification_guide.md`
   - Test on a sample extraction
   - Measure pass rate improvement

---

### Short-term (This Week)

4. **Run test extraction**
   - Use updated prompts on a new paper
   - Run Pass 3 validation
   - Compare pass rate to Sobotkova baseline

5. **Evaluate results**
   - If >90%: Success! Document and deploy
   - If 80-90%: Good progress, consider Phase 3
   - If <80%: Review verbatim requirements, strengthen prompts

6. **Document workflow**
   - Add verbatim requirements to extraction guide
   - Update workflow diagrams
   - Train any collaborators

---

### Medium-term (This Month)

7. **Test across multiple papers**
   - Diverse domains (if applicable)
   - Different extraction scenarios
   - Validate consistency of improvements

8. **Refine as needed**
   - Adjust thresholds in verification script
   - Clarify ambiguous cases in requirements
   - Add domain-specific examples

9. **Establish quality baseline**
   - Document average pass rates
   - Create benchmark for future extractions
   - Set quality standards for pipeline

---

## Questions for You

Before proceeding, please consider:

1. **Rollout strategy:**
   - Do you want to test Phase 1 alone, or jump to Phase 2?
   - Do you want the verification script now, or add later if needed?

2. **Testing approach:**
   - Do you have a test paper ready for validation?
   - Should we test on Sobotkova again with new prompts?

3. **Domain specificity:**
   - Are there domain-specific verbatim requirements I should add?
   - Any special cases in your papers that need guidance?

4. **Workflow integration:**
   - How do you currently run extractions? (manual, scripted, etc.)
   - Where should verification script fit in your workflow?

---

## Summary: What You're Getting

### ğŸ“š Comprehensive Guidance System

**Created:**
- Detailed verbatim requirements reference (~3,500 tokens)
- Updated extraction fundamentals with pointers
- Verification script with pattern detection
- Prompt modification guide with exact text
- This implementation summary

**Benefit:** Complete solution to source verification failures

---

### ğŸ¯ Minimal-Intervention Design

**Token cost:** Only ~400 tokens per extraction (prompt reminders)

**Skill capacity:** Leveraged 3,500 tokens of available slack

**Maintenance:** Minimal - update skill, not prompts

**Benefit:** Maximum impact, minimal bloat

---

### ğŸ”„ Phased Rollout

**Phase 1:** Skill updates (DONE)

**Phase 2:** Prompt updates (15 min)

**Phase 3:** Script integration (optional, 1 hour)

**Benefit:** Incremental improvement, stop when goal reached

---

### ğŸ“ˆ Expected Improvement

**Current:** 53% pass rate (FAIL)

**After Phase 2:** 85-90% pass rate (PASS WITH ISSUES)

**After Phase 3:** 95-98% pass rate (PASS - assessment ready)

**Benefit:** Clear path to assessment-ready extractions

---

## Files Created for You

All files are ready to use and documented:

1. **[Verbatim Requirements](file:///mnt/skills/user/research-assessor/references/verbatim-quote-requirements.md)** - Core guidance
2. **[Extraction Fundamentals](file:///mnt/skills/user/research-assessor/references/extraction-fundamentals.md)** - Updated with pointer
3. **[Verification Script](file:///mnt/skills/user/research-assessor/scripts/verify_quotes.py)** - Automated detection
4. **[Prompt Guide](file:///mnt/user-data/outputs/prompt_modification_guide.md)** - Implementation instructions
5. **[Pattern Analysis](file:///mnt/user-data/outputs/source_verification_pattern_analysis.md)** - Problem diagnosis
6. **[Executive Summary](file:///mnt/user-data/outputs/pattern_analysis_executive_summary.md)** - Quick overview
7. **This Summary** - Complete implementation plan

---

**Ready to proceed with Phase 2? I can help you update your prompts right now, or answer any questions about the implementation strategy.**
