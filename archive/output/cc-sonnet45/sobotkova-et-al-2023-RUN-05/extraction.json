{
  "schema_version": "2.5",
  "paper_metadata": {
    "title": "Creating large, high-quality geospatial datasets from historical maps using novice volunteers",
    "authors": [
      "Adela Sobotkova",
      "Shawn A. Ross",
      "Christian Nassif-Haynes",
      "Brian Ballsun-Stanton"
    ],
    "year": 2023,
    "journal": "Applied Geography",
    "doi": "10.1016/j.apgeog.2023.102967"
  },
  "extraction_timestamp": "2025-10-27T06:42:02.793510Z",
  "extractor": "Claude Sonnet 4.5",
  "evidence": [
    {
      "evidence_id": "E001",
      "evidence_text": "FAIMS Mobile was used to digitise 10,827 mound features from Soviet military topographic maps",
      "evidence_type": "observation",
      "verbatim_quote": "FAIMS Mobile was used to digitise 10,827 mound features from Soviet military topographic maps.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_claims": [
        "C001",
        "C002",
        "C003"
      ]
    },
    {
      "evidence_id": "E002",
      "evidence_text": "Digitisation required 241 person-hours: 57 from staff and 184 from novice volunteers",
      "evidence_type": "measurement",
      "verbatim_quote": "This digitisation required 241 person-hours (57 from staff; 184 from novice volunteers), with an error rate under 6%.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_claims": [
        "C001",
        "C002",
        "C004"
      ]
    },
    {
      "evidence_id": "E003",
      "evidence_text": "Error rate under 6%",
      "evidence_type": "measurement",
      "verbatim_quote": "This digitisation required 241 person-hours (57 from staff; 184 from novice volunteers), with an error rate under 6%.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_claims": [
        "C005"
      ]
    },
    {
      "evidence_id": "E004",
      "evidence_text": "Dataset was consistent, well-documented, and ready for analysis with a few hours of processing",
      "evidence_type": "observation",
      "verbatim_quote": "The resulting dataset was consistent, well-documented, and ready for analysis with a few hours of processing.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_claims": [
        "C005",
        "C006"
      ]
    },
    {
      "evidence_id": "E005",
      "evidence_text": "Deployment occurred during 2017-2018 archaeological fieldwork in Bulgaria",
      "evidence_type": "observation",
      "verbatim_quote": "Deployed in Bulgaria as an ancillary activity during 2017\u20132018 archaeological fieldwork, FAIMS Mobile was used to digitise 10,827 mound features from Soviet military topographic maps.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_claims": [
        "C002"
      ]
    },
    {
      "evidence_id": "E006",
      "evidence_text": "An estimated 50,000 burial mounds were built in Bulgarian lands from the Early Bronze Age through the Middle Ages",
      "evidence_type": "measurement",
      "verbatim_quote": "An estimated 50,000 burial mounds were built in Bulgarian lands from the Early Bronze Age through the Middle Ages (Shkorpil & Shkorpil, 1989, p. 20; Kitov, 1993, p. 42).",
      "location": {
        "section": "Introduction",
        "subsection": "1.2 Burial mounds in Bulgarian archaeology",
        "page": 2,
        "paragraph": 1
      },
      "supported_claims": [
        "C013"
      ]
    },
    {
      "evidence_id": "E007",
      "evidence_text": "Mounds range in size from 10 to 50 m in diameter and 0.5\u201320 m in height",
      "evidence_type": "measurement",
      "verbatim_quote": "They were constructed of earth and rubble, and range in size from 10 to 50 m in diameter and 0.5\u201320 m in height (see Fig. 1).",
      "location": {
        "section": "Introduction",
        "subsection": "1.2 Burial mounds in Bulgarian archaeology",
        "page": 2,
        "paragraph": 1
      },
      "supported_claims": [
        "C013"
      ]
    },
    {
      "evidence_id": "E008",
      "evidence_text": "Between 2008 and 2016, TRAP catalogued 773 mounds in Kazanlak Valley and 431 mounds in Yambol region",
      "evidence_type": "measurement",
      "verbatim_quote": "Between 2008 and 2016, TRAP catalogued some 773 mounds in the Kazanlak Valley and 431 mounds in the Yambol region using pedestrian surface survey supported by manual digitisation of satellite imagery and maps.",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 3
      },
      "supported_claims": []
    },
    {
      "evidence_id": "E009",
      "evidence_text": "Desktop GIS approach in 2010 produced dataset of 915 features",
      "evidence_type": "measurement",
      "verbatim_quote": "Although we did not maintain detailed volunteer time-on-task records, we know this effort produced a dataset of 915 features and required about 5\u20137 h of staff training, support, and error-checking over a three-week period (based on our field journals).",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C028"
      ]
    },
    {
      "evidence_id": "E010",
      "evidence_text": "Desktop GIS approach in 2010 required 5-7 hours of staff training, support, and error-checking",
      "evidence_type": "measurement",
      "verbatim_quote": "Although we did not maintain detailed volunteer time-on-task records, we know this effort produced a dataset of 915 features and required about 5\u20137 h of staff training, support, and error-checking over a three-week period (based on our field journals).",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C028"
      ]
    },
    {
      "evidence_id": "E011",
      "evidence_text": "Soviet topographic maps available as georeferenced GeoTIFFs at 1:50,000 scale, dating to 1980s, each covering ca 400 sq km, containing symbols representing burial/settlement mounds at high density (averaging ~200 per tile, 0.5 per sq km)",
      "evidence_type": "observation",
      "verbatim_quote": "The goal of the work was to extract archaeological features from 1:50,000 scale Soviet military topographic maps dating to the 1980s. Available as georeferenced GeoTIFFs (from http://web.uni-plovdiv.bg/vedrin/index_en.html in 2008), each of these maps covers ca 400 sq km. We wished to extract symbols from them that might represent burial or settlement mounds in our study area (see Fig. 2). Such symbols occurred at a high density, averaging about 200 per tile (0.5 per sq km), with counts per tile ranging from about 50 to 400.",
      "location": {
        "section": "Approach",
        "subsection": "2.1 Archaeological features in Soviet topographic maps",
        "page": 4,
        "paragraph": 1
      },
      "supported_claims": [
        "C029"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E011",
          "E012",
          "E013",
          "E014"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Four observations about Soviet map characteristics all support same claim (C029) about data source properties. Never cited independently. Consolidated into single comprehensive map description."
      }
    },
    {
      "evidence_id": "E015",
      "evidence_text": "Students came from a range of academic backgrounds in Arts and Humanities",
      "evidence_type": "observation",
      "verbatim_quote": "Our students came from a range of academic backgrounds in Arts and Humanities.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 2
      },
      "supported_claims": [
        "C030"
      ]
    },
    {
      "evidence_id": "E016",
      "evidence_text": "Most students had no training in archaeology, cartography, or digital methods",
      "evidence_type": "observation",
      "verbatim_quote": "Most had no training in archaeology, cartography, or digital methods (unlike Pod\u02dd or, \u00a8 2015 or Can et al., 2021).",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 2
      },
      "supported_claims": [
        "C030"
      ]
    },
    {
      "evidence_id": "E017",
      "evidence_text": "In 2010, novice volunteers found learning desktop GIS challenging; many quit and those who continued required ongoing support",
      "evidence_type": "observation",
      "verbatim_quote": "Our experience was much like that of other projects: novice volunteers found learning to configure and navigate desktop GIS challenging; many quit and those who continued required ongoing support.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "supported_claims": [
        "C031",
        "C032"
      ]
    },
    {
      "evidence_id": "E018",
      "evidence_text": "In 2010, volunteer attrition combined with demands on staff time rendered desktop GIS approach unsuccessful",
      "evidence_type": "observation",
      "verbatim_quote": "In the end, volunteer attrition combined with demands on staff time during the height of fieldwork rendered this approach unsuccessful.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "supported_claims": [
        "C031",
        "C032"
      ]
    },
    {
      "evidence_id": "E019",
      "evidence_text": "Mobile application approach stripped GIS functionality to essentials: layer selection, shape digitisation, and annotation",
      "evidence_type": "observation",
      "verbatim_quote": "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validation and automation to improve data quality.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      },
      "supported_claims": [
        "C033",
        "C034"
      ]
    },
    {
      "evidence_id": "E020",
      "evidence_text": "Simple and intuitive UI allowed students to begin digitising after only minutes of training",
      "evidence_type": "observation",
      "verbatim_quote": "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only minutes of training.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      },
      "supported_claims": [
        "C033",
        "C034"
      ]
    },
    {
      "evidence_id": "E021",
      "evidence_text": "FAIMS Mobile works offline",
      "evidence_type": "observation",
      "verbatim_quote": "First, FAIMS Mobile worked offline.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 3
      },
      "supported_claims": [
        "C035"
      ]
    },
    {
      "evidence_id": "E022",
      "evidence_text": "Digitisation took place at field bases in rural Bulgaria where reliable internet connectivity could not be guaranteed",
      "evidence_type": "observation",
      "verbatim_quote": "Our digitisation took place alongside fieldwork, at field bases in rural Bulgaria. Reliable internet connectivity could not be guaranteed under these circumstances; a system that tolerated degraded network connectivity was required.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 3
      },
      "supported_claims": [
        "C035"
      ]
    },
    {
      "evidence_id": "E023",
      "evidence_text": "Only two of 12 students brought computers, and none brought mice, but all had mobile devices",
      "evidence_type": "measurement",
      "verbatim_quote": "This choice also reduced competition for the limited number of computers, ESRI licences, and desk space available in the field, plus it allowed students to use their own devices (only two of 12 students brought computers, and none brought mice, but all had mobile devices).",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 5,
        "paragraph": 3
      },
      "supported_claims": [
        "C036"
      ]
    },
    {
      "evidence_id": "E024",
      "evidence_text": "For 2017 season, creating Map Digitisation customisation required 35h from student programmer plus 4h from staff; in-field setup required 3h from staff; map preparation required 1.5h; file compression/transfer 2.5h; training/supervision 0.5h total",
      "evidence_type": "measurement",
      "verbatim_quote": "For the first season of use (2017), creating the Map Digitisation customisation of FAIMS Mobile required 35 h from an undergraduate student programmer plus 4 h from staff (Nassif-Haynes et al., 2021). Setup of the server and configuration of the client devices in the field required 3 h from staff. Map preparation (tiling, adding pyramids) required about 1.5 h. Monitoring file compression, upload to the server, and download to devices took an additional 2.5 h. Training and supervision of students took no more than half an hour of staff time across the entire season.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C037"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E024",
          "E025",
          "E026",
          "E028",
          "E029",
          "E030"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Six measurements of different time components all support same claim (C037) about 2017 setup time. Never cited independently. Consolidated into single compound finding preserving all measured components."
      }
    },
    {
      "evidence_id": "E027",
      "evidence_text": "Training and supervision of students took no more than half an hour of staff time across entire 2017 season",
      "evidence_type": "measurement",
      "verbatim_quote": "Training and supervision of students took no more than half an hour of staff time across the entire season.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C038",
        "C034"
      ]
    },
    {
      "evidence_id": "E031",
      "evidence_text": "In-field time during fieldwork to prepare maps and supervise participants was 7 h",
      "evidence_type": "measurement",
      "verbatim_quote": "Of this time, initial customisation and setup time before fieldwork was 44 h, while the time required during fieldwork to prepare and distribute maps, and then supervise participants, was 7 h.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C038"
      ]
    },
    {
      "evidence_id": "E032",
      "evidence_text": "FAIMS Mobile implementation included 7 stages: data modeling, customisation, SRS definition, shape drawing, attribute transcription, data export, accuracy checking",
      "evidence_type": "observation",
      "verbatim_quote": "The stages of FAIMS Mobile implementation (Fig. 3) included: (1) project staff modelled the data and workflow to ensure that the final dataset met research needs, (2) a junior software developer worked with project staff to customise the system, (3) project staff defined a spatial reference system (SRS) and imported preprocessed historical maps, (4) volunteers drew a shape (usually a point) wherever they saw a target symbol and (5) volunteers transcribed attributes from the map, (6) project staff exported data using the FAIMS Mobile server, (7) project staff undertook a targeted accuracy-checking exercise.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 1
      },
      "supported_claims": [
        "C039"
      ]
    },
    {
      "evidence_id": "E033",
      "evidence_text": "FAIMS Mobile automated spatial reference system, map rendering, layer management, shape topology, vocabularies, metadata, history, validation, data merging, and export",
      "evidence_type": "observation",
      "verbatim_quote": "It applied the spatial reference system, rendered maps in the workspace, provided layer management (including a data entry layer), enforced shape topology, displayed pre-defined controlled vocabularies for attribute terms, recorded creation time and author for each record, maintained a history of all changes to data, applied validation to ensure record completeness, merged data from multiple devices, and exported data in common formats.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 2
      },
      "supported_claims": [
        "C040",
        "C043",
        "C046"
      ]
    },
    {
      "evidence_id": "E034",
      "evidence_text": "Digitisation interface streamlined with map view for geospatial data interactions and form view for attribute creation/editing; volunteers could toggle between views, adjust layer focus/visibility, pan, zoom, and search/retrieve/inspect/edit existing records",
      "evidence_type": "observation",
      "verbatim_quote": "The digitisation interface itself was as streamlined as possible (see Figs. 4 and 5). Volunteers could toggle between a map view for geospatial data interactions and a form view for attribute creation and editing. In the map, they could adjust layer focus and visibility, pan, and zoom. Existing records could be searched, retrieved, inspected, and edited.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 4
      },
      "supported_claims": [
        "C041"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E034",
          "E035",
          "E036"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Three observations about interface features all support same claim (C041) about streamlining. Never cited independently. Consolidated into single interface description."
      }
    },
    {
      "evidence_id": "E037",
      "evidence_text": "Staff set up infrastructure and preprocessed and loaded maps",
      "evidence_type": "observation",
      "verbatim_quote": "Since project staff set up the infrastructure and pre-processed and loaded the required maps, volunteers were insulated from the friction of setup, layer management, data aggregation, export, and backup.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C039",
        "C042"
      ]
    },
    {
      "evidence_id": "E038",
      "evidence_text": "GIS features not needed for digitisation were hidden or eliminated",
      "evidence_type": "observation",
      "verbatim_quote": "GIS features not needed for digitisation were hidden or eliminated.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C033",
        "C041",
        "C042"
      ]
    },
    {
      "evidence_id": "E039",
      "evidence_text": "Digitisation and metadata creation required no GIS or computing skills",
      "evidence_type": "observation",
      "verbatim_quote": "Digitisation and metadata creation required no GIS or computing skills.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C043",
        "C033"
      ]
    },
    {
      "evidence_id": "E040",
      "evidence_text": "Students capable of basic tasks (selecting files, panning, zooming, dropping points, filling forms) could create data",
      "evidence_type": "observation",
      "verbatim_quote": "Students capable of selecting files from a list, panning and zooming a map, dropping a point, and filling out a form were able to create data.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C043",
        "C033"
      ]
    },
    {
      "evidence_id": "E041",
      "evidence_text": "Only few important controls were present: layer management, navigation, search, shape and attribute editing",
      "evidence_type": "observation",
      "verbatim_quote": "Only a few important controls, including layer management, map navigation, record search and retrieval, and shape and attribute creation and editing, were present.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C044"
      ]
    },
    {
      "evidence_id": "E042",
      "evidence_text": "Users required almost no training and could focus on digitisation without being distracted by technology",
      "evidence_type": "observation",
      "verbatim_quote": "As a result, users required almost no training and could focus on the act of digitisation without being distracted by the technology used to accomplish it (Pascoe et al., 2000).",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C034",
        "C045"
      ]
    },
    {
      "evidence_id": "E043",
      "evidence_text": "Exported data was consistent, complete, ready for analysis with minimal cleaning",
      "evidence_type": "observation",
      "verbatim_quote": "Exported data was consistent and complete, ready for analysis with minimal cleaning.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 2
      },
      "supported_claims": [
        "C005",
        "C046"
      ]
    },
    {
      "evidence_id": "E044",
      "evidence_text": "Data adhered to FAIR principles F2, R1.1-R1.3 through rich and plural metadata at time of creation",
      "evidence_type": "observation",
      "verbatim_quote": "This data adhered to key elements of the FAIR data principles, especially the production of 'rich' and 'plural' metadata at the time of data creation (principles F2, R1.1\u20131.3; GO-FAIR, 2017).",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 2
      },
      "supported_claims": [
        "C046"
      ]
    },
    {
      "evidence_id": "E045",
      "evidence_text": "Code defining customisation available on GitHub with description and user guide",
      "evidence_type": "observation",
      "verbatim_quote": "The code defining this customisation, along with a description and user guide, can be found on GitHub (https://github.com/FAIMS/map-digitisation/releases/tag/map-dig-2018).",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 3
      },
      "supported_claims": []
    },
    {
      "evidence_id": "E046",
      "evidence_text": "Success of approach became apparent early in 2017 field season",
      "evidence_type": "observation",
      "verbatim_quote": "The success of this approach became apparent early in the 2017 field season.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C047",
        "C048"
      ]
    },
    {
      "evidence_id": "E047",
      "evidence_text": "Decision made to catalogue inputs versus outputs as part of research program to evaluate digital fieldwork approaches",
      "evidence_type": "observation",
      "verbatim_quote": "At that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a research program to evaluate digital approaches to fieldwork (e.g., Sobotkova et al., 2016).",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 1
      },
      "supported_claims": [
        "C047",
        "C048"
      ]
    },
    {
      "evidence_id": "E048",
      "evidence_text": "Time data collated from programmer timesheets, student record creation timestamps, and staff journals logging time-on-task; feature count from digitisation output",
      "evidence_type": "observation",
      "verbatim_quote": "To measure inputs, we collated the amount of time spent by various participants in the process, including the student programmer who instantiated the customisation, the student volunteers who undertook the digitisation, and project staff who configured the system, supported volunteers, exported data, and checked for errors. Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project staff logged time-on-task for activities in journals. We took the number of features digitised as the output.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "supported_claims": [
        "C049"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E048",
          "E050",
          "E051"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Three observations about measurement data sources all support same claim (C049) about evaluation approach. Never cited independently. Consolidated into single methods description."
      }
    },
    {
      "evidence_id": "E049",
      "evidence_text": "Number of features digitised taken as the output measure",
      "evidence_type": "observation",
      "verbatim_quote": "We took the number of features digitised as the output.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "supported_claims": [
        "C047"
      ]
    },
    {
      "evidence_id": "E052",
      "evidence_text": "In 2017, system used for 125.8 person-hours concentrated across five rainy days",
      "evidence_type": "measurement",
      "verbatim_quote": "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days, during which time 8,343 features were digitised from 42 Soviet topographic maps (ca. 17,000 sq km).",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C050",
        "C051"
      ]
    },
    {
      "evidence_id": "E053",
      "evidence_text": "In 2017, 8,343 features were digitised from 42 Soviet topographic maps covering ca 17,000 sq km",
      "evidence_type": "measurement",
      "verbatim_quote": "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days, during which time 8,343 features were digitised from 42 Soviet topographic maps (ca. 17,000 sq km).",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C050",
        "C051"
      ]
    },
    {
      "evidence_id": "E054",
      "evidence_text": "In 2017, average time to record a point feature was 54 s based on device timestamps",
      "evidence_type": "measurement",
      "verbatim_quote": "The average time to record a point feature was 54 s, based on start and end times of feature creation as recorded by the devices (representing work time excluding pauses between records).",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C050"
      ]
    },
    {
      "evidence_id": "E055",
      "evidence_text": "In 2018, system used for 63.6 person-hours with more sporadic use",
      "evidence_type": "measurement",
      "verbatim_quote": "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation. The system was used for 63.6 person-hours, with 2,484 features recorded from 16 maps (ca. 6,500 sq km), an average rate of one record every 92 s.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C050",
        "C052"
      ]
    },
    {
      "evidence_id": "E056",
      "evidence_text": "In 2018, 2,484 features recorded from 16 maps covering ca 6,500 sq km",
      "evidence_type": "measurement",
      "verbatim_quote": "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation. The system was used for 63.6 person-hours, with 2,484 features recorded from 16 maps (ca. 6,500 sq km), an average rate of one record every 92 s.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C050"
      ]
    },
    {
      "evidence_id": "E057",
      "evidence_text": "In 2018, average digitisation rate was one record every 92 s",
      "evidence_type": "measurement",
      "verbatim_quote": "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation. The system was used for 63.6 person-hours, with 2,484 features recorded from 16 maps (ca. 6,500 sq km), an average rate of one record every 92 s.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C050",
        "C052"
      ]
    },
    {
      "evidence_id": "E058",
      "evidence_text": "In total, 10,827 point features (mostly burial and settlement mounds) recorded in 189.4 student-hours from 58 map tiles representing about 23,500 sq km",
      "evidence_type": "measurement",
      "verbatim_quote": "In total, 10,827 point features, mostly burial and settlement mounds, were recorded in 189.4 student-hours (63 s per record). Fifty-eight map tiles representing about 23,500 sq km were digitised.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 4
      },
      "supported_claims": [
        "C001",
        "C050"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E058",
          "E059",
          "E060",
          "E062"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Four measurements of total output (features, time, tiles, area) all support same claims (C001, C050) about overall productivity. Never cited independently. Consolidated into single total volume finding."
      }
    },
    {
      "evidence_id": "E061",
      "evidence_text": "Concentrated 2017 digitisation was more productive than intermittent 2018 work",
      "evidence_type": "observation",
      "verbatim_quote": "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets utilising time that might otherwise have been lost (e.g., to inclement weather), while requiring little supervision by project staff.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 4
      },
      "supported_claims": [
        "C051",
        "C052"
      ]
    },
    {
      "evidence_id": "E063",
      "evidence_text": "Work utilized time that might otherwise have been lost (e.g., to inclement weather)",
      "evidence_type": "observation",
      "verbatim_quote": "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets utilising time that might otherwise have been lost (e.g., to inclement weather), while requiring little supervision by project staff.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 4
      },
      "supported_claims": [
        "C038",
        "C051"
      ]
    },
    {
      "evidence_id": "E064",
      "evidence_text": "Work required little supervision by project staff",
      "evidence_type": "observation",
      "verbatim_quote": "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets utilising time that might otherwise have been lost (e.g., to inclement weather), while requiring little supervision by project staff.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 4
      },
      "supported_claims": [
        "C034",
        "C038"
      ]
    },
    {
      "evidence_id": "E065",
      "evidence_text": "2010 desktop GIS attempt produced 915 features but required 5-7 hours of staff training/support over three weeks; high-touch training and volunteer dislike prevented scaling; high cognitive load from desktop GIS on novice users led to poor outcomes",
      "evidence_type": "observation",
      "verbatim_quote": "TRAP had attempted an unsatisfactory digitisation effort in 2010 by students using ArcGIS. Although we did not maintain detailed volunteer time-on-task records, we know this effort produced a dataset of 915 features and required about 5\u20137 h of staff training, support, and error-checking over a three-week period (based on our field journals). The need for high-touch training and support by project staff during fieldwork, combined with a dislike for the activity on the part of students, prevented us from scaling up the use of desktop GIS for volunteer digitisation further, despite attempting to do so. These problems reflect the high cognitive load desktop GIS places on novice users.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C053"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E065",
          "E066",
          "E067"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Three observations about 2010 desktop GIS attempt (output, staff demands, cognitive load) all support same claim (C053) about desktop GIS limitations. Consolidated into single comparative finding."
      }
    },
    {
      "evidence_id": "E068",
      "evidence_text": "One persistent student accounted for almost all digitised features in 2010",
      "evidence_type": "observation",
      "verbatim_quote": "Indeed, one persistent student accounted for almost all the digitised features; without his perseverance, the digitisation effort would have failed entirely.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C031",
        "C053"
      ]
    },
    {
      "evidence_id": "E069",
      "evidence_text": "Without one persistent student, 2010 desktop GIS digitisation effort would have failed entirely",
      "evidence_type": "observation",
      "verbatim_quote": "Indeed, one persistent student accounted for almost all the digitised features; without his perseverance, the digitisation effort would have failed entirely.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C031",
        "C053"
      ]
    },
    {
      "evidence_id": "E070",
      "evidence_text": "Desktop GIS problems reflect high cognitive load placed on novice users",
      "evidence_type": "observation",
      "verbatim_quote": "These problems reflect the high cognitive load desktop GIS places on novice users.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 2
      },
      "supported_claims": [
        "C032",
        "C053"
      ]
    },
    {
      "evidence_id": "E071",
      "evidence_text": "Customised application met fundamental usability requirements",
      "evidence_type": "observation",
      "verbatim_quote": "By contrast, our customised application met fundamental usability requirements (e.g., Nielsen, 2012), both due to careful design of the customisation itself, and the underlying platform's implementation of Google's Material Design guidelines.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C033",
        "C054"
      ]
    },
    {
      "evidence_id": "E072",
      "evidence_text": "UI/UX approach from kinetic fieldwork translated well to map digitisation",
      "evidence_type": "observation",
      "verbatim_quote": "It also benefited from the UI/UX approach employed for kinetic fieldwork (e.g., Pascoe et al., 2000). The principle that the technology had to conform to the workflow, rather than vice versa, translated particularly well to map digitisation.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C054"
      ]
    },
    {
      "evidence_id": "E073",
      "evidence_text": "Result was simple, familiar mobile interface that let novices begin work with little training",
      "evidence_type": "observation",
      "verbatim_quote": "The result was a simple, familiar mobile application interface that let novices begin work with little training and helped them resume work after any hiatus.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C033",
        "C034",
        "C054"
      ]
    },
    {
      "evidence_id": "E074",
      "evidence_text": "Use of controlled vocabularies, automation, and validation reduced errors",
      "evidence_type": "observation",
      "verbatim_quote": "Use of controlled vocabularies, automation, and validation reduced errors.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C040",
        "C046",
        "C054"
      ]
    },
    {
      "evidence_id": "E075",
      "evidence_text": "Low volunteer attrition indicated satisfaction with experience",
      "evidence_type": "observation",
      "verbatim_quote": "Low volunteer attrition indicated satisfaction with the experience.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C053",
        "C054"
      ]
    },
    {
      "evidence_id": "E076",
      "evidence_text": "Volunteers could attain high digitisation rate quickly and maintain it",
      "evidence_type": "observation",
      "verbatim_quote": "Volunteers could attain a high rate of digitisation quickly and maintain it, although further design refinement could improve the ability of more experienced users to enter data even more quickly (for an example of an optimised system in another domain, see Noble et al., 2020, 2018).",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 3
      },
      "supported_claims": [
        "C050",
        "C054"
      ]
    },
    {
      "evidence_id": "E077",
      "evidence_text": "Performance degraded once approximately 2,500-3,000 records created; GPS coordinate extraction slowed from 3-5s to 30s; mitigated by exporting data and instantiating new empty application version",
      "evidence_type": "measurement",
      "verbatim_quote": "Automated testing of other customisations suggested that performance would degrade once approximately 3,000\u20136,000 records had been created. In use, automated extraction of coordinates from GPS into the Latitude/Longitude and Northing/Easting fields, which took three to 5 s with an empty database, took as long as 30 s once a device exceeded about 2,500 records. Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application.",
      "location": {
        "section": "Results",
        "subsection": "3.4 Application performance",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C055"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E077",
          "E078",
          "E079",
          "E080"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Four observations about performance (prediction, threshold, slowdown, mitigation) all support same claim (C055). Never cited independently. Consolidated into single performance degradation finding."
      }
    },
    {
      "evidence_id": "E081",
      "evidence_text": "Recoverable data omissions across both years totaled 223 (2.06% of records)",
      "evidence_type": "measurement",
      "verbatim_quote": "Recoverable data omissions across both years totaled 223 (2.06% of records), including 205 spatial and 18 attribute omissions.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.1 Recoverable data omissions and incomplete records",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C005",
        "C056"
      ]
    },
    {
      "evidence_id": "E082",
      "evidence_text": "Recoverable data omissions totaled 223 (2.06% of 10,827 records): 205 spatial omissions (empty lat/long fields due to users moving too quickly through forms) and 18 attribute omissions (missing map symbol specification); geodatabase preserved geometries allowing recovery",
      "evidence_type": "measurement",
      "verbatim_quote": "Recoverable data omissions across both years totaled 223 (2.06% of records), including 205 spatial and 18 attribute omissions. Most occurred in 2017 when 192 records (2.3%) had empty latitude and longitude fields and 17 (0.2%) were missing specification of the map symbol. Spatial data omissions resulted from a failure of the software to populate the latitude and longitude fields from the application's SpatiaLite geodatabase due to users moving through the forms too quickly (see 'Application performance' above). Since the geodatabase preserved geometries, spatial omissions were corrected by re-extracting latitude and longitude; only two data points could not be recovered.",
      "location": {
        "section": "Results",
        "subsection": "3.5.1 Recoverable data omissions and incomplete records",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C056"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E082",
          "E083",
          "E084",
          "E089"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Four measurements about data omissions (total, breakdown, cause, recovery) all support same claim (C056). Never cited independently. Consolidated into single comprehensive omissions finding."
      }
    },
    {
      "evidence_id": "E085",
      "evidence_text": "Spatial data omissions resulted from failure to populate lat/long from geodatabase due to users moving through forms too quickly",
      "evidence_type": "observation",
      "verbatim_quote": "Spatial data omissions resulted from a failure of the software to populate the latitude and longitude fields from the application's SpatiaLite geodatabase due to users moving through the forms too quickly (see 'Application performance' above).",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.1 Recoverable data omissions and incomplete records",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C055",
        "C056"
      ]
    },
    {
      "evidence_id": "E086",
      "evidence_text": "Before 2018 season, validation added addressing lat/long population problem, resulting in only 13 spatial errors and 1 attribute omission (0.52% vs 2.3% in 2017); fixable omissions delayed visualization/analysis but were recovered",
      "evidence_type": "measurement",
      "verbatim_quote": "Before the 2018 season, we added validation addressing this problem, resulting in only 13 spatial errors and one attribute omission (0.52%). Since the geodatabase preserved geometries, spatial omissions were corrected by re-extracting latitude and longitude; only two data points could not be recovered. Although fixable, these omissions delayed visualisation and analysis of the data.",
      "location": {
        "section": "Results",
        "subsection": "3.5.1 Recoverable data omissions and incomplete records",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C056",
        "C057"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E086",
          "E087",
          "E088"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Three measurements about 2018 improvements (validation, error reduction, recovery) all support same claims (C056, C057). Never cited independently. Consolidated into single improvement finding."
      }
    },
    {
      "evidence_id": "E090",
      "evidence_text": "Overall accuracy was high, over 94% for processed maps",
      "evidence_type": "measurement",
      "verbatim_quote": "Unlike some volunteer digitisation projects, overall accuracy was high, over 94% for processed maps.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C005",
        "C058"
      ]
    },
    {
      "evidence_id": "E091",
      "evidence_text": "Participants failed to digitise some assigned maps, leaving noticeable gaps",
      "evidence_type": "observation",
      "verbatim_quote": "First, participants failed to digitise some assigned maps, leaving noticeable gaps (see Fig. 6).",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C058"
      ]
    },
    {
      "evidence_id": "E092",
      "evidence_text": "Map omission was obvious and could be corrected in later digitising session",
      "evidence_type": "observation",
      "verbatim_quote": "This omission was obvious, and could be corrected in a later digitising session.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 7,
        "paragraph": 1
      },
      "supported_claims": [
        "C058"
      ]
    },
    {
      "evidence_id": "E093",
      "evidence_text": "Review of four randomly selected maps (7% of total) found 49 errors from 834 true features (5.87% error rate)",
      "evidence_type": "measurement",
      "verbatim_quote": "Second, a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error rate (see Table 3).",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_claims": [
        "C005",
        "C058"
      ]
    },
    {
      "evidence_id": "E094",
      "evidence_text": "Of 49 total errors from 834 features (5.87% error rate): 42 false negatives (missed symbols), 6 double-marked (digitised twice), 1 classification error, 0 false positives; 35 of 42 false negatives from one student failing to digitise three contiguous map sections",
      "evidence_type": "measurement",
      "verbatim_quote": "Second, a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error rate (see Table 3). Forty-two of these errors were false negatives (symbols missed by students). Six were double-marked (Student C digitised a section of a map twice). Students made only one classification error (a similar symbol mistaken for a benchmark), and no outright false positives. Moreover, 35 of the 49 false negatives were the result of Student C failing to digitise three contiguous sections of an assigned map.",
      "location": {
        "section": "Results",
        "subsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_claims": [
        "C058",
        "C059"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E094",
          "E095",
          "E096",
          "E097"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Four measurements about error patterns (total, breakdown, causes) all support same claims (C058, C059). Never cited independently. Consolidated into single comprehensive error analysis."
      }
    },
    {
      "evidence_id": "E098",
      "evidence_text": "Students' individual error rates ranged from 1.3% to 10.6%",
      "evidence_type": "measurement",
      "verbatim_quote": "Students' individual error rates ranged from 1.3% to 10.6%.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_claims": [
        "C058",
        "C060"
      ]
    },
    {
      "evidence_id": "E099",
      "evidence_text": "Two fastest digitisers (Students A and B, 44 and 45 s per feature) had lowest error rates (1.3% and 2.9%)",
      "evidence_type": "measurement",
      "verbatim_quote": "Note that the two fastest digitisers (Students A and B; 44 and 45 s per feature respectively) also had the lowest error rates (1.3 and 2.9%), while the two slowest (Students C and D; 61 and 73 s) had the highest error rates (10.6 and 7.4%).",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_claims": [
        "C060"
      ]
    },
    {
      "evidence_id": "E100",
      "evidence_text": "Two slowest digitisers (Students C and D, 61 and 73 s) had highest error rates (10.6% and 7.4%)",
      "evidence_type": "measurement",
      "verbatim_quote": "Note that the two fastest digitisers (Students A and B; 44 and 45 s per feature respectively) also had the lowest error rates (1.3 and 2.9%), while the two slowest (Students C and D; 61 and 73 s) had the highest error rates (10.6 and 7.4%).",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_claims": [
        "C060"
      ]
    },
    {
      "evidence_id": "E101",
      "evidence_text": "35 of 49 false negatives resulted from Student C failing to digitise three contiguous map sections",
      "evidence_type": "measurement",
      "verbatim_quote": "Moreover, 35 of the 49 false negatives were the result of Student C failing to digitise three contiguous sections of an assigned map.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_claims": [
        "C059",
        "C060"
      ]
    },
    {
      "evidence_id": "E102",
      "evidence_text": "Student C's errors made 10.6% error rate an outlier; excluding Student C would cut cumulative error rate in half to 2.8%",
      "evidence_type": "measurement",
      "verbatim_quote": "These mistakes made his error rate of 10.6% an outlier; excluding Student C would have cut the cumulative error rate in half to 2.8%.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_claims": [
        "C058",
        "C060"
      ]
    },
    {
      "evidence_id": "E103",
      "evidence_text": "Overall error rate of 5.9% exceeded expectations",
      "evidence_type": "measurement",
      "verbatim_quote": "Nevertheless, the overall rate of 5.9% exceeded our expectations.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 2
      },
      "supported_claims": [
        "C005",
        "C058"
      ]
    },
    {
      "evidence_id": "E104",
      "evidence_text": "Error pattern (mostly false negatives and double-marked features from contiguous sections) made them easy to identify and correct",
      "evidence_type": "observation",
      "verbatim_quote": "Moreover, the pattern of errors - mostly false negatives and double-marked features, mostly from contiguous map sections - made them relatively easy to identify and correct.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 2
      },
      "supported_claims": [
        "C059",
        "C061"
      ]
    },
    {
      "evidence_id": "E105",
      "evidence_text": "Simple expedients (assigning multiple students to same tiles or peer review) would likely eliminate most errors",
      "evidence_type": "observation",
      "verbatim_quote": "Simple expedients, such as assigning multiple students to digitise the same map tiles independently or assigning one student to review work by another, would likely eliminate most errors.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 2
      },
      "supported_claims": [
        "C061"
      ]
    },
    {
      "evidence_id": "E106",
      "evidence_text": "Even using staff time, it was much faster to check volunteer work than digitise from scratch",
      "evidence_type": "observation",
      "verbatim_quote": "Even using staff time, it was much faster to check volunteer work than digitise from scratch.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 2
      },
      "supported_claims": [
        "C004",
        "C061"
      ]
    },
    {
      "evidence_id": "E107",
      "evidence_text": "Project staff with desktop GIS experience could digitise at sustained rate of 60-75 features per staff-hour",
      "evidence_type": "measurement",
      "verbatim_quote": "After brief workspace setup, project staff with desktop GIS experience could digitise at a sustained rate of 60\u201375 features per staff-hour.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 2
      },
      "supported_claims": [
        "C062",
        "C069",
        "C070"
      ]
    },
    {
      "evidence_id": "E108",
      "evidence_text": "57 hours of staff time could produce 3,420-4,275 staff-digitised features at 60-75 features/hour",
      "evidence_type": "measurement",
      "verbatim_quote": "At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420\u20134,275 staff-digitised features",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 2
      },
      "supported_claims": [
        "C062"
      ]
    },
    {
      "evidence_id": "E109",
      "evidence_text": "Desktop GIS with volunteers: 130-180 features per staff-hour based on 2010 digitisation rate",
      "evidence_type": "measurement",
      "verbatim_quote": "Had specialist project staff instead trained and supervised volunteers to use desktop GIS for digitisation, based on our 2010 digitisation rate of 130\u2013180 features per staff-hour, 57 h might have produced 7,410\u201310,260 features.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 3
      },
      "supported_claims": [
        "C063",
        "C070"
      ]
    },
    {
      "evidence_id": "E110",
      "evidence_text": "57 hours of staff time using crowdsourcing system produced 10,827 features, approximately 190 features per staff-hour",
      "evidence_type": "measurement",
      "verbatim_quote": "By comparison, the 57 h of staff time required for our digitisation approach using a customisation of FAIMS Mobile produced 10,827 features, or about 190 features per staff-hour.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 4
      },
      "supported_claims": [
        "C064",
        "C069"
      ]
    },
    {
      "evidence_id": "E111",
      "evidence_text": "Only 21 of 57 staff hours came from project staff; other 36 hours from student programmer who could be outsourced",
      "evidence_type": "measurement",
      "verbatim_quote": "First, customisation of systems like FAIMS Mobile can be outsourced more easily than other project activities. Only 21 of the 57 h needed to support the system came from project staff, while the other 36 h were completed by a student programmer for a modest cost (ca. AUD $2,000).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 5
      },
      "supported_claims": [
        "C064"
      ]
    },
    {
      "evidence_id": "E112",
      "evidence_text": "21 internal staff hours represent digitisation rate of over 500 features per staff-hour",
      "evidence_type": "measurement",
      "verbatim_quote": "Those 21 internal staff hours represent a digitisation rate of over 500 features per staff-hour.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 1
      },
      "supported_claims": [
        "C064",
        "C069"
      ]
    },
    {
      "evidence_id": "E113",
      "evidence_text": "21 hours would have yielded just 1,260-1,575 features if staff digitised directly, or 2,730-3,780 supervising desktop GIS",
      "evidence_type": "measurement",
      "verbatim_quote": "Twenty-one hours would have yielded just 1,260\u20131,575 features if staff had digitised them directly, or 2,730\u20133,780 had we supervised students using desktop GIS.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 1
      },
      "supported_claims": [
        "C064"
      ]
    },
    {
      "evidence_id": "E114",
      "evidence_text": "In-field support for volunteers was only 7 hours across two seasons, representing about 1,550 features per in-field staff-hour",
      "evidence_type": "measurement",
      "verbatim_quote": "Across two seasons, in-field support for volunteers was only 7 h, representing about 1,550 features per in-field staff-hour.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "supported_claims": [
        "C065",
        "C069"
      ]
    },
    {
      "evidence_id": "E115",
      "evidence_text": "Seven hours in-field would only allow staff to directly digitise 420-525 features, or supervise digitisation of 910-1,260",
      "evidence_type": "measurement",
      "verbatim_quote": "Seven hours would only allow staff to directly digitise 420\u2013525 features, or supervise the digitisation of 910-1,260.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "supported_claims": [
        "C065"
      ]
    },
    {
      "evidence_id": "E116",
      "evidence_text": "Marginal cost for additional feature: 4.3 seconds of staff support per feature (from 13h support + QA)",
      "evidence_type": "measurement",
      "verbatim_quote": "Third, the marginal cost for each additional feature digitised is low. This figure includes in-field support and quality assurance (13 h), and translates to 4.3 s of staff support per additional feature.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "supported_claims": [
        "C066",
        "C067"
      ]
    },
    {
      "evidence_id": "E117",
      "evidence_text": "Preparing and distributing additional maps took only 6 minutes per map (6 hours for 58 maps)",
      "evidence_type": "measurement",
      "verbatim_quote": "Preparing and distributing additional maps took only 6 min per map (6 h for 58 maps).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "supported_claims": [
        "C066",
        "C067"
      ]
    },
    {
      "evidence_id": "E118",
      "evidence_text": "Adding another field season costs only one additional hour of setup time (based on 2018 redeployment)",
      "evidence_type": "measurement",
      "verbatim_quote": "Even adding another field season only costs one additional hour of setup time (based on our 2018 redeployment).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "supported_claims": [
        "C067"
      ]
    },
    {
      "evidence_id": "E119",
      "evidence_text": "In 2010 desktop GIS approach, demands on staff time never plateaued due to attrition and learning curve",
      "evidence_type": "observation",
      "verbatim_quote": "By comparison, in 2010, the demands on staff time related to volunteer support never plateaued, as attrition meant that we were constantly onboarding new volunteers, while the learning curve of desktop GIS meant that support time declined only slowly as students became more experienced.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "supported_claims": [
        "C067",
        "C053"
      ]
    },
    {
      "evidence_id": "E120",
      "evidence_text": "Desktop GIS approach caused continual stress/distraction from troubleshooting demands; volunteers perceived digitisation as burden (tethered to computer, tedious task), reducing morale and causing friction; mobile GIS switch nearly eliminated staff interventions and improved volunteer satisfaction",
      "evidence_type": "observation",
      "verbatim_quote": "First, the need for staff to be continually available to troubleshoot problems with desktop GIS, lest digitisation stall, provided a continual source of stress and distraction. Second, when desktop GIS was used, volunteers perceived digitisation as a burden. Tethered to a computer (which was also needed for other work), doing a time-consuming and tedious task, digitisation was one of the least popular activities, reducing morale and causing friction with other project activities and participants. The switch to a lightweight GIS running on mobile devices nearly eliminated the need for staff interventions and improved volunteer satisfaction.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 5
      },
      "supported_claims": [
        "C068"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E120",
          "E121",
          "E122"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Three observations about qualitative factors (staff stress, volunteer burden, mobile improvement) all support same claim (C068) about qualitative advantages. Consolidated into single comparative assessment."
      }
    },
    {
      "evidence_id": "E123",
      "evidence_text": "Urban Occupations Project required 1,250 hours of manual digitisation to create training data for ML",
      "evidence_type": "measurement",
      "verbatim_quote": "The ERC-funded Urban Occupations Project (Can, Gerrits, and Kabadayi 2021), however, provides one benchmark for judging when pursuing a ML approach might be worthwhile. This project reported 1,250 h of manual digitisation to create enough training data to classify roads visible in historical maps of the Ottoman Empire.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "supported_claims": [
        "C071",
        "C072"
      ]
    },
    {
      "evidence_id": "E124",
      "evidence_text": "Urban Occupations: ML expert spent seven days testing and fine tuning model after preprocessing and filtering",
      "evidence_type": "measurement",
      "verbatim_quote": "Using this input, and after additional preprocessing and filtering, an ML expert spent seven days testing and fine tuning the model.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "supported_claims": [
        "C071"
      ]
    },
    {
      "evidence_id": "E125",
      "evidence_text": "Urban Occupations ML approach digitised approximately 300,000 km of roads",
      "evidence_type": "measurement",
      "verbatim_quote": "The output was impressive: some 300,000 km of roads were digitised.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "supported_claims": [
        "C071"
      ]
    },
    {
      "evidence_id": "E126",
      "evidence_text": "ML approach required minimum 1,300 hours preparation time (1,250h digitisation + 7 days expert)",
      "evidence_type": "measurement",
      "verbatim_quote": "This example, which appears to have required a minimum of about 1,300 h of preparation time alone, suggests that ML approaches are worthwhile for large-scale projects that benefit from the consistent symbology and style (as found in British and Ottoman imperial maps).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "supported_claims": [
        "C071"
      ]
    },
    {
      "evidence_id": "E127",
      "evidence_text": "TRAP spent 241 hours total (44 staff + 184 volunteer + 7 support + 6 QA) producing 10,827 features = 44.9 features/person-hour",
      "evidence_type": "measurement",
      "verbatim_quote": "We spent 44 staff hours customising and deploying a streamlined geospatial system in FAIMS Mobile, 184 participant-hours digitising features, seven staff-hours directly supporting that digitisation, and six staff hours checking for errors. These 241 h produced a dataset of 10,827 features, a rate of 44.9 features/person-hour.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "supported_claims": [
        "C069",
        "C071"
      ]
    },
    {
      "evidence_id": "E128",
      "evidence_text": "At TRAP rate (44.9 features/hour), 1,300 hours (ML prep time) would yield approximately 58,400 records",
      "evidence_type": "measurement",
      "verbatim_quote": "At that rate, the 1,300 h it took to deploy the ML approach taken by Can, Gerrits, and Kabadayi would yield about 58,400 records",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "supported_claims": [
        "C069",
        "C071"
      ]
    },
    {
      "evidence_id": "E129",
      "evidence_text": "ML model training requires manually produced dataset and manual error-checking; datasets big enough for ML likely need training data big enough for crowdsourcing; crowdsourcing platform can be reused for ML quality assurance",
      "evidence_type": "observation",
      "verbatim_quote": "Finally, since training a model requires a manually produced dataset and a degree of manual error-checking, a combination of ML and crowdsourcing approaches might serve even large-scale projects. A dataset big enough to justify ML will likely need a training dataset big enough to warrant crowdsourcing, especially if the features or background are variable. Once the crowdsourcing platform has been built, moreover, it can be used to produce additional datasets for error-checking to confirm the accuracy of the ML results. Our approach can also be used to produce the training datasets needed for ML, and as a tool for quality assurance for ML outputs.",
      "location": {
        "section": "Discussion",
        "subsection": "4.2 Combining crowdsourcing and ML approaches",
        "page": 10,
        "paragraph": 1
      },
      "supported_claims": [
        "C072"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E129",
          "E130",
          "E131",
          "E142"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Four observations about ML-crowdsourcing complementarity all support same claim (C072). Never cited independently. Consolidated into single argument about combined approach."
      }
    },
    {
      "evidence_id": "E132",
      "evidence_text": "Typical HASS project may lack personnel/infrastructure for ML but can deploy crowdsourcing; digital humanist at Software Carpentry skill level can customise platforms like FAIMS Mobile; entire class of customisable mobile GIS software exists (ArcGIS Field Maps, QField, Mergin Maps, GeoODK)",
      "evidence_type": "observation",
      "verbatim_quote": "Today, a typical project in history or archaeology - often small, under-resourced, and pursuing several research activities - may not be able to dedicate the personnel, infrastructure, or attention needed to incorporate ML successfully, but could deploy a collaborative geospatial system for crowdsourcing map digitisation. A project with a digital humanist or similar technologist with skills at the level of core Software Carpentry lessons (TheCarpentries, 2023) can customise and operate a generalised platform such as FAIMS Mobile to implement an effective crowdsourcing system. An entire class of software for customisable geospatial data collection on mobile devices exists (e.g., ArcGIS Field Maps, QField, Mergin Maps, or GeoODK).",
      "location": {
        "section": "Discussion",
        "subsection": "4.3 Overall feasibility",
        "page": 10,
        "paragraphs": "1-2"
      },
      "supported_claims": [
        "C073"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "E132",
          "E133",
          "E134"
        ],
        "consolidation_type": "identical_support_pattern",
        "information_preserved": "complete",
        "rationale": "Three observations about HASS project capabilities (constraints, skills, tools) all support same claim (C073) about feasibility. Consolidated into single feasibility assessment."
      }
    },
    {
      "evidence_id": "E135",
      "evidence_text": "Many mobile GIS systems attempt to make customisation as easy as possible, goal of recent FAIMS redevelopment",
      "evidence_type": "observation",
      "verbatim_quote": "Many of these systems attempt to make customisation as easy as possible, a goal at the heart of recent FAIMS redevelopment (ARDC, 2022); in future the technical barriers to deploying such systems will likely decline.",
      "location": {
        "section": "Discussion",
        "subsection": "4.3 Overall feasibility",
        "page": 10,
        "paragraph": 2
      },
      "supported_claims": [
        "C074"
      ]
    },
    {
      "evidence_id": "E136",
      "evidence_text": "Total digitisation time: 57 staff-hours, 184 volunteer-hours, 241 total person-hours",
      "evidence_type": "measurement",
      "verbatim_quote": "The deployment of the Map Digitisation FAIMS Mobile customisation facilitated the rapid digitisation (57 staff-hours; 184 volunteer-hours; 241 total) of 10,827 features found in Soviet topographic maps",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 2
      },
      "supported_claims": [
        "C075",
        "C076"
      ]
    },
    {
      "evidence_id": "E137",
      "evidence_text": "Comprehensive, FAIR-compliant dataset ready for analysis with less than 2 hours of processing after collection",
      "evidence_type": "measurement",
      "verbatim_quote": "All collected data was available daily for review, and a comprehensive, FAIR-compliant dataset was ready for analysis with less than 2 h of processing after collection.",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 2
      },
      "supported_claims": [
        "C075",
        "C005"
      ]
    },
    {
      "evidence_id": "E138",
      "evidence_text": "Payoff threshold approximately 4,500 features versus expert staff digitisation using desktop GIS",
      "evidence_type": "measurement",
      "verbatim_quote": "If staff time is the primary limiting resource, our approach becomes worthwhile for datasets no larger than about 4,500 features versus direct digitisation of features by expert staff",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 3
      },
      "supported_claims": [
        "C062",
        "C070"
      ]
    },
    {
      "evidence_id": "E139",
      "evidence_text": "Payoff threshold approximately 10,000 features versus volunteer digitisation using desktop GIS",
      "evidence_type": "measurement",
      "verbatim_quote": "and no larger than about 10,000 features versus volunteer digitisation using desktop GIS.",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 3
      },
      "supported_claims": [
        "C063",
        "C070"
      ]
    },
    {
      "evidence_id": "E140",
      "evidence_text": "Approach may pay off for fewer than 1,000 features if project staff time is at premium",
      "evidence_type": "measurement",
      "verbatim_quote": "It may pay off for fewer than 1,000 if project staff time is at a premium.",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 3
      },
      "supported_claims": [
        "C065",
        "C069"
      ]
    },
    {
      "evidence_id": "E141",
      "evidence_text": "Crowdsourcing remains most efficient approach for datasets up to at least 60,000 features",
      "evidence_type": "measurement",
      "verbatim_quote": "It remains the most efficient approach for datasets up to at least 60,000 features, above which automated approaches like ML should be considered.",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 3
      },
      "supported_claims": [
        "C069",
        "C071"
      ]
    }
  ],
  "claims": [
    {
      "claim_id": "C001",
      "claim_text": "Crowdsourcing approach produced large, high-quality geospatial dataset",
      "claim_role": "core",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Here we present a customisation of the Field Acquired Information Management Systems (FAIMS) Mobile platform tailored to offer a streamlined, collaborative system for crowdsourcing map digitisation by volunteers with no prior GIS experience.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [
        "C002",
        "C003",
        "C004",
        "C005"
      ],
      "supported_by_evidence": [
        "E001",
        "E002",
        "E004"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C002",
      "claim_text": "FAIMS Mobile customisation enabled effective crowdsourcing with minimal training",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Deployed in Bulgaria as an ancillary activity during 2017\u20132018 archaeological fieldwork, FAIMS Mobile was used to digitise 10,827 mound features from Soviet military topographic maps.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [
        "C004",
        "C005"
      ],
      "supported_by_evidence": [
        "E001",
        "E002",
        "E005"
      ],
      "supports_claims": [
        "C001"
      ]
    },
    {
      "claim_id": "C003",
      "claim_text": "Crowdsourcing approach is most efficient for digitisation projects of 10,000-60,000 features",
      "claim_role": "core",
      "claim_type": "interpretation",
      "verbatim_quote": "A conservative estimate based on our work suggests our crowdsourcing approach is most efficient for digitisation projects of 10,000\u201360,000 features, but may offer advantages for datasets as small as a few hundred records.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [
        "C026",
        "C027",
        "C028"
      ],
      "supported_by_evidence": [
        "E001"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C004",
      "claim_text": "Volunteer-based digitisation was resource-efficient compared to alternatives",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "This digitisation required 241 person-hours (57 from staff; 184 from novice volunteers), with an error rate under 6%.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E002"
      ],
      "supports_claims": [
        "C001",
        "C002"
      ]
    },
    {
      "claim_id": "C005",
      "claim_text": "Crowdsourcing approach produced high-quality, analysis-ready data",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "The resulting dataset was consistent, well-documented, and ready for analysis with a few hours of processing.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E003",
        "E004"
      ],
      "supports_claims": [
        "C001",
        "C002"
      ]
    },
    {
      "claim_id": "C006",
      "claim_text": "Systems designed for field data collection can be profitably customised for participatory geospatial data systems accessible to novices",
      "claim_role": "core",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Furthermore, it indicates that systems designed for field data collection, running on mobile devices, can be profitably customised to serve as participatory geospatial data systems accessible to novice volunteers.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [
        "C001",
        "C002"
      ],
      "supported_by_evidence": [
        "E004"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C007",
      "claim_text": "Unlocking data from historical maps for landscape analysis is costly",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Unlocking data from historical maps for landscape analysis is costly.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E001"
      ],
      "supports_claims": [
        "C001"
      ]
    },
    {
      "claim_id": "C008",
      "claim_text": "Machine Learning requires extensive preparation and expertise",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Automatic extraction using Machine Learning (ML) requires extensive preparation and expertise.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C001",
        "C003"
      ]
    },
    {
      "claim_id": "C009",
      "claim_text": "Crowdsourcing scales better than direct digitisation by experts but requires appropriate platform and technical skills",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Crowdsourcing scales better than direct digitisation by experts, but requires an appropriate platform and the technical skills to adapt it.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C001",
        "C002"
      ]
    },
    {
      "claim_id": "C010",
      "claim_text": "Existing research provides little guidance on when investments in different digitisation approaches become worthwhile",
      "claim_role": "supporting",
      "claim_type": "gap",
      "verbatim_quote": "Existing research provides little guidance as to when investments in these approaches become worthwhile.",
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C003"
      ]
    },
    {
      "claim_id": "C011",
      "claim_text": "Approach complements Machine Learning by requiring less technical expertise, time, and resourcing",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "It complements Machine Learning (ML) and other automated approaches in that it requires less technical expertise, time, and resourcing to undertake.",
      "location": {
        "section": "Introduction",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C001",
        "C003"
      ]
    },
    {
      "claim_id": "C012",
      "claim_text": "Approach is suitable for small to mid-sized datasets that don't warrant ML investment",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Such an approach is suitable for projects working with small to mid-sized data sources (100s\u201310,000s of features) that do not warrant the investment needed for successful ML-based data extraction - as well as for exploratory work preceding automated analyses or the production of the training and quality assurance datasets needed for ML.",
      "location": {
        "section": "Introduction",
        "page": 1,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C003",
        "C011"
      ]
    },
    {
      "claim_id": "C013",
      "claim_text": "Burial mounds are archaeologically and culturally significant",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "The mounds and their contents are important archaeologically as they attest to demographics, social complexity, international connections, and other important historical questions.",
      "location": {
        "section": "Introduction",
        "subsection": "1.2 Burial mounds in Bulgarian archaeology",
        "page": 2,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E006",
        "E007"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C014",
      "claim_text": "Burial mounds are endangered and require systematic recording",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Burial mounds are an irreplaceable - but endangered - aspect of Bulgarian cultural heritage, making their systematic recording and registration an urgent undertaking for both research and cultural heritage management.",
      "location": {
        "section": "Introduction",
        "subsection": "1.2 Burial mounds in Bulgarian archaeology",
        "page": 2,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": []
    },
    {
      "claim_id": "C015",
      "claim_text": "Historical maps help heritage specialists analyse change over time",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Historical maps help heritage specialists analyse change over time in order to monitor and mitigate the impact of urban development, climate change, biodiversity loss, erosion, agricultural extensification, and other kinds of land use and environmental changes (Rondelli, Stride, and Garc\u00eda-Granero 2013; Petrie et al., 2018).",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 2,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": []
    },
    {
      "claim_id": "C016",
      "claim_text": "Value of historical maps has been underexploited due to manual digitisation challenges",
      "claim_role": "supporting",
      "claim_type": "gap",
      "verbatim_quote": "The value of such maps has, however, been underexploited due to the entailed process of manual digitisation needed to transform their analogue information into machine-readable data.",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 2,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C001"
      ]
    },
    {
      "claim_id": "C017",
      "claim_text": "Manual desktop GIS digitisation is time-consuming and requires specialised skills",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Manually drawing and annotating shapes in historical maps using a desktop GIS is time-consuming and requires specialised skills (Can, Gerrits, and Kabadayi 2021; Petrie et al., 2018; Jones & Weber, 2012).",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 2,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C007",
        "C009",
        "C016"
      ]
    },
    {
      "claim_id": "C018",
      "claim_text": "Desktop GIS scalability is limited by difficulty of training and supporting novice users",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Its principal limitations are difficulty of scaling the effort, particularly restricted time and availability of expert users to either undertake digitisation themselves, or to train and support novices to the extent required for efficient and accurate work (see also Jessop, 2007 for other challenges).",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 2,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C017"
      ]
    },
    {
      "claim_id": "C019",
      "claim_text": "ML has unmatched potential for large-scale digitisation but requires specific programming expertise",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "ML has unmatched potential for large-scale data digitisation, but it requires specific programming expertise, and familiarity with the capabilities and limitations of ML.",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C008",
        "C011"
      ]
    },
    {
      "claim_id": "C020",
      "claim_text": "Naive use of ML likely produces biased or unreliable results",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Naive use of ML is likely to produce biased or otherwise unreliable results (Mehrabi et al., 2021; Schwemmer et al., 2020; Besse et al., 2018; Fuchs, 2018; Haas, 2017), even if pretrained image recognition models are used (Jiang et al., 2022).",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C019"
      ]
    },
    {
      "claim_id": "C021",
      "claim_text": "ML expertise is difficult to attract to smaller HASS projects",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "This technical expertise is in high demand, and may be difficult to attract to the smaller humanities and social sciences (HASS) projects that undertake much of this digitisation.",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C019"
      ]
    },
    {
      "claim_id": "C022",
      "claim_text": "ML requires manual creation of training data and quality assurance",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Training an algorithm, moreover, requires manual creation and preparation of training data and manual quality assurance (Bennett et al., 2014; Can & Kabadayi, 2021).",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C019"
      ]
    },
    {
      "claim_id": "C023",
      "claim_text": "Crowdsourcing can expand scope of map digitisation",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Crowdsourcing can expand the scope of map digitisation.",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C009"
      ]
    },
    {
      "claim_id": "C024",
      "claim_text": "Volunteers lack the skills necessary to use GIS software",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Volunteers often lack the skills necessary to use GIS software (Elwood, 2008b; Jones & Weber, 2012; Owen et al., 2009).",
      "location": {
        "section": "Introduction",
        "subsection": "1.4 Sociotechnical barriers to collaborative map digitisation",
        "page": 3,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C018"
      ]
    },
    {
      "claim_id": "C025",
      "claim_text": "Digital divide can be bridged through expert training and guidance but approach scales poorly",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "This 'digital divide' can be bridged in part through more expert training and guidance of novice users (Owen et al., 2009, p. 24). Such an approach scales poorly, however; the supply of expert time available to any project is restricted and often oversubscribed, while the willingness of volunteers to learn specialised skills and software has limits.",
      "location": {
        "section": "Introduction",
        "subsection": "1.4 Sociotechnical barriers to collaborative map digitisation",
        "page": 3,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C018",
        "C024"
      ]
    },
    {
      "claim_id": "C026",
      "claim_text": "Crowdsourcing offers advantages compared to alternative approaches under many map digitisation scenarios",
      "claim_role": "core",
      "claim_type": "methodological_argument",
      "verbatim_quote": "This paper argues that crowdsourcing offers advantages compared to alternative approaches under many, if not most, map digitisation scenarios.",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 4
      },
      "supported_by_claims": [
        "C027",
        "C028"
      ],
      "supported_by_evidence": [],
      "supports_claims": [
        "C003"
      ]
    },
    {
      "claim_id": "C027",
      "claim_text": "Crowdsourcing requires more upfront investment than desktop GIS but scales better",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Crowdsourcing requires more upfront investment in system setup than using available GIS specialists or training and supervising volunteers using desktop GIS, but it scales better in the face of likely constraints related to expert staffing and volunteer attrition.",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": [
        "C026",
        "C003"
      ]
    },
    {
      "claim_id": "C028",
      "claim_text": "Crowdsourcing requires less specialised expertise and time than ML",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Compared to ML, it requires less specialised and hard-to-come-by expertise, requires less time for initial setup, and produces high-quality datasets with more predictable errors.",
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E009",
        "E010"
      ],
      "supports_claims": [
        "C026",
        "C003"
      ]
    },
    {
      "claim_id": "C029",
      "claim_text": "Soviet topographic maps contained high-density, moderately obtrusive mound symbols suitable for digitisation",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Such symbols occurred at a high density, averaging about 200 per tile (0.5 per sq km), with counts per tile ranging from about 50 to 400.",
      "location": {
        "section": "Approach",
        "subsection": "2.1 Archaeological features in Soviet topographic maps",
        "page": 4,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E011",
        "E012",
        "E013",
        "E014"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C030",
      "claim_text": "Field school students were novices in archaeology, cartography, and digital methods",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Most had no training in archaeology, cartography, or digital methods (unlike Pod\u02dd or, \u00a8 2015 or Can et al., 2021).",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E015",
        "E016"
      ],
      "supports_claims": [
        "C002"
      ]
    },
    {
      "claim_id": "C031",
      "claim_text": "2010 desktop GIS digitisation attempt was unsuccessful due to volunteer attrition and staff demands",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "In the end, volunteer attrition combined with demands on staff time during the height of fieldwork rendered this approach unsuccessful.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E017",
        "E018"
      ],
      "supports_claims": [
        "C027",
        "C032"
      ]
    },
    {
      "claim_id": "C032",
      "claim_text": "Desktop GIS approach was unsuccessful due to difficulty training novice volunteers",
      "claim_role": "supporting",
      "claim_type": "background",
      "verbatim_quote": "Our experience was much like that of other projects: novice volunteers found learning to configure and navigate desktop GIS challenging; many quit and those who continued required ongoing support.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E017",
        "E018"
      ],
      "supports_claims": [
        "C018",
        "C024",
        "C031"
      ]
    },
    {
      "claim_id": "C033",
      "claim_text": "Streamlined mobile approach empowered volunteers to digitise independently with minimal training",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Our approach sought to help novice users begin digitising quickly and then work productively for the duration of each field season with minimal support or frustration.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      },
      "supported_by_claims": [
        "C034"
      ],
      "supported_by_evidence": [
        "E019",
        "E020"
      ],
      "supports_claims": [
        "C002",
        "C006"
      ]
    },
    {
      "claim_id": "C034",
      "claim_text": "Simple UI allowed students to begin digitising after only minutes of training",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only minutes of training.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E020",
        "E027"
      ],
      "supports_claims": [
        "C033",
        "C002"
      ]
    },
    {
      "claim_id": "C035",
      "claim_text": "Offline capability was essential for field-based digitisation in rural Bulgaria",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Reliable internet connectivity could not be guaranteed under these circumstances; a system that tolerated degraded network connectivity was required.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E021",
        "E022"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C036",
      "claim_text": "Mobile devices were more available than computers for field school participants",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "This choice also reduced competition for the limited number of computers, ESRI licences, and desk space available in the field, plus it allowed students to use their own devices (only two of 12 students brought computers, and none brought mice, but all had mobile devices).",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 5,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E023"
      ],
      "supports_claims": [
        "C033"
      ]
    },
    {
      "claim_id": "C037",
      "claim_text": "Customisation and setup required modest upfront investment of staff time",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Across both seasons, customisation, setup, and supervision took about 51 h, including 36 h from the programmer and 15 from project staff.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E024",
        "E025",
        "E026",
        "E028",
        "E029",
        "E030"
      ],
      "supports_claims": [
        "C027"
      ]
    },
    {
      "claim_id": "C038",
      "claim_text": "In-field staff time demands were minimal",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Of this time, initial customisation and setup time before fieldwork was 44 h, while the time required during fieldwork to prepare and distribute maps, and then supervise participants, was 7 h.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E027",
        "E031"
      ],
      "supports_claims": [
        "C004"
      ]
    },
    {
      "claim_id": "C039",
      "claim_text": "Workflow moved technical activities to specialist phases while simplifying volunteer tasks",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "This approach moved activities requiring technical expertise to phases where specialists could contribute, while simplifying the tasks assigned to student volunteers as much as possible.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E032",
        "E037"
      ],
      "supports_claims": [
        "C033",
        "C002"
      ]
    },
    {
      "claim_id": "C040",
      "claim_text": "FAIMS Mobile automated necessary tasks to make work easier for staff and participants",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "To support this workflow and make work easier for both project staff and participants, FAIMS Mobile automated a number of tasks and provided necessary capabilities.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E033"
      ],
      "supports_claims": [
        "C039",
        "C043"
      ]
    },
    {
      "claim_id": "C041",
      "claim_text": "Digitisation interface was streamlined as much as possible",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "The digitisation interface itself was as streamlined as possible (see Figs. 4 and 5).",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E034",
        "E035",
        "E036"
      ],
      "supports_claims": [
        "C033",
        "C045"
      ]
    },
    {
      "claim_id": "C042",
      "claim_text": "Volunteers were insulated from technical friction of setup and data management",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Since project staff set up the infrastructure and pre-processed and loaded the required maps, volunteers were insulated from the friction of setup, layer management, data aggregation, export, and backup.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E037",
        "E038"
      ],
      "supports_claims": [
        "C039",
        "C033"
      ]
    },
    {
      "claim_id": "C043",
      "claim_text": "Digitisation and metadata creation required no GIS or computing skills",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Digitisation and metadata creation required no GIS or computing skills.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E039",
        "E040"
      ],
      "supports_claims": [
        "C033",
        "C034"
      ]
    },
    {
      "claim_id": "C044",
      "claim_text": "Only few important controls were present in interface",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Only a few important controls, including layer management, map navigation, record search and retrieval, and shape and attribute creation and editing, were present.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E041"
      ],
      "supports_claims": [
        "C041",
        "C045"
      ]
    },
    {
      "claim_id": "C045",
      "claim_text": "Users could focus on digitisation without being distracted by technology",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "As a result, users required almost no training and could focus on the act of digitisation without being distracted by the technology used to accomplish it (Pascoe et al., 2000).",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E042"
      ],
      "supports_claims": [
        "C033",
        "C034"
      ]
    },
    {
      "claim_id": "C046",
      "claim_text": "Exported data was FAIR-compliant",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "This data adhered to key elements of the FAIR data principles, especially the production of 'rich' and 'plural' metadata at the time of data creation (principles F2, R1.1\u20131.3; GO-FAIR, 2017).",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E043",
        "E044"
      ],
      "supports_claims": [
        "C005"
      ]
    },
    {
      "claim_id": "C047",
      "claim_text": "Project systematically evaluated digital fieldwork approaches",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "At that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a research program to evaluate digital approaches to fieldwork (e.g., Sobotkova et al., 2016).",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E046",
        "E047",
        "E049"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C048",
      "claim_text": "Early success prompted systematic evaluation",
      "claim_role": "supporting",
      "claim_type": "interpretation",
      "verbatim_quote": "The success of this approach became apparent early in the 2017 field season. At that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a research program to evaluate digital approaches to fieldwork (e.g., Sobotkova et al., 2016).",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E046",
        "E047"
      ],
      "supports_claims": [
        "C047"
      ]
    },
    {
      "claim_id": "C049",
      "claim_text": "Multiple data sources used to comprehensively track time investment and quality",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project staff logged time-on-task for activities in journals.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E048",
        "E050",
        "E051"
      ],
      "supports_claims": [
        "C047"
      ]
    },
    {
      "claim_id": "C050",
      "claim_text": "Volunteer digitisation produced large volume of high-quality geospatial data",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "In total, 10,827 point features, mostly burial and settlement mounds, were recorded in 189.4 student-hours (63 s per record).",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E052",
        "E053",
        "E054",
        "E055",
        "E056",
        "E057",
        "E058",
        "E059",
        "E060",
        "E062",
        "E076"
      ],
      "supports_claims": [
        "C001",
        "C002"
      ]
    },
    {
      "claim_id": "C051",
      "claim_text": "Concentrated digitisation was more productive than intermittent work",
      "claim_role": "supporting",
      "claim_type": "interpretation",
      "verbatim_quote": "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets utilising time that might otherwise have been lost (e.g., to inclement weather), while requiring little supervision by project staff.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E052",
        "E053",
        "E061",
        "E063"
      ],
      "supports_claims": [
        "C050"
      ]
    },
    {
      "claim_id": "C052",
      "claim_text": "System flexibility enabled opportunistic digitisation during spare time",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E055",
        "E057",
        "E061"
      ],
      "supports_claims": [
        "C050",
        "C051"
      ]
    },
    {
      "claim_id": "C053",
      "claim_text": "Desktop GIS placed high cognitive load on novice users, causing volunteer attrition",
      "claim_role": "supporting",
      "claim_type": "interpretation",
      "verbatim_quote": "These problems reflect the high cognitive load desktop GIS places on novice users.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E065",
        "E066",
        "E067",
        "E068",
        "E069",
        "E070",
        "E075"
      ],
      "supports_claims": [
        "C031",
        "C032"
      ]
    },
    {
      "claim_id": "C054",
      "claim_text": "Mobile customisation met usability requirements and enabled productive volunteer work",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "By contrast, our customised application met fundamental usability requirements (e.g., Nielsen, 2012), both due to careful design of the customisation itself, and the underlying platform's implementation of Google's Material Design guidelines.",
      "location": {
        "section": "Results",
        "subsection": "3.3 Digitisation comparison with desktop GIS",
        "page": 7,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E071",
        "E072",
        "E073",
        "E074",
        "E075",
        "E076"
      ],
      "supports_claims": [
        "C033",
        "C034",
        "C050"
      ]
    },
    {
      "claim_id": "C055",
      "claim_text": "Performance degradation was mitigated through export and restart workflow",
      "claim_role": "supporting",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application.",
      "location": {
        "section": "Results",
        "subsection": "3.4 Application performance",
        "page": 7,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E077",
        "E078",
        "E079",
        "E080",
        "E085"
      ],
      "supports_claims": []
    },
    {
      "claim_id": "C056",
      "claim_text": "Recoverable data omissions were low and mostly correctable",
      "claim_role": "supporting",
      "claim_type": "interpretation",
      "verbatim_quote": "Recoverable data omissions across both years totaled 223 (2.06% of records), including 205 spatial and 18 attribute omissions.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.1 Recoverable data omissions and incomplete records",
        "page": 7,
        "paragraph": 1
      },
      "supported_by_claims": [
        "C057"
      ],
      "supported_by_evidence": [
        "E081",
        "E082",
        "E083",
        "E084",
        "E085",
        "E086",
        "E087",
        "E088",
        "E089"
      ],
      "supports_claims": [
        "C005"
      ]
    },
    {
      "claim_id": "C057",
      "claim_text": "Validation improvements in 2018 dramatically reduced omissions",
      "claim_role": "supporting",
      "claim_type": "interpretation",
      "verbatim_quote": "Before the 2018 season, we added validation addressing this problem, resulting in only 13 spatial errors and one attribute omission (0.52%).",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.1 Recoverable data omissions and incomplete records",
        "page": 7,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E086",
        "E087",
        "E088"
      ],
      "supports_claims": [
        "C056"
      ]
    },
    {
      "claim_id": "C058",
      "claim_text": "Overall digitisation accuracy was high (>94%) despite some errors",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "Unlike some volunteer digitisation projects, overall accuracy was high, over 94% for processed maps.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 7,
        "paragraph": 1
      },
      "supported_by_claims": [
        "C059",
        "C060"
      ],
      "supported_by_evidence": [
        "E090",
        "E091",
        "E092",
        "E093",
        "E094",
        "E095",
        "E096",
        "E097",
        "E098",
        "E102",
        "E103"
      ],
      "supports_claims": [
        "C005"
      ]
    },
    {
      "claim_id": "C059",
      "claim_text": "Error patterns were predictable and easy to identify for correction",
      "claim_role": "supporting",
      "claim_type": "interpretation",
      "verbatim_quote": "Moreover, the pattern of errors - mostly false negatives and double-marked features, mostly from contiguous map sections - made them relatively easy to identify and correct.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E094",
        "E095",
        "E096",
        "E097",
        "E101",
        "E104"
      ],
      "supports_claims": [
        "C058",
        "C061"
      ]
    },
    {
      "claim_id": "C060",
      "claim_text": "Best digitisers were both fast and accurate",
      "claim_role": "supporting",
      "claim_type": "interpretation",
      "verbatim_quote": "Note that the two fastest digitisers (Students A and B; 44 and 45 s per feature respectively) also had the lowest error rates (1.3 and 2.9%), while the two slowest (Students C and D; 61 and 73 s) had the highest error rates (10.6 and 7.4%).",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E098",
        "E099",
        "E100",
        "E101",
        "E102"
      ],
      "supports_claims": [
        "C058"
      ]
    },
    {
      "claim_id": "C061",
      "claim_text": "Simple quality control expedients would eliminate most errors with less effort than expert digitisation",
      "claim_role": "intermediate",
      "claim_type": "methodological_argument",
      "verbatim_quote": "Simple expedients, such as assigning multiple students to digitise the same map tiles independently or assigning one student to review work by another, would likely eliminate most errors.",
      "location": {
        "section": "Results",
        "subsection": "3.5 Data quality",
        "subsubsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E104",
        "E105",
        "E106"
      ],
      "supports_claims": [
        "C004",
        "C005"
      ]
    },
    {
      "claim_id": "C062",
      "claim_text": "Crowdsourcing system has payoff threshold of 3,420-4,275 features versus direct staff digitisation",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420\u20134,275 staff-digitised features (see Table 4). Such a payoff threshold suggests that digitisation by project staff will be suitable only for smaller datasets.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E107",
        "E108",
        "E110",
        "E138"
      ],
      "supports_claims": [
        "C069",
        "C070",
        "C075"
      ]
    },
    {
      "claim_id": "C063",
      "claim_text": "Crowdsourcing system has payoff threshold of 7,410-10,260 features versus volunteers using desktop GIS",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "Had specialist project staff instead trained and supervised volunteers to use desktop GIS for digitisation, based on our 2010 digitisation rate of 130\u2013180 features per staff-hour, 57 h might have produced 7,410\u201310,260 features. At the highest rate, desktop GIS digitisation using novice volunteers is almost competitive with the mobile application approach we used.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E109",
        "E110",
        "E139"
      ],
      "supports_claims": [
        "C069",
        "C070",
        "C075"
      ]
    },
    {
      "claim_id": "C064",
      "claim_text": "Crowdsourcing approach provides outsourcing advantage with only 21h internal staff time versus 57h total",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "First, customisation of systems like FAIMS Mobile can be outsourced more easily than other project activities. Only 21 of the 57 h needed to support the system came from project staff, while the other 36 h were completed by a student programmer for a modest cost (ca. AUD $2,000). Those 21 internal staff hours represent a digitisation rate of over 500 features per staff-hour.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 5
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E110",
        "E111",
        "E112",
        "E113"
      ],
      "supports_claims": [
        "C069",
        "C075"
      ]
    },
    {
      "claim_id": "C065",
      "claim_text": "Staff time during field season was scarce and valuable, making in-field efficiency critical",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "Second, given competing responsibilities, staff time during the field season was scarce and valuable. We could afford to invest in customisation and setup beforehand, and error checking after, if it reduced staff obligations during fieldwork.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E114",
        "E115",
        "E140"
      ],
      "supports_claims": [
        "C069",
        "C075"
      ]
    },
    {
      "claim_id": "C066",
      "claim_text": "Marginal cost for each additional feature digitised is low (4.3 seconds of staff support)",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "Third, the marginal cost for each additional feature digitised is low. This figure includes in-field support and quality assurance (13 h), and translates to 4.3 s of staff support per additional feature.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E116",
        "E117"
      ],
      "supports_claims": [
        "C067",
        "C069"
      ]
    },
    {
      "claim_id": "C067",
      "claim_text": "Scalability of crowdsourcing approach makes it more attractive as project expands",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "The scalability of our crowdsourcing approach makes it more attractive if a project may expand over time to include more volunteers, more redeployments, or more maps.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 4
      },
      "supported_by_claims": [
        "C066"
      ],
      "supported_by_evidence": [
        "E116",
        "E117",
        "E118",
        "E119"
      ],
      "supports_claims": [
        "C069",
        "C075"
      ]
    },
    {
      "claim_id": "C068",
      "claim_text": "Qualitative factors argue for mobile crowdsourcing approach over desktop GIS",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "Finally, qualitative factors also argue for implementing a crowdsourcing approach using a mobile application.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 5
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E120",
        "E121",
        "E122"
      ],
      "supports_claims": [
        "C069",
        "C075"
      ]
    },
    {
      "claim_id": "C069",
      "claim_text": "Crowdsourcing approach most suitable for datasets numbering 10,000-60,000 records",
      "claim_role": "primary",
      "claim_type": "interpretation",
      "verbatim_quote": "To summarise in round numbers, a crowdsourcing approach like ours is most suitable for datasets numbering perhaps 10,000\u201360,000 records, assuming similar feature characteristics and data collection requirements (see Table 5).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 4
      },
      "supported_by_claims": [
        "C062",
        "C063",
        "C064",
        "C065",
        "C066",
        "C067",
        "C068"
      ],
      "supported_by_evidence": [
        "E107",
        "E110",
        "E112",
        "E114",
        "E127",
        "E128",
        "E140",
        "E141"
      ],
      "supports_claims": [
        "C001",
        "C002",
        "C075"
      ]
    },
    {
      "claim_id": "C070",
      "claim_text": "Below 10,000 records, desktop GIS approaches should be considered",
      "claim_role": "primary",
      "claim_type": "interpretation",
      "verbatim_quote": "Below 10,000 records, approaches using desktop GIS should be considered.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 4
      },
      "supported_by_claims": [
        "C062",
        "C063"
      ],
      "supported_by_evidence": [
        "E107",
        "E108",
        "E109",
        "E138",
        "E139"
      ],
      "supports_claims": [
        "C075"
      ]
    },
    {
      "claim_id": "C071",
      "claim_text": "Above 60,000 records, machine learning approaches should be contemplated if expertise available",
      "claim_role": "primary",
      "claim_type": "interpretation",
      "verbatim_quote": "Above 60,000 records, ML approaches should be contemplated, but only if a project has access to the requisite expertise.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E123",
        "E124",
        "E125",
        "E126",
        "E127",
        "E128",
        "E141"
      ],
      "supports_claims": [
        "C075"
      ]
    },
    {
      "claim_id": "C072",
      "claim_text": "Machine learning and crowdsourcing approaches are complementary, not exclusive",
      "claim_role": "primary",
      "claim_type": "interpretation",
      "verbatim_quote": "Finally, since training a model requires a manually produced dataset and a degree of manual error-checking, a combination of ML and crowdsourcing approaches might serve even large-scale projects.",
      "location": {
        "section": "Discussion",
        "subsection": "4.2 Combining crowdsourcing and ML approaches",
        "page": 10,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E123",
        "E129",
        "E130",
        "E131",
        "E142"
      ],
      "supports_claims": [
        "C075"
      ]
    },
    {
      "claim_id": "C073",
      "claim_text": "Typical HASS project can deploy crowdsourcing system but may struggle with machine learning",
      "claim_role": "primary",
      "claim_type": "interpretation",
      "verbatim_quote": "Today, a typical project in history or archaeology - often small, under-resourced, and pursuing several research activities - may not be able to dedicate the personnel, infrastructure, or attention needed to incorporate ML successfully, but could deploy a collaborative geospatial system for crowdsourcing map digitisation.",
      "location": {
        "section": "Discussion",
        "subsection": "4.3 Overall feasibility",
        "page": 10,
        "paragraph": 1
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E132",
        "E133",
        "E134"
      ],
      "supports_claims": [
        "C069",
        "C075"
      ]
    },
    {
      "claim_id": "C074",
      "claim_text": "Technical barriers to deploying mobile GIS customisation systems are declining",
      "claim_role": "intermediate",
      "claim_type": "interpretation",
      "verbatim_quote": "Many of these systems attempt to make customisation as easy as possible, a goal at the heart of recent FAIMS redevelopment (ARDC, 2022); in future the technical barriers to deploying such systems will likely decline.",
      "location": {
        "section": "Discussion",
        "subsection": "4.3 Overall feasibility",
        "page": 10,
        "paragraph": 2
      },
      "supported_by_claims": [],
      "supported_by_evidence": [
        "E134",
        "E135"
      ],
      "supports_claims": [
        "C073",
        "C076"
      ]
    },
    {
      "claim_id": "C075",
      "claim_text": "Crowdsourced map digitisation using mobile GIS proved unexpectedly successful",
      "claim_role": "primary",
      "claim_type": "interpretation",
      "verbatim_quote": "Our crowdsourced digitisation effort involving novice volunteers using an adapted mobile application for data capture proved unexpectedly successful.",
      "location": {
        "section": "Discussion",
        "page": 9,
        "paragraph": 1
      },
      "supported_by_claims": [
        "C050",
        "C054",
        "C058",
        "C062",
        "C063",
        "C064",
        "C065",
        "C067",
        "C068",
        "C069",
        "C070",
        "C071",
        "C072",
        "C073"
      ],
      "supported_by_evidence": [
        "E136",
        "E137"
      ],
      "supports_claims": [
        "C001",
        "C002"
      ]
    },
    {
      "claim_id": "C076",
      "claim_text": "Approach is readily transferable to other mobile GIS systems and map corpora",
      "claim_role": "primary",
      "claim_type": "interpretation",
      "verbatim_quote": "This approach is readily transferable to other mobile GIS systems and map corpora",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 4
      },
      "supported_by_claims": [
        "C074"
      ],
      "supported_by_evidence": [
        "E136"
      ],
      "supports_claims": [
        "C001"
      ]
    },
    {
      "claim_id": "C077",
      "claim_text": "More projects need to track and publish time/error data for map digitisation",
      "claim_role": "secondary",
      "claim_type": "gap",
      "verbatim_quote": "More projects - whether they use manual or automated approaches - need to track and publish the expert and volunteer time required for setup, training, support, and quality assurance related to map digitisation, as well as digitisation speed, error rates and types, the characteristics of the features being digitised, and the complexity of information extracted.",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 4
      },
      "supported_by_claims": [],
      "supported_by_evidence": [],
      "supports_claims": []
    },
    {
      "claim_id": "C078",
      "claim_text": "Authors plan to use TRAP dataset to train ML model for systematic comparison with crowdsourcing",
      "claim_role": "secondary",
      "claim_type": "background",
      "verbatim_quote": "We next plan to take our dataset and use it to train and error-check a ML model, to more systematically compare the results of crowdsourcing versus machine learning.",
      "location": {
        "section": "Conclusion",
        "page": 11,
        "paragraph": 4
      },
      "supported_by_claims": [
        "C072"
      ],
      "supported_by_evidence": [],
      "supports_claims": []
    }
  ],
  "implicit_arguments": [
    {
      "implicit_argument_id": "IA001",
      "implicit_argument_type": "Type 2: Unstated Assumption",
      "implicit_argument_text": "Novice volunteers can produce high-quality geospatial data if given appropriate tools",
      "trigger_text": [
        "volunteers with no prior GIS experience",
        "with an error rate under 6%",
        "The resulting dataset was consistent, well-documented"
      ],
      "trigger_locations": [
        {
          "section": "Abstract",
          "page": 1,
          "paragraph": 1
        },
        {
          "section": "Abstract",
          "page": 1,
          "paragraph": 1
        },
        {
          "section": "Abstract",
          "page": 1,
          "paragraph": 1
        }
      ],
      "inference_reasoning": "The paper demonstrates that novice volunteers achieved low error rates and produced quality data, but doesn't explicitly state the underlying assumption that volunteers CAN produce such quality given the right tools. This assumption is fundamental to the entire argument but remains implicit.",
      "supports_claims": [
        "C001",
        "C002",
        "C006"
      ],
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      }
    },
    {
      "implicit_argument_id": "IA002",
      "implicit_argument_type": "Type 3: Bridging Claim",
      "implicit_argument_text": "Efficiency thresholds for digitisation approaches can be estimated from single-project data",
      "trigger_text": [
        "A conservative estimate based on our work suggests our crowdsourcing approach is most efficient for digitisation projects of 10,000\u201360,000 features"
      ],
      "trigger_locations": [
        {
          "section": "Abstract",
          "page": 1,
          "paragraph": 1
        }
      ],
      "inference_reasoning": "The paper makes efficiency recommendations for dataset sizes, but doesn't explicitly justify how findings from one project (10,827 features, Bulgarian context) can generalize to estimate optimal thresholds for other projects. The bridging claim that single-project data can inform general efficiency thresholds is implicit.",
      "supports_claims": [
        "C003"
      ],
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      }
    },
    {
      "implicit_argument_id": "IA003",
      "implicit_argument_type": "Type 4: Disciplinary Assumption",
      "implicit_argument_text": "Error rates under 6% constitute 'high quality' for crowdsourced digitisation",
      "trigger_text": [
        "with an error rate under 6%",
        "The resulting dataset was consistent, well-documented, and ready for analysis"
      ],
      "trigger_locations": [
        {
          "section": "Abstract",
          "page": 1,
          "paragraph": 1
        },
        {
          "section": "Abstract",
          "page": 1,
          "paragraph": 1
        }
      ],
      "inference_reasoning": "The paper presents 6% error rate alongside quality assertions, implying this rate is acceptable/good, but doesn't explicitly state what error threshold defines 'high quality' in this domain. This is a disciplinary assumption about acceptable quality standards that GIS/archaeology practitioners may take for granted.",
      "supports_claims": [
        "C001",
        "C005"
      ],
      "location": {
        "section": "Abstract",
        "page": 1,
        "paragraph": 1
      }
    },
    {
      "implicit_argument_id": "IA004",
      "implicit_argument_type": "Type 1: Logical Implication",
      "implicit_argument_text": "If crowdsourcing scales better than desktop GIS approaches, then projects with volunteer attrition problems should prefer crowdsourcing",
      "trigger_text": [
        "Crowdsourcing requires more upfront investment in system setup than using available GIS specialists or training and supervising volunteers using desktop GIS, but it scales better in the face of likely constraints related to expert staffing and volunteer attrition."
      ],
      "trigger_locations": [
        {
          "section": "Introduction",
          "subsection": "1.3 Extracting data from historical maps",
          "page": 3,
          "paragraph": 4
        }
      ],
      "inference_reasoning": "The explicit claim states crowdsourcing scales better in face of volunteer attrition constraints. The logical implication (not stated) is that projects experiencing such attrition should therefore prefer this approach - this recommendation follows logically but isn't explicitly made.",
      "supports_claims": [
        "C027",
        "C026"
      ],
      "location": {
        "section": "Introduction",
        "subsection": "1.3 Extracting data from historical maps",
        "page": 3,
        "paragraph": 4
      }
    },
    {
      "implicit_argument_id": "IA005",
      "implicit_argument_type": "Type 2: Unstated Assumption",
      "implicit_argument_text": "Simplified interfaces reduce cognitive load enough to overcome lack of GIS expertise",
      "trigger_text": [
        "it stripped GIS functionality to its essentials, focusing on three tasks",
        "simple and intuitive UI allowed students to begin digitising after only minutes of training",
        "Most had no training in archaeology, cartography, or digital methods"
      ],
      "trigger_locations": [
        {
          "section": "Approach",
          "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
          "page": 4,
          "paragraph": 4
        },
        {
          "section": "Approach",
          "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
          "page": 4,
          "paragraph": 4
        },
        {
          "section": "Approach",
          "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
          "page": 4,
          "paragraph": 2
        }
      ],
      "inference_reasoning": "The paper shows that simplifying GIS to essentials enabled novices to work productively, but doesn't explicitly state the underlying UI/UX principle that reducing cognitive load through simplification can compensate for lack of domain expertise. This cognitive load reduction assumption is implicit but fundamental to the design rationale.",
      "supports_claims": [
        "C033",
        "C034",
        "C006"
      ],
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      }
    },
    {
      "implicit_argument_id": "IA006",
      "implicit_argument_type": "Type 2: Unstated Assumption",
      "implicit_argument_text": "Automation and metadata capture during data creation ensures data quality and FAIRness",
      "trigger_text": [
        "FAIMS Mobile automated a number of tasks",
        "recorded creation time and author for each record, maintained a history of all changes to data",
        "adhered to key elements of the FAIR data principles"
      ],
      "trigger_locations": [
        {
          "section": "Approach",
          "subsection": "2.4 Design and implementation of the recording system",
          "page": 5,
          "paragraph": 2
        },
        {
          "section": "Approach",
          "subsection": "2.4 Design and implementation of the recording system",
          "page": 5,
          "paragraph": 2
        },
        {
          "section": "Approach",
          "subsection": "2.4 Design and implementation of the recording system",
          "page": 6,
          "paragraph": 2
        }
      ],
      "inference_reasoning": "The paper describes extensive automation and metadata capture, then asserts FAIR compliance and data quality, but doesn't explicitly state the underlying assumption that automated metadata creation at time of data entry is superior to post-hoc metadata addition. This assumption about the relationship between automated capture and quality is implicit.",
      "supports_claims": [
        "C040",
        "C046",
        "C005"
      ],
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 2
      }
    }
  ],
  "research_designs": [
    {
      "design_id": "RD001",
      "design_text": "Evaluate crowdsourcing approach for map digitization by measuring time inputs vs feature outputs",
      "design_type": "evaluation_study",
      "design_status": "explicit",
      "verbatim_quote": "As such, at that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a research program to evaluate digital approaches to fieldwork (e.g., Sobotkova et al., 2016).",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 1
      },
      "research_framing": {
        "purpose": "Evaluate cost-effectiveness of crowdsourced map digitization using mobile GIS",
        "objectives": [
          "Measure time inputs from staff and volunteers",
          "Measure digitization outputs (features created)",
          "Compare efficiency with alternative approaches"
        ],
        "scope": {
          "temporal_scope": "2017-2018 field seasons",
          "spatial_scope": "58 Soviet topographic map tiles covering ~23,500 sq km in Bulgaria",
          "population_scope": "Undergraduate field school participants (novice volunteers)",
          "methodological_scope": "Map digitization using customized mobile GIS platform"
        }
      },
      "enables_methods": [
        "M001",
        "M002",
        "M003"
      ]
    },
    {
      "design_id": "RD002",
      "design_text": "Usability-focused design to minimize cognitive load and training requirements for novice volunteers",
      "design_type": "intervention_design",
      "design_status": "explicit",
      "verbatim_quote": "Our approach sought to help novice users begin digitising quickly and then work productively for the duration of each field season with minimal support or frustration. As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validation and automation to improve data quality.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      },
      "theoretical_framework": {
        "framework_name": "Usability Heuristics / Human-Computer Interaction principles",
        "framework_application": "Apply mobile HCI principles (learnability, efficiency, error mitigation) to reduce cognitive load for novice GIS users",
        "key_concepts": [
          "Cognitive load reduction",
          "Streamlined UI",
          "Focus on essential tasks",
          "Automation and validation"
        ]
      },
      "enables_methods": [
        "M004",
        "M005",
        "M006"
      ]
    },
    {
      "design_id": "RD003",
      "design_text": "Comparative evaluation design: crowdsourcing vs desktop GIS vs machine learning",
      "design_type": "comparative_study",
      "design_status": "explicit",
      "verbatim_quote": "Digitisation projects will likely choose between one of four principal approaches to digitising historical maps. 1. Have expert staff or specialists digitise features using a desktop GIS; 2. Employ volunteers to digitise features using a desktop GIS with training and support from expert staff; 3. Customise and deploy a collaborative geospatial system that can be used by volunteers, including novices with little GIS experience, backstopped by training and support from expert staff; 4. Invest in a ML approach to automatically extract features",
      "location": {
        "section": "Discussion",
        "subsection": "4.1 Choosing an approach",
        "page": 9,
        "paragraph": 2
      },
      "research_framing": {
        "purpose": "Compare payoff thresholds and tradeoffs between digitization approaches",
        "objectives": [
          "Calculate time/feature ratios for each approach",
          "Identify dataset size thresholds for approach selection",
          "Assess qualitative factors beyond efficiency metrics"
        ]
      },
      "enables_methods": [
        "M007",
        "M008"
      ]
    },
    {
      "design_id": "RD004",
      "design_text": "Case study approach demonstrating unanticipated success of minimally resourced digitization for small-to-mid-sized datasets (100s-10,000s features), complementing ML for larger datasets",
      "design_type": "case_study",
      "design_status": "explicit",
      "verbatim_quote": "This article presents a case study of crowdsourced cultural heritage digitisation from historical maps... Such an approach is suitable for projects working with small to mid-sized data sources (100s\u201310,000s of features) that do not warrant the investment needed for successful ML-based data extraction",
      "location": {
        "section": "Introduction",
        "page": 1,
        "paragraph": 1
      },
      "research_framing": {
        "purpose": "Document unexpected success of low-resource crowdsourcing approach and position it relative to ML alternatives",
        "objectives": [
          "Demonstrate feasibility of minimally resourced digitization",
          "Show value for archaeological research",
          "Define niche for 100s-10,000s features"
        ],
        "scope": {
          "methodological_scope": "Small to mid-sized datasets (100s-10,000s features) where ML not warranted"
        }
      },
      "study_design": {
        "design_rationale": "Complementary approach to ML for datasets too small to warrant ML investment",
        "design_choice": "Crowdsourcing with lightweight mobile GIS for minimally resourced projects"
      },
      "enables_methods": [
        "M007",
        "M008",
        "M009",
        "M010"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "RD004",
          "RD005"
        ],
        "consolidation_type": "thematic_overlap",
        "information_preserved": "complete",
        "rationale": "RD004 and RD005 both frame the case study approach. Consolidated into single design capturing both success demonstration and methodological positioning."
      }
    },
    {
      "design_id": "RD006",
      "design_text": "Secondary activity design: digitization as ancillary to primary pedestrian survey fieldwork",
      "design_type": "opportunistic_study",
      "design_status": "explicit",
      "verbatim_quote": "Digitisation was undertaken as a secondary activity on a landscape archaeology project focusing on pedestrian feature survey. Undergraduates in the associated field school digitised data from maps using a system repurposed from other project activities.",
      "location": {
        "section": "Introduction",
        "page": 1,
        "paragraph": 1
      },
      "research_framing": {
        "purpose": "Leverage field school downtime for map digitization using repurposed tools",
        "scope": {
          "temporal_scope": "Time-available basis during fieldwork seasons",
          "population_scope": "Undergraduate field school participants"
        }
      },
      "enables_methods": [
        "M004",
        "M009"
      ]
    },
    {
      "design_id": "RD007",
      "design_text": "TRAP project: Long-term cultural development in environmental context combining multiple methodologies",
      "design_type": "interdisciplinary_study",
      "design_status": "explicit",
      "verbatim_quote": "It has explored long-term cultural development in its environmental context since 2008 (Ross et al., 2010, 2018; Sobotkova, 2013). Methodologically, it combines historical research, archaeological survey, remote sensing, excavation, and ecological sampling.",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 1
      },
      "research_framing": {
        "purpose": "Reconstruct ancient environment, map habitation evolution, explain human-environment interactions",
        "objectives": [
          "Reconstruct ancient environment",
          "Map evolution of habitation",
          "Explain long-term human-environment interactions",
          "Produce archaeological heritage inventory"
        ]
      },
      "study_design": {
        "design_rationale": "Multi-method approach to capture long-term cultural and environmental change",
        "design_choice": "Combine historical, archaeological, remote sensing, excavation, and ecological methods"
      },
      "enables_methods": [
        "M010",
        "M011"
      ]
    },
    {
      "design_id": "RD008",
      "design_text": "Three-activity research design for 2017-2018: mound registration, satellite monitoring, and map digitization with ground-truthing",
      "design_type": "multi_method_study",
      "design_status": "explicit",
      "verbatim_quote": "Three activities were undertaken: (1) visiting known burial mounds, registering their location and condition; (2) identifying changes in mound condition using satellite imagery; (3) digitising mounds from over 20,000 sq km of Soviet military 1:50,000 topographic maps covering southeast Bulgaria, followed by ground-truthing (which continued through 2022).",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "research_framing": {
        "purpose": "Record location, characteristics, and condition of burial mounds in Yambol region",
        "objectives": [
          "Register known mound locations and conditions",
          "Monitor condition changes via satellite",
          "Digitize mounds from historical maps",
          "Ground-truth digitized features"
        ]
      },
      "scope": {
        "temporal_scope": "2017-2018 primary activities, ground-truthing through 2022",
        "spatial_scope": "Over 20,000 sq km of Soviet military topographic maps, southeast Bulgaria"
      },
      "enables_methods": [
        "M010",
        "M011",
        "M012"
      ]
    },
    {
      "design_id": "RD009",
      "design_text": "Student involvement design: Involve field school undergraduates in authentic research through map digitization",
      "design_type": "participatory_research",
      "design_status": "explicit",
      "verbatim_quote": "The task of digitising potentially thousands of mounds provided an opportunity to involve students in authentic research. Our students came from a range of academic backgrounds in Arts and Humanities.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 1
      },
      "research_framing": {
        "purpose": "Provide authentic research experience while accomplishing digitization goals",
        "scope": {
          "population_scope": "Undergraduate field school participants from Arts and Humanities backgrounds, mostly without archaeology/cartography/digital methods training"
        }
      },
      "enables_methods": [
        "M015",
        "M016"
      ]
    },
    {
      "design_id": "RD010",
      "design_text": "Volunteer empowerment approach: Focus on implementing tools to enable independent volunteer work with minimal training and supervision",
      "design_type": "usability_focused_design",
      "design_status": "explicit",
      "verbatim_quote": "In 2017, faced with a short field season and little time for student training, we focused on implementing tools that would empower volunteers to digitise maps independently. Our approach sought to help novice users begin digitising quickly and then work productively for the duration of each field season with minimal support or frustration.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "research_framing": {
        "purpose": "Enable novice volunteers to work independently with minimal training and support",
        "objectives": [
          "Help novice users begin digitising quickly",
          "Enable productive work with minimal support",
          "Minimize volunteer frustration"
        ]
      },
      "study_design": {
        "design_rationale": "Short field season and limited time for training necessitated tool-based empowerment approach",
        "design_choice": "Strip GIS functionality to essentials: layer selection, shape digitisation, annotation with validation and automation"
      },
      "enables_methods": [
        "M017",
        "M018"
      ]
    },
    {
      "design_id": "RD011",
      "design_text": "Platform selection design: Choose FAIMS Mobile for customization based on offline capability, functional requirements, workflow conformance, cost, and usability",
      "design_type": "technology_selection",
      "design_status": "explicit",
      "verbatim_quote": "The decision to use mobile software, and FAIMS Mobile in particular, was based on several factors. First, FAIMS Mobile worked offline... Second, this system met the functional requirements we identified for geospatial software... Third, it allowed us to test the idea that usability approaches from data capture during kinetic fieldwork were beneficially transferable to digitisation work. Fourth, we were already using FAIMS Mobile for in-field legacy data verification... Fifth, student volunteers are accustomed to, and even prefer, 'slippy-map', touch-screen interfaces on mobile devices...",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraphs": "1-2"
      },
      "research_framing": {
        "purpose": "Select appropriate platform for crowdsourced map digitization under field conditions"
      },
      "study_design": {
        "design_rationale": "Five factors: offline capability for rural Bulgaria field conditions, functional requirements met, usability transferability from kinetic fieldwork, existing platform use for other project activities, volunteer familiarity with mobile touch interfaces",
        "design_choice": "FAIMS Mobile customization over alternatives (ESRI ArcGIS Collector/Field Maps/Survey123 had disadvantages: divided map/form interfaces, internet connectivity requirements, proprietary nature)"
      },
      "enables_methods": [
        "M019",
        "M020"
      ]
    },
    {
      "design_id": "RD012",
      "design_text": "Division of labor design: Move technical expertise activities to specialist phases, simplify volunteer tasks to essential digitization",
      "design_type": "workflow_design",
      "design_status": "explicit",
      "verbatim_quote": "This approach moved activities requiring technical expertise to phases where specialists could contribute, while simplifying the tasks assigned to student volunteers as much as possible.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 1
      },
      "research_framing": {
        "purpose": "Optimize distribution of technical vs. simple tasks across project staff and volunteers"
      },
      "study_design": {
        "design_rationale": "Concentrate expertise requirements in staff-controlled phases, minimize technical demands on volunteers",
        "design_choice": "Seven-stage workflow dividing technical (staff) from simple (volunteer) activities"
      },
      "enables_methods": [
        "M021"
      ]
    },
    {
      "design_id": "RD013",
      "design_text": "System evaluation design: Catalogue inputs (staff and volunteer time) versus outputs (features digitized) to evaluate digital fieldwork approach",
      "design_type": "evaluation_study",
      "design_status": "explicit",
      "verbatim_quote": "The success of this approach became apparent early in the 2017 field season. At that point, we decided to catalogue inputs (time invested by staff and volunteers) versus outputs (features digitised) as part of a research program to evaluate digital approaches to fieldwork (e.g., Sobotkova et al., 2016).",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 1
      },
      "research_framing": {
        "purpose": "Evaluate crowdsourcing approach efficiency as part of research program on digital fieldwork approaches",
        "objectives": [
          "Measure time inputs from all participants",
          "Measure feature output",
          "Enable comparison with alternative approaches"
        ]
      },
      "enables_methods": [
        "M022"
      ]
    },
    {
      "design_id": "RD014",
      "design_text": "2018 validation refinement: Address performance degradation problem discovered in 2017 season",
      "design_type": "iterative_design",
      "design_status": "explicit",
      "verbatim_quote": "For the second season, adding additional validation to ensure population of latitude and longitude from GPS (see 'Recoverable data omissions and incomplete records' below) took 1 h of development from the programmer.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 2
      },
      "research_framing": {
        "purpose": "Improve data quality by addressing lat/long population failure discovered in 2017",
        "objectives": [
          "Prevent spatial data omissions",
          "Improve validation to catch errors at time of data entry"
        ]
      },
      "enables_methods": [
        "M024"
      ]
    },
    {
      "design_id": "RD015",
      "design_text": "Four-approach decision framework for map digitization: desktop GIS by experts, desktop GIS by volunteers, crowdsourcing with collaborative system, or machine learning",
      "design_type": "comparative_framework",
      "design_status": "explicit",
      "verbatim_quote": "Digitisation projects will likely choose between one of four principal approaches to digitising historical maps. 1. Have expert staff or specialists digitise features using a desktop GIS; 2. Employ volunteers to digitise features using a desktop GIS with training and support from expert staff; 3. Customise and deploy a collaborative geospatial system that can be used by volunteers, including novices with little GIS experience, backstopped by training and support from expert staff; 4. Invest in a ML approach to automatically extract features",
      "location": {
        "section": "Discussion",
        "subsection": "4.1 Choosing an approach",
        "page": 9,
        "paragraph": 2
      },
      "research_framing": {
        "purpose": "Provide decision framework for selecting digitization approach based on project constraints",
        "objectives": [
          "Compare setup costs vs ongoing expert involvement trade-offs",
          "Identify payoff thresholds for each approach"
        ]
      },
      "enables_methods": [
        "M027"
      ]
    },
    {
      "design_id": "RD016",
      "design_text": "Payoff threshold analysis: Compare staff time investment thresholds for different digitization approaches",
      "design_type": "comparative_evaluation",
      "design_status": "explicit",
      "verbatim_quote": "Note that in all following comparisons, we present our experience as a (perhaps idiosyncratic) example... This discussion, furthermore, focuses on our most limited resource: staff time. As such, the calculations below, which propose dataset size thresholds for various approaches, prioritise staff time required for digitisation.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1 Choosing an approach",
        "page": 9,
        "paragraph": 3
      },
      "research_framing": {
        "purpose": "Calculate dataset size thresholds where crowdsourcing becomes more efficient than alternatives",
        "objectives": [
          "Determine payoff thresholds vs desktop GIS approaches",
          "Determine payoff thresholds vs ML approaches"
        ]
      },
      "enables_methods": [
        "M028",
        "M029"
      ]
    }
  ],
  "methods": [
    {
      "method_id": "M001",
      "method_text": "Time measurement: collate time-on-task from programmer timesheets, student record timestamps, and staff journals",
      "method_tier": "data_collection",
      "method_status": "explicit",
      "verbatim_quote": "To measure inputs, we collated the amount of time spent by various participants in the process, including the student programmer who instantiated the customisation, the student volunteers who undertook the digitisation, and project staff who configured the system, supported volunteers, exported data, and checked for errors. Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project staff logged time-on-task for activities in journals.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P001",
        "P002",
        "P003"
      ]
    },
    {
      "method_id": "M002",
      "method_text": "Output measurement: count features digitized from application records",
      "method_tier": "data_collection",
      "method_status": "explicit",
      "verbatim_quote": "We took the number of features digitised as the output.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P004"
      ]
    },
    {
      "method_id": "M003",
      "method_text": "Quality assurance: random sampling of digitized maps with manual re-examination to characterize errors",
      "method_tier": "validation",
      "method_status": "explicit",
      "verbatim_quote": "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P005"
      ]
    },
    {
      "method_id": "M004",
      "method_text": "FAIMS Mobile customization for map digitization: definition files interpreted to generate customized Android application",
      "method_tier": "data_collection",
      "method_status": "explicit",
      "verbatim_quote": "FAIMS Mobile is a server-client platform that generates customised Android applications for data collection during offline field research. Customisation is accomplished via definition files that can be shared, modified, and redeployed. FAIMS Mobile interprets the definition files to generate a specific data capture application.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD002"
      ],
      "realized_through_protocols": [
        "P006",
        "P007",
        "P008"
      ]
    },
    {
      "method_id": "M005",
      "method_text": "Streamlined UI design: strip GIS to essentials (layer selection, shape digitization, annotation)",
      "method_tier": "intervention",
      "method_status": "explicit",
      "verbatim_quote": "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validation and automation to improve data quality.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      },
      "enabled_by_designs": [
        "RD002"
      ],
      "realized_through_protocols": [
        "P009",
        "P010"
      ]
    },
    {
      "method_id": "M006",
      "method_text": "Automated metadata capture: system records creation time, author, change history for each record",
      "method_tier": "data_management",
      "method_status": "explicit",
      "verbatim_quote": "FAIMS Mobile automated a number of tasks and provided necessary capabilities. It applied the spatial reference system, rendered maps in the workspace, provided layer management (including a data entry layer), enforced shape topology, displayed pre-defined controlled vocabularies for attribute terms, recorded creation time and author for each record, maintained a history of all changes to data",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD002"
      ],
      "realized_through_protocols": [
        "P011"
      ]
    },
    {
      "method_id": "M007",
      "method_text": "Payoff threshold calculation: compare staff-hours required vs features produced for each approach",
      "method_tier": "analysis",
      "method_status": "explicit",
      "verbatim_quote": "A minimum threshold for automation can be extrapolated from our 2017-18 fieldwork and the Urban Occupations Project.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "enabled_by_designs": [
        "RD003"
      ],
      "realized_through_protocols": [
        "P012"
      ]
    },
    {
      "method_id": "M008",
      "method_text": "Error characterization: categorize digitization errors by type (false positives, false negatives, double-marking, classification errors)",
      "method_tier": "analysis",
      "method_status": "explicit",
      "verbatim_quote": "Second, a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error rate (see Table 3). Forty-two of these errors were false negatives (symbols missed by students). Six were double-marked (Student C digitised a section of a map twice). Students made only one classification error (a similar symbol mistaken for a benchmark), and no outright false positives.",
      "location": {
        "section": "Results",
        "subsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "enabled_by_designs": [
        "RD001"
      ],
      "realized_through_protocols": [
        "P013"
      ]
    },
    {
      "method_id": "M009",
      "method_text": "Repurposing system from other project activities for map digitization",
      "method_tier": "adaptation",
      "method_status": "explicit",
      "verbatim_quote": "Undergraduates in the associated field school digitised data from maps using a system repurposed from other project activities.",
      "location": {
        "section": "Introduction",
        "page": 1,
        "paragraph": 1
      },
      "enabled_by_designs": [
        "RD006"
      ],
      "realized_through_protocols": [
        "P014"
      ]
    },
    {
      "method_id": "M010",
      "method_text": "Digital field data collection workflows to produce FAIR and analysis-ready datasets",
      "method_tier": "data_management",
      "method_status": "explicit",
      "verbatim_quote": "All three approaches involved digital field data collection workflows, improving research transparency and facilitating production of Findable, Accessible, Interoperable, and Reproducible (FAIR) and analysis-ready datasets.",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD007",
        "RD008"
      ],
      "realized_through_protocols": [
        "P015"
      ]
    },
    {
      "method_id": "M011",
      "method_text": "Visiting known burial mounds to register location and condition",
      "method_tier": "data_collection",
      "method_status": "explicit",
      "verbatim_quote": "(1) visiting known burial mounds, registering their location and condition",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD008"
      ],
      "realized_through_protocols": [
        "P016"
      ]
    },
    {
      "method_id": "M012",
      "method_text": "Identifying changes in mound condition using satellite imagery",
      "method_tier": "monitoring",
      "method_status": "explicit",
      "verbatim_quote": "(2) identifying changes in mound condition using satellite imagery",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD008"
      ],
      "realized_through_protocols": [
        "P017"
      ]
    },
    {
      "method_id": "M013",
      "method_text": "Digitising mounds from Soviet military topographic maps followed by ground-truthing",
      "method_tier": "data_collection",
      "method_status": "explicit",
      "verbatim_quote": "(3) digitising mounds from over 20,000 sq km of Soviet military 1:50,000 topographic maps covering southeast Bulgaria, followed by ground-truthing (which continued through 2022)",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD008"
      ],
      "realized_through_protocols": [
        "P018",
        "P019"
      ]
    },
    {
      "method_id": "M014",
      "method_text": "Crowdsourcing map digitization using undergraduate field school participants",
      "method_tier": "data_collection",
      "method_status": "explicit",
      "verbatim_quote": "This paper discusses the digitisation of mound symbols from maps using a crowdsourcing approach involving undergraduate students associated with the project.",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD006",
        "RD008"
      ],
      "realized_through_protocols": [
        "P020"
      ]
    },
    {
      "method_id": "M015",
      "method_text": "Leveraging field school downtime for auxiliary map digitization: concentrated work during adverse weather (rainy days) and when students remain at base",
      "method_tier": "opportunistic_data_collection",
      "method_status": "explicit",
      "verbatim_quote": "Digitisation was undertaken as a secondary activity... In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days",
      "location": {
        "section": "Approach",
        "subsection": "2.2",
        "page": 4
      },
      "enabled_by_designs": [
        "RD006",
        "RD009"
      ],
      "realized_through_protocols": [
        "P021",
        "P038"
      ],
      "consolidation_metadata": {
        "consolidated_from": [
          "M015",
          "M025"
        ],
        "consolidation_type": "identical_concept",
        "information_preserved": "complete",
        "rationale": "M015 and M025 describe the same method of leveraging field school downtime. M025 execution details integrated into M015."
      }
    },
    {
      "method_id": "M016",
      "method_text": "Stripping GIS functionality to essentials: layer selection, shape digitisation, annotation with validation and automation",
      "method_tier": "interface_simplification",
      "method_status": "explicit",
      "verbatim_quote": "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validation and automation to improve data quality.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "enabled_by_designs": [
        "RD010"
      ],
      "realized_through_protocols": [
        "P022"
      ]
    },
    {
      "method_id": "M017",
      "method_text": "Staff-controlled geospatial data preparation and management while volunteers focus on digitization",
      "method_tier": "division_of_labor",
      "method_status": "explicit",
      "verbatim_quote": "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only minutes of training.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "enabled_by_designs": [
        "RD010",
        "RD012"
      ],
      "realized_through_protocols": [
        "P023"
      ]
    },
    {
      "method_id": "M018",
      "method_text": "Refinement approach: Iterate system design across field seasons based on experience",
      "method_tier": "iterative_development",
      "method_status": "explicit",
      "verbatim_quote": "This approach was refined during the 2018 field season. The outcomes of both field seasons are discussed in this paper.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 3
      },
      "enabled_by_designs": [
        "RD010"
      ],
      "realized_through_protocols": [
        "P024"
      ]
    },
    {
      "method_id": "M019",
      "method_text": "FAIMS Mobile platform customization via definition files for map digitization",
      "method_tier": "platform_adaptation",
      "method_status": "explicit",
      "verbatim_quote": "Having decided to adopt a crowdsourced approach to produce VGI, we chose to customise FAIMS Mobile for map digitisation... Briefly, FAIMS Mobile is a server-client platform that generates customised Android applications for data collection during offline field research. Customisation is accomplished via definition files that can be shared, modified, and redeployed.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD011"
      ],
      "realized_through_protocols": [
        "P025",
        "P026"
      ]
    },
    {
      "method_id": "M020",
      "method_text": "Testing transferability of field data capture usability approaches to desk-based digitization",
      "method_tier": "usability_transfer",
      "method_status": "explicit",
      "verbatim_quote": "Third, it allowed us to test the idea that usability approaches from data capture during kinetic fieldwork were beneficially transferable to digitisation work.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD011"
      ],
      "realized_through_protocols": [
        "P027"
      ]
    },
    {
      "method_id": "M021",
      "method_text": "Seven-stage implementation workflow dividing specialist and volunteer activities",
      "method_tier": "workflow_management",
      "method_status": "explicit",
      "verbatim_quote": "The stages of FAIMS Mobile implementation (Fig. 3) included: (1) project staff modelled the data and workflow to ensure that the final dataset met research needs, (2) a junior software developer worked with project staff to customise the system, (3) project staff defined a spatial reference system (SRS) and imported preprocessed historical maps, (4) volunteers drew a shape (usually a point) wherever they saw a target symbol and (5) volunteers transcribed attributes from the map, (6) project staff exported data using the FAIMS Mobile server, (7) project staff undertook a targeted accuracy-checking exercise.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 1
      },
      "enabled_by_designs": [
        "RD012"
      ],
      "realized_through_protocols": [
        "P028",
        "P029",
        "P030",
        "P031",
        "P032",
        "P033",
        "P034"
      ]
    },
    {
      "method_id": "M022",
      "method_text": "Multi-source time-on-task data collection combining programmer timesheets, device timestamps, and staff journals",
      "method_tier": "evaluation_data_collection",
      "method_status": "explicit",
      "verbatim_quote": "To measure inputs, we collated the amount of time spent by various participants in the process, including the student programmer who instantiated the customisation, the student volunteers who undertook the digitisation, and project staff who configured the system, supported volunteers, exported data, and checked for errors. Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project staff logged time-on-task for activities in journals.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD013"
      ],
      "realized_through_protocols": [
        "P035"
      ]
    },
    {
      "method_id": "M023",
      "method_text": "Random sampling for accuracy assessment of volunteer digitization work",
      "method_tier": "quality_assurance",
      "method_status": "explicit",
      "verbatim_quote": "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD013"
      ],
      "realized_through_protocols": [
        "P036"
      ]
    },
    {
      "method_id": "M024",
      "method_text": "Application performance mitigation: Export data and instantiate fresh application when performance degrades",
      "method_tier": "performance_management",
      "method_status": "explicit",
      "verbatim_quote": "Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application. Since data structures were identical, aggregation of multiple exports was trivial.",
      "location": {
        "section": "Results",
        "subsection": "3.4 Application performance",
        "page": 7,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD013"
      ],
      "realized_through_protocols": [
        "P037"
      ]
    },
    {
      "method_id": "M026",
      "method_text": "Quality assurance by project staff: Review randomly selected digitisation work to characterise error patterns",
      "method_tier": "quality_assurance",
      "method_status": "explicit",
      "verbatim_quote": "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors... a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error rate",
      "location": {
        "section": "Results",
        "subsection": "3.5.2 Digitisation errors",
        "page": 7,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD013"
      ],
      "realized_through_protocols": [
        "P036"
      ]
    },
    {
      "method_id": "M027",
      "method_text": "Continuum analysis: Position approaches along setup cost vs ongoing expert involvement trade-off spectrum",
      "method_tier": "comparative_analysis",
      "method_status": "explicit",
      "verbatim_quote": "These approaches fall along a continuum from the first, which requires the least setup cost, time, and technical support, but the most ongoing expert involvement, to the last, which requires the greatest setup cost, time, and technical input but the least ongoing expert involvement (Fig. 7).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1 Choosing an approach",
        "page": 9,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD015"
      ],
      "realized_through_protocols": [
        "P042"
      ]
    },
    {
      "method_id": "M028",
      "method_text": "Staff time payoff calculation: Calculate feature count thresholds using digitization rates and staff hour investments",
      "method_tier": "threshold_analysis",
      "method_status": "explicit",
      "verbatim_quote": "After brief workspace setup, project staff with desktop GIS experience could digitise at a sustained rate of 60\u201375 features per staff-hour. At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420\u20134,275 staff-digitised features (see Table 4).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 1
      },
      "enabled_by_designs": [
        "RD016"
      ],
      "realized_through_protocols": [
        "P043"
      ]
    },
    {
      "method_id": "M029",
      "method_text": "ML threshold extrapolation: Use Urban Occupations Project benchmark to estimate minimum ML payoff threshold",
      "method_tier": "threshold_analysis",
      "method_status": "explicit",
      "verbatim_quote": "A minimum threshold for automation can be extrapolated from our 2017-18 fieldwork and the Urban Occupations Project. We spent 44 staff hours customising and deploying a streamlined geospatial system in FAIMS Mobile, 184 participant-hours digitising features, seven staff-hours directly supporting that digitisation, and six staff hours checking for errors. These 241 h produced a dataset of 10,827 features, a rate of 44.9 features/person-hour. At that rate, the 1,300 h it took to deploy the ML approach taken by Can, Gerrits, and Kabadayi would yield about 58,400 records",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.2 Machine learning versus crowdsourcing",
        "page": 10,
        "paragraph": 2
      },
      "enabled_by_designs": [
        "RD016"
      ],
      "realized_through_protocols": [
        "P044"
      ]
    },
    {
      "method_id": "M030",
      "method_text": "Marginal cost analysis: Calculate per-feature staff support cost to assess scalability",
      "method_tier": "cost_analysis",
      "method_status": "explicit",
      "verbatim_quote": "Third, the marginal cost for each additional feature digitised is low. This figure includes in-field support and quality assurance (13 h), and translates to 4.3 s of staff support per additional feature. Thus, the larger the dataset, the more value is extracted from the setup and deployment time.",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "enabled_by_designs": [
        "RD016"
      ],
      "realized_through_protocols": [
        "P045"
      ]
    }
  ],
  "protocols": [
    {
      "protocol_id": "P001",
      "protocol_text": "Programmer time measurement: timesheets from student programmer",
      "protocol_tier": "measurement",
      "protocol_status": "explicit",
      "verbatim_quote": "Project records provided much of this data (timesheets from the programmer",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "implements_method": "M001"
    },
    {
      "protocol_id": "P002",
      "protocol_text": "Student time measurement: record creation timestamps from FAIMS Mobile system",
      "protocol_tier": "measurement",
      "protocol_status": "explicit",
      "verbatim_quote": "record creation timestamps for students using the system",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "implements_method": "M001",
      "parameters": {
        "time_recorded": "start and end times of feature creation as recorded by devices",
        "time_metric": "work time excluding pauses between records"
      }
    },
    {
      "protocol_id": "P003",
      "protocol_text": "Staff time measurement: time-on-task logging in field journals",
      "protocol_tier": "measurement",
      "protocol_status": "explicit",
      "verbatim_quote": "project staff logged time-on-task for activities in journals",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "implements_method": "M001"
    },
    {
      "protocol_id": "P004",
      "protocol_text": "Feature counting: extract count from digitization application records",
      "protocol_tier": "measurement",
      "protocol_status": "explicit",
      "verbatim_quote": "We took the number of features digitised as the output.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "implements_method": "M002"
    },
    {
      "protocol_id": "P005",
      "protocol_text": "Quality assurance sampling: review 4 randomly selected maps (7% of total) for error characterization",
      "protocol_tier": "validation",
      "protocol_status": "explicit",
      "verbatim_quote": "Second, a review by project staff of four randomly selected maps (7% of the total)",
      "location": {
        "section": "Results",
        "subsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "implements_method": "M003",
      "parameters": {
        "sample_size": "4 maps",
        "sample_percentage": "7% of total maps",
        "sampling_method": "random selection"
      }
    },
    {
      "protocol_id": "P006",
      "protocol_text": "System customization: student programmer creates definition files (35h in 2017, 1h in 2018)",
      "protocol_tier": "setup",
      "protocol_status": "explicit",
      "verbatim_quote": "For the first season of use (2017), creating the Map Digitisation customisation of FAIMS Mobile required 35 h from an undergraduate student programmer plus 4 h from staff (Nassif-Haynes et al., 2021).",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 1
      },
      "implements_method": "M004",
      "parameters": {
        "2017_programmer_time": "35 hours",
        "2017_staff_time": "4 hours",
        "2018_programmer_time": "1 hour"
      }
    },
    {
      "protocol_id": "P007",
      "protocol_text": "Server setup and device configuration: 3h in 2017, 1h in 2018",
      "protocol_tier": "setup",
      "protocol_status": "explicit",
      "verbatim_quote": "Setup of the server and configuration of the client devices in the field required 3 h from staff.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 1
      },
      "implements_method": "M004",
      "parameters": {
        "2017_setup_time": "3 hours",
        "2018_setup_time": "1 hour"
      }
    },
    {
      "protocol_id": "P008",
      "protocol_text": "Map preparation: tiling and adding pyramids (1.5h in 2017, 0.5h in 2018)",
      "protocol_tier": "data_preparation",
      "protocol_status": "explicit",
      "verbatim_quote": "Map preparation (tiling, adding pyramids) required about 1.5 h.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 1
      },
      "implements_method": "M004",
      "parameters": {
        "2017_map_prep_time": "1.5 hours",
        "2018_map_prep_time": "0.5 hours",
        "procedure": "tiling and adding pyramids to GeoTIFF files"
      }
    },
    {
      "protocol_id": "P009",
      "protocol_text": "Volunteer training: minimal training, students begin digitizing after only minutes",
      "protocol_tier": "training",
      "protocol_status": "explicit",
      "verbatim_quote": "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only minutes of training.",
      "location": {
        "section": "Approach",
        "subsection": "2.2 Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "paragraph": 4
      },
      "implements_method": "M005",
      "parameters": {
        "training_duration": "minutes",
        "staff_supervision": "no more than half an hour across entire season"
      }
    },
    {
      "protocol_id": "P010",
      "protocol_text": "Interface design: toggle between map view (geospatial) and form view (attributes)",
      "protocol_tier": "interface_design",
      "protocol_status": "explicit",
      "verbatim_quote": "Volunteers could toggle between a map view for geospatial data interactions and a form view for attribute creation and editing.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 4
      },
      "implements_method": "M005"
    },
    {
      "protocol_id": "P011",
      "protocol_text": "Automated metadata: system records creation time, author, change history automatically",
      "protocol_tier": "automation",
      "protocol_status": "explicit",
      "verbatim_quote": "recorded creation time and author for each record, maintained a history of all changes to data",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 2
      },
      "implements_method": "M006"
    },
    {
      "protocol_id": "P012",
      "protocol_text": "Threshold calculation: divide staff hours by digitization rate to find break-even point",
      "protocol_tier": "calculation",
      "protocol_status": "explicit",
      "verbatim_quote": "At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420\u20134,275 staff-digitised features",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "paragraph": 2
      },
      "implements_method": "M007",
      "parameters": {
        "calculation_formula": "staff_hours \u00d7 digitization_rate_per_hour = threshold_features"
      }
    },
    {
      "protocol_id": "P013",
      "protocol_text": "Error categorization: classify as false positive, false negative, double-marked, or classification error",
      "protocol_tier": "analysis",
      "protocol_status": "explicit",
      "verbatim_quote": "Forty-two of these errors were false negatives (symbols missed by students). Six were double-marked (Student C digitised a section of a map twice). Students made only one classification error (a similar symbol mistaken for a benchmark), and no outright false positives.",
      "location": {
        "section": "Results",
        "subsection": "3.5.2 Digitisation errors",
        "page": 8,
        "paragraph": 1
      },
      "implements_method": "M008",
      "parameters": {
        "error_types": [
          "false_positive",
          "false_negative",
          "double_marked",
          "classification_error"
        ]
      }
    },
    {
      "protocol_id": "P014",
      "protocol_text": "System repurposing: adapt FAIMS Mobile from in-field legacy data verification to map digitization",
      "protocol_tier": "adaptation",
      "protocol_status": "explicit",
      "verbatim_quote": "Reusing the platform for digitisation offered a consistent working environment for users, reduced administrative load on staff, leveraged our experience with the platform, and avoided any additional hardware or software costs.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 3
      },
      "implements_method": "M009"
    },
    {
      "protocol_id": "P015",
      "protocol_text": "FAIR data principles implementation: produce rich and plural metadata at time of data creation",
      "protocol_tier": "data_management",
      "protocol_status": "explicit",
      "verbatim_quote": "Exported data was consistent and complete, ready for analysis with minimal cleaning. This data adhered to key elements of the FAIR data principles, especially the production of 'rich' and 'plural' metadata at the time of data creation (principles F2, R1.1\u20131.3; GO-FAIR, 2017).",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 5
      },
      "implements_method": "M010",
      "parameters": {
        "FAIR_principles_addressed": [
          "F2",
          "R1.1",
          "R1.2",
          "R1.3"
        ],
        "metadata_timing": "at time of data creation"
      }
    },
    {
      "protocol_id": "P016",
      "protocol_text": "Mound registration: visit known mounds, record GPS location and condition assessment",
      "protocol_tier": "data_collection",
      "protocol_status": "explicit",
      "verbatim_quote": "visiting known burial mounds, registering their location and condition",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "implements_method": "M011"
    },
    {
      "protocol_id": "P017",
      "protocol_text": "Satellite monitoring: identify condition changes in mounds using satellite imagery comparison",
      "protocol_tier": "monitoring",
      "protocol_status": "explicit",
      "verbatim_quote": "identifying changes in mound condition using satellite imagery",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "implements_method": "M012"
    },
    {
      "protocol_id": "P018",
      "protocol_text": "Map digitization: extract mound symbols from Soviet 1:50,000 topographic maps covering 20,000+ sq km",
      "protocol_tier": "data_collection",
      "protocol_status": "explicit",
      "verbatim_quote": "digitising mounds from over 20,000 sq km of Soviet military 1:50,000 topographic maps covering southeast Bulgaria",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "implements_method": "M013",
      "parameters": {
        "map_scale": "1:50,000",
        "map_type": "Soviet military topographic maps",
        "coverage_area": "over 20,000 sq km"
      }
    },
    {
      "protocol_id": "P019",
      "protocol_text": "Ground-truthing: field verification of digitized mound locations (continued through 2022)",
      "protocol_tier": "validation",
      "protocol_status": "explicit",
      "verbatim_quote": "followed by ground-truthing (which continued through 2022)",
      "location": {
        "section": "Introduction",
        "subsection": "1.1 The Tundzha Regional Archaeology Project",
        "page": 2,
        "paragraph": 2
      },
      "implements_method": "M013",
      "parameters": {
        "validation_period": "2017-2022",
        "validation_method": "field verification of digitized locations"
      }
    },
    {
      "protocol_id": "P020",
      "protocol_text": "Undergraduate volunteers digitize map features using mobile application during field school",
      "protocol_tier": "data_collection",
      "protocol_status": "explicit",
      "verbatim_quote": "Undergraduates in the associated field school digitised data from maps using a system repurposed from other project activities.",
      "location": {
        "section": "Introduction",
        "page": 1,
        "paragraph": 1
      },
      "implements_method": "M014"
    },
    {
      "protocol_id": "P021",
      "protocol_text": "Secondary activity scheduling: Digitization during rainy days and when students remain at field base",
      "protocol_tier": "scheduling",
      "protocol_status": "explicit",
      "verbatim_quote": "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days... In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation.",
      "location": {
        "section": "Results",
        "subsection": "3.2 Student-volunteer digitisation velocity and volume",
        "page": 7,
        "paragraph": 1
      },
      "implements_method": "M015"
    },
    {
      "protocol_id": "P022",
      "protocol_text": "Essential GIS operations: Hide unnecessary features, expose only layer selection, shape digitization, attribute annotation controls",
      "protocol_tier": "interface_design",
      "protocol_status": "explicit",
      "verbatim_quote": "GIS features not needed for digitisation were hidden or eliminated. Digitisation and metadata creation required no GIS or computing skills. Students capable of selecting files from a list, panning and zooming a map, dropping a point, and filling out a form were able to create data. Only a few important controls, including layer management, map navigation, record search and retrieval, and shape and attribute creation and editing, were present.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 2
      },
      "implements_method": "M016"
    },
    {
      "protocol_id": "P023",
      "protocol_text": "Staff insulation workflow: Staff handle setup, layer management, aggregation, export, backup; volunteers only digitize",
      "protocol_tier": "workflow_management",
      "protocol_status": "explicit",
      "verbatim_quote": "Since project staff set up the infrastructure and pre-processed and loaded the required maps, volunteers were insulated from the friction of setup, layer management, data aggregation, export, and backup.",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 6,
        "paragraph": 1
      },
      "implements_method": "M017"
    },
    {
      "protocol_id": "P024",
      "protocol_text": "2018 refinements: Add validation for lat/long population, improve error handling based on 2017 experience",
      "protocol_tier": "iterative_improvement",
      "protocol_status": "explicit",
      "verbatim_quote": "For the second season, adding additional validation to ensure population of latitude and longitude from GPS (see 'Recoverable data omissions and incomplete records' below) took 1 h of development from the programmer.",
      "location": {
        "section": "Results",
        "subsection": "3.1 Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "paragraph": 2
      },
      "implements_method": "M018"
    },
    {
      "protocol_id": "P025",
      "protocol_text": "FAIMS Mobile customization: Create definition files interpreted by platform to generate Android data collection app",
      "protocol_tier": "software_development",
      "protocol_status": "explicit",
      "verbatim_quote": "Customisation is accomplished via definition files that can be shared, modified, and redeployed. FAIMS Mobile interprets the definition files to generate a specific data capture application.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 2
      },
      "implements_method": "M019",
      "parameters": {
        "platform": "FAIMS Mobile",
        "customization_mechanism": "definition files",
        "output": "Android application"
      }
    },
    {
      "protocol_id": "P026",
      "protocol_text": "Multi-device offline data collection with opportunistic network synchronization",
      "protocol_tier": "data_synchronization",
      "protocol_status": "explicit",
      "verbatim_quote": "Data collection works offline, and can employ as many devices as necessary. It is later synchronised opportunistically, when a network is available.",
      "location": {
        "section": "Approach",
        "subsection": "2.3 Using a mobile application for map digitisation",
        "page": 4,
        "paragraph": 2
      },
      "implements_method": "M019"
    },
    {
      "protocol_id": "P027",
      "protocol_text": "Unobtrusive interface design: Minimize user interactions with recording mechanism, conform to workflow, automate metadata",
      "protocol_tier": "usability_design",
      "protocol_status": "explicit",
      "verbatim_quote": "UIs for mobile data collection systems must allow the user to (1) focus on observations while minimising interactions with the recording mechanism, (2), enter large amounts of data quickly and accurately, with appropriate automation and validation, and (3) aid recording of data context such as metadata or related data... In short, such systems should be unobtrusive, conform to research workflows rather than forcing users to compromise, and automate and validate entered (meta)data aggressively",
      "location": {
        "section": "Introduction",
        "subsection": "1.4 Sociotechnical barriers to collaborative map digitisation",
        "page": 3,
        "paragraph": 6
      },
      "implements_method": "M020"
    },
    {
      "protocol_id": "P028",
      "protocol_text": "Stages 1-2: Staff model data/workflow, then developer customizes system (2017: 35h+4h; 2018: 1h refinement)",
      "protocol_tier": "workflow_implementation",
      "protocol_status": "explicit",
      "verbatim_quote": "(1) project staff modelled the data and workflow... (2) a junior software developer worked with project staff to customise the system",
      "location": {
        "section": "Approach",
        "subsection": "2.4",
        "page": 5
      },
      "implements_method": "M021",
      "parameters": {
        "2017_staff_hours": 4,
        "2017_dev_hours": 35,
        "2018_hours": 1
      },
      "consolidation_metadata": {
        "consolidated_from": [
          "P028",
          "P029"
        ],
        "consolidation_type": "sequential_stages",
        "information_preserved": "complete",
        "rationale": "P028 and P029 are sequential stages 1-2 of pre-fieldwork development. Consolidated as tightly coupled."
      }
    },
    {
      "protocol_id": "P030",
      "protocol_text": "Stage 3: Staff define spatial reference system and import preprocessed historical maps",
      "protocol_tier": "workflow_implementation",
      "protocol_status": "explicit",
      "verbatim_quote": "project staff defined a spatial reference system (SRS) and imported preprocessed historical maps",
      "location": {
        "section": "Approach",
        "subsection": "2.4 Design and implementation of the recording system",
        "page": 5,
        "paragraph": 1
      },
      "implements_method": "M021",
      "parameters": {
        "map_format": "georeferenced GeoTIFFs",
        "preprocessing": "tiling, adding pyramids"
      }
    },
    {
      "protocol_id": "P031",
      "protocol_text": "Stages 4-5: Volunteers perform digitization - draw shapes at target locations, then transcribe attributes",
      "protocol_tier": "workflow_implementation",
      "protocol_status": "explicit",
      "verbatim_quote": "(4) volunteers drew a shape (usually a point) wherever they saw a target symbol and (5) volunteers transcribed attributes from the map",
      "location": {
        "section": "Approach",
        "subsection": "2.4",
        "page": 5
      },
      "implements_method": "M021",
      "consolidation_metadata": {
        "consolidated_from": [
          "P031",
          "P032"
        ],
        "consolidation_type": "sequential_stages",
        "information_preserved": "complete",
        "rationale": "P031 and P032 are volunteer-performed stages 4-5 of digitization. Consolidated as single volunteer activity."
      }
    },
    {
      "protocol_id": "P033",
      "protocol_text": "Stages 6-7: Staff post-processing - export data from server, then accuracy-checking",
      "protocol_tier": "workflow_implementation",
      "protocol_status": "explicit",
      "verbatim_quote": "(6) project staff exported data using the FAIMS Mobile server, (7) project staff undertook a targeted accuracy-checking exercise",
      "location": {
        "section": "Approach",
        "subsection": "2.4",
        "page": 5
      },
      "implements_method": "M021",
      "consolidation_metadata": {
        "consolidated_from": [
          "P033",
          "P034"
        ],
        "consolidation_type": "sequential_stages",
        "information_preserved": "complete",
        "rationale": "P033 and P034 are post-fieldwork staff stages 6-7. Consolidated as both QA activities."
      }
    },
    {
      "protocol_id": "P035",
      "protocol_text": "Time tracking protocol: Combine programmer timesheets, device record timestamps, and staff journal logs",
      "protocol_tier": "evaluation_data_collection",
      "protocol_status": "explicit",
      "verbatim_quote": "Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project staff logged time-on-task for activities in journals.",
      "location": {
        "section": "Approach",
        "subsection": "2.5 Evaluating the digitisation approach",
        "page": 6,
        "paragraph": 2
      },
      "implements_method": "M022",
      "parameters": {
        "data_sources": [
          "programmer timesheets",
          "device record creation timestamps",
          "staff time-on-task journals"
        ]
      }
    },
    {
      "protocol_id": "P036",
      "protocol_text": "Random map selection for staff re-digitization and error characterization",
      "protocol_tier": "quality_assurance",
      "protocol_status": "explicit",
      "verbatim_quote": "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors... a review by project staff of four randomly selected maps (7% of the total)",
      "location": {
        "section": "Results",
        "subsection": "3.5.2 Digitisation errors",
        "page": 7,
        "paragraph": 2
      },
      "implements_method": "M023",
      "parameters": {
        "sample_size": "4 maps",
        "sample_percentage": "7% of total maps",
        "verification_method": "staff re-digitization and comparison"
      }
    },
    {
      "protocol_id": "P037",
      "protocol_text": "Performance degradation mitigation: Export all data, instantiate empty application, continue work, aggregate exports",
      "protocol_tier": "performance_management",
      "protocol_status": "explicit",
      "verbatim_quote": "Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application. Since data structures were identical, aggregation of multiple exports was trivial.",
      "location": {
        "section": "Results",
        "subsection": "3.4 Application performance",
        "page": 7,
        "paragraph": 2
      },
      "implements_method": "M024",
      "parameters": {
        "performance_threshold": "approximately 2,500 records per device",
        "degradation_symptom": "lat/long extraction time increased from 3-5s to 30s"
      }
    },
    {
      "protocol_id": "P038",
      "protocol_text": "Two-season execution: 2017 (125.8h, 8,343 feat, 54s avg) + 2018 (63.6h, 2,484 feat, 92s avg) = 189.4h, 10,827 feat total",
      "protocol_tier": "data_collection_execution",
      "protocol_status": "explicit",
      "verbatim_quote": "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days, during which time 8,343 features were digitised... In 2018, use was more sporadic... 63.6 person-hours, with 2,484 features recorded",
      "location": {
        "section": "Results",
        "subsection": "3.2",
        "page": 7
      },
      "implements_method": "M015",
      "parameters": {
        "2017": {
          "hours": 125.8,
          "features": 8343,
          "maps": 42,
          "avg_s": 54,
          "pattern": "concentrated"
        },
        "2018": {
          "hours": 63.6,
          "features": 2484,
          "maps": 16,
          "avg_s": 92,
          "pattern": "sporadic"
        },
        "total": {
          "hours": 189.4,
          "features": 10827,
          "maps": 58,
          "avg_s": 63
        }
      },
      "consolidation_metadata": {
        "consolidated_from": [
          "P038",
          "P039"
        ],
        "consolidation_type": "complementary_execution",
        "information_preserved": "complete",
        "rationale": "P038 and P039 report two seasons of same protocol. Consolidated with combined totals."
      }
    },
    {
      "protocol_id": "P040",
      "protocol_text": "Spatial data omission recovery: Re-extract latitude/longitude from preserved geodatabase geometries",
      "protocol_tier": "error_correction",
      "protocol_status": "explicit",
      "verbatim_quote": "Since the geodatabase preserved geometries, spatial omissions were corrected by re-extracting latitude and longitude; only two data points could not be recovered.",
      "location": {
        "section": "Results",
        "subsection": "3.5.1 Recoverable data omissions and incomplete records",
        "page": 7,
        "paragraph": 1
      },
      "implements_method": "M026",
      "parameters": {
        "2017_spatial_errors": 192,
        "2018_spatial_errors": 13,
        "unrecoverable": 2
      }
    },
    {
      "protocol_id": "P041",
      "protocol_text": "Error characterization: Random sample QA checking to identify error types (false positives, false negatives, double-marking, classification errors)",
      "protocol_tier": "quality_assurance",
      "protocol_status": "explicit",
      "verbatim_quote": "a review by project staff of four randomly selected maps (7% of the total) found 49 errors from a true count of 834 features, a 5.87% error rate (see Table 3). Forty-two of these errors were false negatives (symbols missed by students). Six were double-marked (Student C digitised a section of a map twice). Students made only one classification error (a similar symbol mistaken for a benchmark), and no outright false positives.",
      "location": {
        "section": "Results",
        "subsection": "3.5.2 Digitisation errors",
        "page": 7,
        "paragraph": 2
      },
      "implements_method": "M026",
      "parameters": {
        "sample_size_maps": 4,
        "sample_percentage": "7%",
        "true_feature_count": 834,
        "total_errors": 49,
        "error_rate_percent": 5.87,
        "false_negatives": 42,
        "double_marked": 6,
        "classification_errors": 1,
        "false_positives": 0
      }
    },
    {
      "protocol_id": "P042",
      "protocol_text": "Trade-off visualization: Position approaches on continuum from fast-setup/high-touch to slow-setup/low-touch",
      "protocol_tier": "analytical_framework",
      "protocol_status": "explicit",
      "verbatim_quote": "These approaches fall along a continuum from the first, which requires the least setup cost, time, and technical support, but the most ongoing expert involvement, to the last, which requires the greatest setup cost, time, and technical input but the least ongoing expert involvement (Fig. 7).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1 Choosing an approach",
        "page": 9,
        "paragraph": 2
      },
      "implements_method": "M027"
    },
    {
      "protocol_id": "P043",
      "protocol_text": "Comprehensive threshold framework: Expert GIS (3,420-4,275\u21924,500), Volunteer GIS (7,410-10,260\u219210,000), Crowdsourcing optimal (10,000-60,000), ML (>60,000)",
      "protocol_tier": "threshold_calculation",
      "protocol_status": "explicit",
      "verbatim_quote": "After brief workspace setup, project staff with desktop GIS experience could digitise at a sustained rate of 60\u201375 features per staff-hour... To summarise in round numbers, a crowdsourcing approach like ours is most suitable for datasets numbering perhaps 10,000\u201360,000 records",
      "location": {
        "section": "Discussion",
        "subsection": "4.1",
        "page": 9
      },
      "implements_method": "M028",
      "parameters": {
        "expert_GIS": {
          "rate": "60-75/h",
          "threshold": "3,420-4,275",
          "conservative": 4500
        },
        "volunteer_GIS": {
          "rate": "130-180/h",
          "threshold": "7,410-10,260",
          "conservative": 10000
        },
        "crowdsourcing": {
          "rate": "44.9/h",
          "optimal_range": "10,000-60,000"
        },
        "ML": {
          "training_hours": 1300,
          "threshold_estimate": 58400,
          "conservative": 60000
        }
      },
      "consolidation_metadata": {
        "consolidated_from": [
          "P043",
          "P044",
          "P046"
        ],
        "consolidation_type": "unified_framework",
        "information_preserved": "complete",
        "rationale": "P043, P044, P046 provide parts of single threshold framework. Consolidated as one decision tool."
      }
    },
    {
      "protocol_id": "P045",
      "protocol_text": "Marginal cost calculation: Divide in-field support and QA hours by total features to determine per-feature cost",
      "protocol_tier": "cost_analysis",
      "protocol_status": "explicit",
      "verbatim_quote": "This figure includes in-field support and quality assurance (13 h), and translates to 4.3 s of staff support per additional feature. Thus, the larger the dataset, the more value is extracted from the setup and deployment time. Adding more volunteers does not increase setup time at all. Preparing and distributing additional maps took only 6 min per map (6 h for 58 maps).",
      "location": {
        "section": "Discussion",
        "subsection": "4.1.1 Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "paragraph": 3
      },
      "implements_method": "M030",
      "parameters": {
        "in_field_support_and_QA_hours": 13,
        "marginal_staff_support_per_feature_seconds": 4.3,
        "map_preparation_minutes": 6,
        "maps_prepared": 58,
        "total_map_prep_hours": 6
      }
    }
  ],
  "project_metadata": {
    "timeline": {
      "project_start": "2008",
      "project_duration": "2008-present (2023)",
      "data_collection_period": "2017-2018",
      "field_seasons": [
        "2017",
        "2018"
      ]
    },
    "location": {
      "country": "Bulgaria",
      "regions": [
        "Kazanlak Valley",
        "Yambol region"
      ],
      "study_area": "Tundzha River watershed (middle and upper)"
    },
    "resources": {
      "personnel": {
        "total_person_hours": 241,
        "staff_hours": 57,
        "volunteer_hours": 184,
        "programmer_hours": 36,
        "staff_setup_hours": 15,
        "in_field_staff_hours": 7
      },
      "equipment": [
        "Mobile devices",
        "FAIMS Mobile platform",
        "Android devices"
      ],
      "data_sources": [
        "Soviet military topographic maps 1:50,000 (georeferenced GeoTIFFs)",
        "Satellite imagery"
      ]
    },
    "track_record": {
      "previous_digitisation_effort": {
        "year": 2010,
        "approach": "Desktop GIS (ArcGIS)",
        "features_digitised": 915,
        "staff_time": "5-7 hours over three weeks",
        "outcome": "Unsuccessful due to volunteer attrition and staff demands"
      },
      "previous_survey_work": {
        "period": "2008-2016",
        "kazanlak_mounds": 773,
        "yambol_mounds": 431,
        "method": "Pedestrian surface survey with manual digitisation"
      }
    }
  },
  "extraction_notes": {
    "pass": 5,
    "section": "Validation & Reporting complete",
    "validation_status": "complete",
    "validation_date": "2025-10-27",
    "quality_metrics": {
      "sourcing_issues": 0,
      "cross_reference_issues": 45,
      "orphan_claims": 21,
      "orphan_evidence": 107,
      "orphan_research_designs": 0,
      "orphan_methods": 0,
      "orphan_protocols": 0
    },
    "extraction_summary": {
      "claims": 78,
      "evidence": 107,
      "implicit_arguments": 6,
      "research_designs": 15,
      "methods": 29,
      "protocols": 40,
      "total_items": 275
    },
    "rdmap_connectivity": {
      "designs_with_methods": "15/15",
      "methods_connected_both_ways": "29/29",
      "protocols_with_methods": "40/40"
    },
    "pass_5_status": "COMPLETE",
    "workflow_status": "ALL 5 PASSES COMPLETE"
  }
}