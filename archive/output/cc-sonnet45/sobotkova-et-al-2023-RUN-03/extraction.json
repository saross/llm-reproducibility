{
  "schema_version": "2.5",
  "extraction_timestamp": "2025-10-25T03:15:00Z",
  "extractor": "Claude Sonnet 4.5",
  "paper_metadata": {
    "title": "Creating large, high-quality geospatial datasets from historical maps using novice volunteers",
    "authors": [
      "Adela Sobotkova",
      "Shawn A. Ross",
      "Christian Nassif-Haynes",
      "Brian Ballsun-Stanton"
    ],
    "year": 2023,
    "journal": "Applied Geography",
    "doi": "10.1016/j.apgeog.2023.102967"
  },
  "evidence": [
    {
      "evidence_id": "E001",
      "evidence_type": "quantitative_measurement",
      "observation_text": "10,827 mound features digitized from Soviet military topographic maps",
      "verbatim_quote": "FAIMS Mobile was used to digitise 10,827 mound features from Soviet military topographic maps.",
      "source_location": {
        "section": "Abstract",
        "page": 1,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Exact count of digitized features"
    },
    {
      "evidence_id": "E002",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Total digitization effort: 241 person-hours (57 from staff, 184 from novice volunteers)",
      "verbatim_quote": "This digitisation required 241 person-hours (57 from staff; 184 from novice volunteers)",
      "source_location": {
        "section": "Abstract",
        "page": 1,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Complete person-hours breakdown consolidated from breakdown items",
      "consolidation_metadata": {
        "consolidated_from": [
          "E002-original",
          "E003",
          "E004"
        ],
        "consolidation_type": "breakdown_synthesis",
        "consolidation_rationale": "Three items from identical quote representing total and breakdown - consolidated to avoid redundancy while preserving all numeric values",
        "consolidation_timestamp": "2025-10-25T23:13:29.412485"
      }
    },
    {
      "evidence_id": "E005",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Error rate under 6%",
      "verbatim_quote": "with an error rate under 6%",
      "source_location": {
        "section": "Abstract",
        "page": 1,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "upper_bound",
        "uncertainty_language": "under 6%"
      },
      "measurement_precision": {
        "value_type": "upper_bound",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Quality metric reported as upper bound"
    },
    {
      "evidence_id": "E006",
      "evidence_type": "qualitative_observation",
      "observation_text": "Dataset was consistent, well-documented, and ready for analysis with a few hours of processing",
      "verbatim_quote": "The resulting dataset was consistent, welldocumented, and ready for analysis with a few hours of processing.",
      "source_location": {
        "section": "Abstract",
        "page": 1,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": null,
      "extraction_confidence": "high",
      "extraction_notes": "Quality assessment of output dataset"
    },
    {
      "evidence_id": "E007",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Estimated 50,000 burial mounds were built in Bulgarian lands",
      "verbatim_quote": "An estimated 50,000 burial mounds were built in Bulgarian lands from the Early Bronze Age through the Middle Ages",
      "source_location": {
        "section": "1.2. Burial mounds in Bulgarian archaeology",
        "page": 2,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "estimate",
        "uncertainty_language": "estimated"
      },
      "measurement_precision": {
        "value_type": "estimate",
        "precision_level": "low"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Archaeological context - estimate from cited sources"
    },
    {
      "evidence_id": "E008",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Mounds range 10-50m diameter, 0.5-20m height",
      "verbatim_quote": "They were constructed of earth and rubble, and range in size from 10 to 50 m in diameter and 0.5\u201320 m in height",
      "source_location": {
        "section": "1.2. Burial mounds in Bulgarian archaeology",
        "page": 2,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "range",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Physical characteristics of target features"
    },
    {
      "evidence_id": "E009",
      "evidence_type": "quantitative_measurement",
      "observation_text": "TRAP catalogued 773 mounds in Kazanlak Valley and 431 mounds in Yambol region between 2008-2016",
      "verbatim_quote": "Between 2008 and 2016, TRAP catalogued some 773 mounds in the Kazanlak Valley and 431 mounds in the Yambol region using pedestrian surface survey",
      "source_location": {
        "section": "1.1. The Tundzha Regional Archaeology Project",
        "page": 2,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Consolidated prior work output from both regions",
      "consolidation_metadata": {
        "consolidated_from": [
          "E009",
          "E010"
        ],
        "consolidation_type": "breakdown_synthesis",
        "consolidation_rationale": "Two items from same quote representing regional breakdown of same activity - consolidated for clarity",
        "consolidation_timestamp": "2025-10-25T23:13:29.412497"
      }
    },
    {
      "evidence_id": "E011",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Soviet maps at 1:50,000 scale from 1980s, each covering ca 400 sq km",
      "verbatim_quote": "The goal of the work was to extract archaeological features from 1:50,000 scale Soviet military topographic maps dating to the 1980s. Available as georeferenced GeoTIFFs (from http://web.uni-plovdiv. bg/vedrin/index_en.html in 2008), each of these maps covers ca 400 sq km.",
      "source_location": {
        "section": "2.1. Archaeological features in Soviet topographic maps",
        "page": 4,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Map specifications"
    },
    {
      "evidence_id": "E012",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Symbols occurred at average 200 per tile (0.5 per sq km), ranging 50-400 per tile",
      "verbatim_quote": "Such symbols occurred at a high density, averaging about 200 per tile (0.5 per sq km), with counts per tile ranging from about 50 to 400.",
      "source_location": {
        "section": "2.1. Archaeological features in Soviet topographic maps",
        "page": 4,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "range",
        "uncertainty_language": "about, ranging from"
      },
      "measurement_precision": {
        "value_type": "range_with_average",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Feature density statistics"
    },
    {
      "evidence_id": "E013",
      "evidence_type": "qualitative_observation",
      "observation_text": "Mound symbols were moderately obtrusive with some aspects of shape or colour shared with other map symbols",
      "verbatim_quote": "The mound symbols were moderately obtrusive; some aspects of shape or colour were shared with other map symbols.",
      "source_location": {
        "section": "2.1. Archaeological features in Soviet topographic maps",
        "page": 4,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": null,
      "extraction_confidence": "high",
      "extraction_notes": "Visual complexity assessment"
    },
    {
      "evidence_id": "E014",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Records relatively simple: point for feature, record number, plus ten attributes",
      "verbatim_quote": "The records we sought to create were relatively simple: a point for the feature, a record number, plus ten attributes.",
      "source_location": {
        "section": "2.1. Archaeological features in Soviet topographic maps",
        "page": 4,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Data structure complexity"
    },
    {
      "evidence_id": "E015",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Maps of Yambol region contained 1,000+ targeted symbols",
      "verbatim_quote": "We knew that the maps of the Yambol region contained 1,000+ of these targeted symbols.",
      "source_location": {
        "section": "2.1. Archaeological features in Soviet topographic maps",
        "page": 4,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "lower_bound",
        "uncertainty_language": "1,000+"
      },
      "measurement_precision": {
        "value_type": "lower_bound",
        "precision_level": "low"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Initial scope estimate"
    },
    {
      "evidence_id": "E016",
      "evidence_type": "qualitative_observation",
      "observation_text": "Students came from range of academic backgrounds in Arts and Humanities, most had no training in archaeology, cartography, or digital methods",
      "verbatim_quote": "Our students came from a range of academic backgrounds in Arts and Humanities. Most had no training in archaeology, cartography, or digital methods",
      "source_location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": null,
      "extraction_confidence": "high",
      "extraction_notes": "Participant characteristics"
    },
    {
      "evidence_id": "E017",
      "evidence_type": "qualitative_observation",
      "observation_text": "2010 desktop GIS digitization: novice volunteers found learning to configure and navigate challenging, many quit, those who continued required ongoing support",
      "verbatim_quote": "Our experience was much like that of other projects: novice volunteers found learning to configure and navigate desktop GIS challenging; many quit and those who continued required ongoing support.",
      "source_location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": null,
      "extraction_confidence": "high",
      "extraction_notes": "Prior approach outcome"
    },
    {
      "evidence_id": "E018",
      "evidence_type": "interpretation",
      "observation_text": "2010 volunteer attrition combined with demands on staff time rendered desktop GIS approach unsuccessful",
      "verbatim_quote": "In the end, volunteer attrition combined with demands on staff time during the height of fieldwork rendered this approach unsuccessful.",
      "source_location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": null,
      "extraction_confidence": "high",
      "extraction_notes": "Outcome assessment of 2010 approach"
    },
    {
      "evidence_id": "E019",
      "evidence_type": "qualitative_observation",
      "observation_text": "2017: faced short field season and little time for student training",
      "verbatim_quote": "In 2017, faced with a short field season and little time for student training, we focused on implementing tools that would empower volunteers to digitise maps independently.",
      "source_location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "start_paragraph": 4,
        "end_paragraph": 4
      },
      "declared_uncertainty": null,
      "measurement_precision": null,
      "extraction_confidence": "high",
      "extraction_notes": "Context for 2017 approach"
    },
    {
      "evidence_id": "E020",
      "evidence_type": "qualitative_observation",
      "observation_text": "Approach stripped GIS functionality to essentials: layer selection, shape digitisation, annotation with validation and automation",
      "verbatim_quote": "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validation and automation to improve data quality.",
      "source_location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "start_paragraph": 4,
        "end_paragraph": 4
      },
      "declared_uncertainty": null,
      "measurement_precision": null,
      "extraction_confidence": "high",
      "extraction_notes": "Design principle description"
    },
    {
      "evidence_id": "E021",
      "evidence_type": "qualitative_observation",
      "observation_text": "Simple and intuitive UI allowed students to begin digitizing after only minutes of training",
      "verbatim_quote": "Geospatial data preparation and management was relegated to staff, while a simple and intuitive UI allowed students to begin digitising after only minutes of training.",
      "source_location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "page": 4,
        "start_paragraph": 4,
        "end_paragraph": 4
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximate_time",
        "uncertainty_language": "minutes"
      },
      "measurement_precision": {
        "value_type": "order_of_magnitude",
        "precision_level": "low"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Training time observation"
    },
    {
      "evidence_id": "E022",
      "evidence_type": "quantitative_measurement",
      "observation_text": "FAIMS Mobile customization: 2017: 35h programmer + 4h staff; 2018: 1h programmer for validation",
      "verbatim_quote": "For the first season of use (2017), creating the Map Digitisation customisation of FAIMS Mobile required 35 h from an undergraduate student programmer plus 4 h from staff. For the second season, adding additional validation to ensure population of latitude and longitude from GPS (see 'Recoverable data omissions and incomplete records' below) took 1 h of development from the programmer.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Consolidated customization time across both seasons",
      "consolidation_metadata": {
        "consolidated_from": [
          "E022",
          "E027"
        ],
        "consolidation_type": "identical_support_pattern",
        "consolidation_rationale": "Both support only C022, represent customization effort across seasons - consolidated for completeness",
        "consolidation_timestamp": "2025-10-25T23:13:29.412505"
      }
    },
    {
      "evidence_id": "E023",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Server and device setup required 3 hours from staff in 2017",
      "verbatim_quote": "Setup of the server and configuration of the client devices in the field required 3 h from staff.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Setup time - infrastructure"
    },
    {
      "evidence_id": "E024",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Map preparation required about 1.5 hours in 2017",
      "verbatim_quote": "Map preparation (tiling, adding pyramids) required about 1.5 h.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "about"
      },
      "measurement_precision": {
        "value_type": "approximate",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Setup time - data preparation"
    },
    {
      "evidence_id": "E025",
      "evidence_type": "quantitative_measurement",
      "observation_text": "File compression, upload, download took additional 2.5 hours in 2017",
      "verbatim_quote": "Monitoring file compression, upload to the server, and download to devices took an additional 2.5 h.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Setup time - data transfer"
    },
    {
      "evidence_id": "E026",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Training and supervision took no more than half hour of staff time across entire 2017 season",
      "verbatim_quote": "Training and supervision of students took no more than half an hour of staff time across the entire season.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "upper_bound",
        "uncertainty_language": "no more than"
      },
      "measurement_precision": {
        "value_type": "upper_bound",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Support time - minimal supervision"
    },
    {
      "evidence_id": "E028",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2018: In-field setup required 1 hour",
      "verbatim_quote": "In-field set-up required an hour (reusing the same equipment and system as the previous year)",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "2018 setup time"
    },
    {
      "evidence_id": "E029",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2018: Map preparation 30 minutes, file preparation and transfer 1.5 hours, training and supervision 30 minutes",
      "verbatim_quote": "map preparation 30 min, file preparation and transfer 1.5 h, and student training and supervision another 30 min.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "2018 operational time breakdown"
    },
    {
      "evidence_id": "E030",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Across both seasons: customization, setup, supervision took about 51 hours (36h programmer, 15h staff)",
      "verbatim_quote": "Across both seasons, customisation, setup, and supervision took about 51 h, including 36 h from the programmer and 15 from project staff.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "about"
      },
      "measurement_precision": {
        "value_type": "approximate",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Total setup time aggregated"
    },
    {
      "evidence_id": "E031",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Initial customization and setup before fieldwork: 44 hours",
      "verbatim_quote": "Of this time, initial customisation and setup time before fieldwork was 44 h",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Pre-fieldwork time"
    },
    {
      "evidence_id": "E032",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Time during fieldwork to prepare/distribute maps and supervise: 7 hours",
      "verbatim_quote": "while the time required during fieldwork to prepare and distribute maps, and then supervise participants, was 7 h.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "In-field operational time"
    },
    {
      "evidence_id": "E033",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Post-fieldwork quality checking of 4 maps required 6 hours staff time",
      "verbatim_quote": "Finally, reexamination of four randomly selected maps after fieldwork required 6 h of staff time, including desktop GIS setup, confirmation of feature digitisation, and tabulating errors and error rates.",
      "source_location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "page": 7,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Quality assurance time"
    },
    {
      "evidence_id": "E034",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2017: 125.8 person-hours over 5 rainy days, 8,343 features digitized from 42 maps (ca. 17,000 sq km)",
      "verbatim_quote": "In 2017, it was used for a total of 125.8 person-hours concentrated across five rainy days, during which time 8,343 features were digitised from 42 Soviet topographic maps (ca. 17,000 sq km).",
      "source_location": {
        "section": "3.2. Student-volunteer digitisation velocity and volume",
        "page": 7,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "ca."
      },
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "2017 digitization output"
    },
    {
      "evidence_id": "E035",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2017: Average time to record point feature was 54 seconds",
      "verbatim_quote": "The average time to record a point feature was 54 s, based on start and end times of feature creation as recorded by the devices (representing work time excluding pauses between records).",
      "source_location": {
        "section": "3.2. Student-volunteer digitisation velocity and volume",
        "page": 7,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "2017 digitization rate"
    },
    {
      "evidence_id": "E036",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2018: 63.6 person-hours, 2,484 features from 16 maps (ca. 6,500 sq km), average 92 seconds per record",
      "verbatim_quote": "In 2018, use was more sporadic; participants who stayed at the base for any reason sometimes undertook digitisation. The system was used for 63.6 person-hours, with 2,484 features recorded from 16 maps (ca. 6,500 sq km), an average rate of one record every 92 s.",
      "source_location": {
        "section": "3.2. Student-volunteer digitisation velocity and volume",
        "page": 7,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "ca."
      },
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "2018 digitization output"
    },
    {
      "evidence_id": "E037",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Total: 189.4 student-hours, 63 seconds per record average",
      "verbatim_quote": "In total, 10,827 point features, mostly burial and settlement mounds, were recorded in 189.4 student-hours (63 s per record).",
      "source_location": {
        "section": "3.2. Student-volunteer digitisation velocity and volume",
        "page": 7,
        "start_paragraph": 4,
        "end_paragraph": 4
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Aggregated digitization rate"
    },
    {
      "evidence_id": "E038",
      "evidence_type": "quantitative_measurement",
      "observation_text": "58 map tiles representing about 23,500 sq km were digitized",
      "verbatim_quote": "Fifty-eight map tiles representing about 23,500 sq km were digitised.",
      "source_location": {
        "section": "3.2. Student-volunteer digitisation velocity and volume",
        "page": 7,
        "start_paragraph": 4,
        "end_paragraph": 4
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "about"
      },
      "measurement_precision": {
        "value_type": "approximate",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Total spatial coverage"
    },
    {
      "evidence_id": "E039",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Single point record could be associated with 11 attribute-value pairs, dataset contained up to 119,097 discrete values",
      "verbatim_quote": "Since a single point record could be associated with 11 attribute-value pairs, the dataset contained as many as 119,097 discrete values (many captured automatically).",
      "source_location": {
        "section": "3.2. Student-volunteer digitisation velocity and volume",
        "page": 7,
        "start_paragraph": 4,
        "end_paragraph": 4
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "upper_bound",
        "uncertainty_language": "as many as"
      },
      "measurement_precision": {
        "value_type": "calculated_maximum",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Data complexity metric"
    },
    {
      "evidence_id": "E040",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2010 desktop GIS effort: 915 features, 5-7 hours staff training/support/error-checking over 3 weeks",
      "verbatim_quote": "Although we did not maintain detailed volunteer time-on-task records, we know this effort produced a dataset of 915 features and required about 5\u20137 h of staff training, support, and error-checking over a three-week period (based on our field journals).",
      "source_location": {
        "section": "3.3. Digitisation comparison with desktop GIS",
        "page": 7,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "range",
        "uncertainty_language": "about 5-7 h"
      },
      "measurement_precision": {
        "value_type": "range",
        "precision_level": "low"
      },
      "extraction_confidence": "medium",
      "extraction_notes": "Historical comparison baseline"
    },
    {
      "evidence_id": "E041",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Performance degradation: GPS extraction took 3-5s with empty database, up to 30s with 2,500+ records; degradation expected after 3,000-6,000 records",
      "verbatim_quote": "Automated testing of other customisations suggested that performance would degrade once approximately 3,000\u20136,000 records had been created. In use, automated extraction of coordinates from GPS into the Latitude/Longitude and Northing/Easting fields, which took three to 5 s with an empty database, took as long as 30 s once a device exceeded about 2,500 records.",
      "source_location": {
        "section": "3.4. Application performance",
        "page": 7,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "range",
        "uncertainty_language": "approximately, three to 5 s, as long as 30 s, about 2,500"
      },
      "measurement_precision": {
        "value_type": "range",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Consolidated prediction and observed performance degradation",
      "consolidation_metadata": {
        "consolidated_from": [
          "E041",
          "E042"
        ],
        "consolidation_type": "identical_support_pattern",
        "consolidation_rationale": "Both support only C010, describe related aspects of performance degradation - consolidated as compound finding",
        "consolidation_timestamp": "2025-10-25T23:13:29.412501"
      }
    },
    {
      "evidence_id": "E043",
      "evidence_type": "quantitative_measurement",
      "observation_text": "223 total recoverable data omissions (2.06% of records): 205 spatial, 18 attribute",
      "verbatim_quote": "Recoverable data omissions across both years totaled 223 (2.06% of records), including 205 spatial and 18 attribute omissions.",
      "source_location": {
        "section": "3.5.1. Recoverable data omissions and incomplete records",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Consolidated total and breakdown of omissions",
      "consolidation_metadata": {
        "consolidated_from": [
          "E043",
          "E044"
        ],
        "consolidation_type": "breakdown_synthesis",
        "consolidation_rationale": "Two items from same quote - total and type breakdown consolidated to reduce redundancy",
        "consolidation_timestamp": "2025-10-25T23:13:29.412499"
      }
    },
    {
      "evidence_id": "E045",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2017: 192 records (2.3%) had empty latitude/longitude, 17 (0.2%) missing map symbol",
      "verbatim_quote": "Most occurred in 2017 when 192 records (2.3%) had empty latitude and longitude fields and 17 (0.2%) were missing specification of the map symbol.",
      "source_location": {
        "section": "3.5.1. Recoverable data omissions and incomplete records",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "2017 error breakdown"
    },
    {
      "evidence_id": "E046",
      "evidence_type": "quantitative_measurement",
      "observation_text": "2018: 13 spatial errors and 1 attribute omission (0.52%)",
      "verbatim_quote": "Before the 2018 season, we added validation addressing this problem, resulting in only 13 spatial errors and one attribute omission (0.52%).",
      "source_location": {
        "section": "3.5.1. Recoverable data omissions and incomplete records",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "2018 error improvement after validation added"
    },
    {
      "evidence_id": "E047",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Only 2 data points could not be recovered from geodatabase",
      "verbatim_quote": "Since the geodatabase preserved geometries, spatial omissions were corrected by re-extracting latitude and longitude; only two data points could not be recovered.",
      "source_location": {
        "section": "3.5.1. Recoverable data omissions and incomplete records",
        "page": 7,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Irrecoverable data quantified"
    },
    {
      "evidence_id": "E048",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Review of 4 randomly selected maps (7% of total)",
      "verbatim_quote": "a review by project staff of four randomly selected maps (7% of the total)",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 7,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Quality assurance sample size"
    },
    {
      "evidence_id": "E049",
      "evidence_type": "quantitative_measurement",
      "observation_text": "49 errors from true count of 834 features, 5.87% error rate",
      "verbatim_quote": "found 49 errors from a true count of 834 features, a 5.87% error rate",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "calculated_percentage",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Overall error rate from QA"
    },
    {
      "evidence_id": "E050",
      "evidence_type": "quantitative_measurement",
      "observation_text": "42 false negatives (symbols missed by students)",
      "verbatim_quote": "Forty-two of these errors were false negatives (symbols missed by students).",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Error type breakdown - omissions"
    },
    {
      "evidence_id": "E051",
      "evidence_type": "quantitative_measurement",
      "observation_text": "6 double-marked features; 35 of 49 false negatives from Student C failing to digitise three contiguous map sections",
      "verbatim_quote": "Six were double-marked (Student C digitised a section of a map twice). Moreover, 35 of the 49 false negatives were the result of Student C failing to digitise three contiguous sections of an assigned map.",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Consolidated error pattern attribution",
      "consolidation_metadata": {
        "consolidated_from": [
          "E051",
          "E057"
        ],
        "consolidation_type": "identical_support_pattern",
        "consolidation_rationale": "Both support only C013, describe related error patterns from same student - consolidated for coherence",
        "consolidation_timestamp": "2025-10-25T23:13:29.412502"
      }
    },
    {
      "evidence_id": "E052",
      "evidence_type": "quantitative_measurement",
      "observation_text": "1 classification error (similar symbol mistaken for benchmark)",
      "verbatim_quote": "Students made only one classification error (a similar symbol mistaken for a benchmark)",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Error type breakdown - classification"
    },
    {
      "evidence_id": "E053",
      "evidence_type": "quantitative_measurement",
      "observation_text": "0 outright false positives",
      "verbatim_quote": "and no outright false positives",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_count",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Error type breakdown - no false positives"
    },
    {
      "evidence_id": "E054",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Individual error rates ranged from 1.3% to 10.6%",
      "verbatim_quote": "Students' individual error rates ranged from 1.3% to 10.6%.",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "range",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Individual variability in error rates"
    },
    {
      "evidence_id": "E055",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Two fastest digitisers (Students A & B: 44 and 45 s/feature) had lowest error rates (1.3% and 2.9%)",
      "verbatim_quote": "Note that the two fastest digitisers (Students A and B; 44 and 45 s per feature respectively) also had the lowest error rates (1.3 and 2.9%)",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Speed-accuracy correlation - positive"
    },
    {
      "evidence_id": "E056",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Two slowest digitisers (Students C & D: 61 and 73 s/feature) had highest error rates (10.6% and 7.4%)",
      "verbatim_quote": "while the two slowest (Students C and D; 61 and 73 s) had the highest error rates (10.6 and 7.4%).",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Speed-accuracy correlation - inverse for slow workers"
    },
    {
      "evidence_id": "E058",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Excluding Student C would cut cumulative error rate to 2.8%",
      "verbatim_quote": "These mistakes made his error rate of 10.6% an outlier; excluding Student C would have cut the cumulative error rate in half to 2.8%.",
      "source_location": {
        "section": "3.5.2. Digitisation errors",
        "page": 9,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "calculated_percentage",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Adjusted error rate without outlier"
    },
    {
      "evidence_id": "E059",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Expert staff digitization rate: 60-75 features per staff-hour",
      "verbatim_quote": "After brief workspace setup, project staff with desktop GIS experience could digitise at a sustained rate of 60\u201375 features per staff-hour.",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "range",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Baseline expert performance"
    },
    {
      "evidence_id": "E060",
      "evidence_type": "quantitative_measurement",
      "observation_text": "57 hours staff time could produce 3,420-4,275 staff-digitised features",
      "verbatim_quote": "At this rate, the 57 h of staff time devoted to set-up, support, and quality assurance for our crowdsourcing system could have resulted in some 3,420\u20134,275 staff-digitised features",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "range",
        "uncertainty_language": "some 3,420-4,275"
      },
      "measurement_precision": {
        "value_type": "calculated_range",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Payoff threshold calculation"
    },
    {
      "evidence_id": "E061",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Volunteers with desktop GIS: 130-180 features per staff-hour",
      "verbatim_quote": "based on our 2010 digitisation rate of 130\u2013180 features per staff-hour",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "range",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Volunteer+desktop GIS performance"
    },
    {
      "evidence_id": "E062",
      "evidence_type": "quantitative_measurement",
      "observation_text": "57 hours might have produced 7,410-10,260 features with desktop GIS volunteers",
      "verbatim_quote": "57 h might have produced 7,410\u201310,260 features.",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "calculated_range",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Desktop GIS volunteer payoff threshold"
    },
    {
      "evidence_id": "E063",
      "evidence_type": "quantitative_measurement",
      "observation_text": "FAIMS Mobile approach: 190 features per staff-hour (using 57h total staff time, 10,827 features)",
      "verbatim_quote": "the 57 h of staff time required for our digitisation approach using a customisation of FAIMS Mobile produced 10,827 features, or about 190 features per staff-hour.",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 9,
        "start_paragraph": 4,
        "end_paragraph": 4
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "about"
      },
      "measurement_precision": {
        "value_type": "calculated_rate",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "FAIMS Mobile performance metric"
    },
    {
      "evidence_id": "E064",
      "evidence_type": "quantitative_measurement",
      "observation_text": "21 internal staff hours (excluding programmer) = 500+ features per staff-hour",
      "verbatim_quote": "Only 21 of the 57 h needed to support the system came from project staff, while the other 36 h were completed by a student programmer for a modest cost (ca. AUD $2,000). Those 21 internal staff hours represent a digitisation rate of over 500 features per staff-hour.",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "lower_bound",
        "uncertainty_language": "over 500"
      },
      "measurement_precision": {
        "value_type": "calculated_rate",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Internal staff performance metric"
    },
    {
      "evidence_id": "E065",
      "evidence_type": "quantitative_measurement",
      "observation_text": "7 hours in-field support = 1,550 features per in-field staff-hour",
      "verbatim_quote": "Across two seasons, in-field support for volunteers was only 7 h, representing about 1,550 features per in-field staff-hour.",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "about"
      },
      "measurement_precision": {
        "value_type": "calculated_rate",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "In-field efficiency metric"
    },
    {
      "evidence_id": "E066",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Marginal cost: 4.3 seconds staff support per additional feature",
      "verbatim_quote": "This figure includes in-field support and quality assurance (13 h), and translates to 4.3 s of staff support per additional feature.",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "calculated_rate",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Scalability metric"
    },
    {
      "evidence_id": "E067",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Map preparation and distribution: 6 minutes per map (6h for 58 maps)",
      "verbatim_quote": "Preparing and distributing additional maps took only 6 min per map (6 h for 58 maps).",
      "source_location": {
        "section": "4.1.1. Desktop GIS approaches versus crowdsourcing",
        "page": 10,
        "start_paragraph": 3,
        "end_paragraph": 3
      },
      "declared_uncertainty": null,
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "Data preparation efficiency"
    },
    {
      "evidence_id": "E068",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Urban Occupations Project: 1,250 hours manual digitization for training data, 7 days ML tuning, ~300,000 km roads digitized",
      "verbatim_quote": "This project reported 1,250 h of manual digitisation to create enough training data to classify roads visible in historical maps of the Ottoman Empire. Using this input, and after additional preprocessing and filtering, an ML expert spent seven days testing and fine tuning the model. The output was impressive: some 300,000 km of roads were digitised.",
      "source_location": {
        "section": "4.1.2. Machine learning versus crowdsourcing",
        "page": 10,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "some 300,000"
      },
      "measurement_precision": {
        "value_type": "exact_measurement",
        "precision_level": "high"
      },
      "extraction_confidence": "high",
      "extraction_notes": "ML approach benchmark"
    },
    {
      "evidence_id": "E069",
      "evidence_type": "quantitative_measurement",
      "observation_text": "ML approach minimum threshold ~1,300 hours preparation time",
      "verbatim_quote": "This example, which appears to have required a minimum of about 1,300 h of preparation time alone",
      "source_location": {
        "section": "4.1.2. Machine learning versus crowdsourcing",
        "page": 10,
        "start_paragraph": 1,
        "end_paragraph": 1
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "about, minimum of"
      },
      "measurement_precision": {
        "value_type": "approximate",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "ML setup cost threshold"
    },
    {
      "evidence_id": "E070",
      "evidence_type": "quantitative_measurement",
      "observation_text": "Calculation: 1,300h at 44.9 features/person-hour = 58,400 records",
      "verbatim_quote": "At that rate, the 1,300 h it took to deploy the ML approach taken by Can, Gerrits, and Kabadayi would yield about 58,400 records",
      "source_location": {
        "section": "4.1.2. Machine learning versus crowdsourcing",
        "page": 10,
        "start_paragraph": 2,
        "end_paragraph": 2
      },
      "declared_uncertainty": {
        "explicitly_stated": true,
        "uncertainty_type": "approximation",
        "uncertainty_language": "about"
      },
      "measurement_precision": {
        "value_type": "calculated",
        "precision_level": "medium"
      },
      "extraction_confidence": "high",
      "extraction_notes": "ML payoff threshold calculation"
    }
  ],
  "claims": [
    {
      "claim_id": "C001",
      "claim_type": "methodological_effectiveness",
      "claim_role": "core",
      "claim_text": "Crowdsourcing approach using FAIMS Mobile is most efficient for digitization projects of 10,000-60,000 features",
      "verbatim_quote": "A conservative estimate based on our work suggests our crowdsourcing approach is most efficient for digitisation projects of 10,000\u201360,000 features, but may offer advantages for datasets as small as a few hundred records.",
      "source_location": {
        "section": "Abstract",
        "page": 1
      },
      "supported_by_evidence": [
        "E001",
        "E002",
        "E003",
        "E004",
        "E005"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C002",
      "claim_type": "methodological_effectiveness",
      "claim_role": "core",
      "claim_text": "Systems designed for field data collection on mobile devices can be customized to serve as participatory geospatial data systems accessible to novice volunteers",
      "verbatim_quote": "Furthermore, it indicates that systems designed for field data collection, running on mobile devices, can be profitably customised to serve as participatory geospatial data systems accessible to novice volunteers.",
      "source_location": {
        "section": "Abstract",
        "page": 1
      },
      "supported_by_evidence": [
        "E001",
        "E002",
        "E021"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C003",
      "claim_type": "methodological_effectiveness",
      "claim_role": "supporting",
      "claim_text": "Concentrated digitization in 2017 was more productive than intermittent work of 2018",
      "verbatim_quote": "The concentrated digitisation in 2017 was more productive than the intermittent work of 2018, but both seasons yielded large and valuable datasets utilising time that might otherwise have been lost",
      "source_location": {
        "section": "3.2",
        "page": 7
      },
      "supported_by_evidence": [
        "E034",
        "E035",
        "E036"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C004",
      "claim_type": "comparison",
      "claim_role": "intermediate",
      "claim_text": "Customized mobile application met fundamental usability requirements better than desktop GIS",
      "verbatim_quote": "By contrast, our customised application met fundamental usability requirements (e.g., Nielsen, 2012), both due to careful design of the customisation itself, and the underlying platform's implementation of Google's Material Design guidelines.",
      "source_location": {
        "section": "3.3",
        "page": 7
      },
      "supported_by_evidence": [
        "E017",
        "E018",
        "E021"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C005",
      "claim_type": "methodological_effectiveness",
      "claim_role": "supporting",
      "claim_text": "Result was simple, familiar mobile application interface that let novices begin work with little training",
      "verbatim_quote": "The result was a simple, familiar mobile application interface that let novices begin work with little training and helped them resume work after any hiatus.",
      "source_location": {
        "section": "3.3",
        "page": 7
      },
      "supported_by_evidence": [
        "E021",
        "E026"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C006",
      "claim_type": "methodological_effectiveness",
      "claim_role": "supporting",
      "claim_text": "Use of controlled vocabularies, automation, and validation reduced errors",
      "verbatim_quote": "Use of controlled vocabularies, automation, and validation reduced errors.",
      "source_location": {
        "section": "3.3",
        "page": 7
      },
      "supported_by_evidence": [
        "E020"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C007",
      "claim_type": "interpretation",
      "claim_role": "supporting",
      "claim_text": "Low volunteer attrition indicated satisfaction with the experience",
      "verbatim_quote": "Low volunteer attrition indicated satisfaction with the experience.",
      "source_location": {
        "section": "3.3",
        "page": 7
      },
      "supported_by_evidence": [],
      "extraction_confidence": "medium",
      "extraction_notes": "Interpretive claim without direct attrition rate evidence"
    },
    {
      "claim_id": "C008",
      "claim_type": "comparison",
      "claim_role": "supporting",
      "claim_text": "Volunteers could attain high rate of digitization quickly and maintain it",
      "verbatim_quote": "Volunteers could attain a high rate of digitisation quickly and maintain it",
      "source_location": {
        "section": "3.3",
        "page": 7
      },
      "supported_by_evidence": [
        "E035",
        "E036",
        "E037"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C009",
      "claim_type": "methodological_effectiveness",
      "claim_role": "supporting",
      "claim_text": "Both seasons required little supervision by project staff",
      "verbatim_quote": "both seasons yielded large and valuable datasets utilising time that might otherwise have been lost (e. g., to inclement weather), while requiring little supervision by project staff.",
      "source_location": {
        "section": "3.2",
        "page": 7
      },
      "supported_by_evidence": [
        "E026",
        "E029"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C010",
      "claim_type": "data_quality",
      "claim_role": "supporting",
      "claim_text": "Deteriorating performance was mitigated by exporting data and instantiating new empty version",
      "verbatim_quote": "Deteriorating performance was mitigated by exporting all data and instantiating a new and empty version of the application.",
      "source_location": {
        "section": "3.4",
        "page": 7
      },
      "supported_by_evidence": [
        "E041",
        "E042"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C011",
      "claim_type": "data_quality",
      "claim_role": "supporting",
      "claim_text": "Overall digitization accuracy was high, over 94% for processed maps",
      "verbatim_quote": "Unlike some volunteer digitisation projects, overall accuracy was high, over 94% for processed maps.",
      "source_location": {
        "section": "3.5.2",
        "page": 7
      },
      "supported_by_evidence": [
        "E049",
        "E058"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C012",
      "claim_type": "data_quality",
      "claim_role": "supporting",
      "claim_text": "Overall error rate of 5.9% exceeded expectations",
      "verbatim_quote": "Nevertheless, the overall rate of 5.9% exceeded our expectations.",
      "source_location": {
        "section": "3.5.2",
        "page": 9
      },
      "supported_by_evidence": [
        "E049"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C013",
      "claim_type": "data_quality",
      "claim_role": "supporting",
      "claim_text": "Pattern of errors (mostly false negatives and double-marking from contiguous sections) made them relatively easy to identify and correct",
      "verbatim_quote": "Moreover, the pattern of errors - mostly false negatives and doublemarked features, mostly from contiguous map sections - made them relatively easy to identify and correct.",
      "source_location": {
        "section": "3.5.2",
        "page": 9
      },
      "supported_by_evidence": [
        "E050",
        "E051",
        "E057"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C014",
      "claim_type": "methodological_effectiveness",
      "claim_role": "supporting",
      "claim_text": "Simple expedients (multiple students per map or peer review) would likely eliminate most errors",
      "verbatim_quote": "Simple expedients, such as assigning multiple students to digitise the same map tiles independently or assigning one student to review work by another, would likely eliminate most errors.",
      "source_location": {
        "section": "3.5.2",
        "page": 9
      },
      "supported_by_evidence": [
        "E049",
        "E050"
      ],
      "extraction_confidence": "medium",
      "extraction_notes": "Hypothetical/proposed mitigation strategy"
    },
    {
      "claim_id": "C015",
      "claim_type": "methodological_effectiveness",
      "claim_role": "core",
      "claim_text": "Crowdsourcing proved unexpectedly successful as auxiliary activity producing large, high-quality dataset with reasonable demands on staff and volunteers",
      "verbatim_quote": "Our crowdsourced digitisation effort involving novice volunteers using an adapted mobile application for data capture proved unexpectedly successful. It was only an auxiliary activity undertaken on a time-available basis, intentionally secondary to pedestrian survey... yet produced a large (>10,000 features), high-quality (<6% error rate) dataset while placing reasonable demands on both volunteers and staff compared to other approaches.",
      "source_location": {
        "section": "4. Discussion",
        "page": 9
      },
      "supported_by_evidence": [
        "E001",
        "E002",
        "E005",
        "E049"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C016",
      "claim_type": "comparison",
      "claim_role": "intermediate",
      "claim_text": "Crowdsourcing approach becomes worthwhile for datasets no larger than 4,500 features vs direct staff digitization",
      "verbatim_quote": "Under the most conservative scenario that considers all invested time, the use of our system pays off between about 3,500\u20134,500 features versus direct digitisation by staff using desktop GIS",
      "source_location": {
        "section": "4.1.1",
        "page": 9
      },
      "supported_by_evidence": [
        "E060",
        "E063"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C017",
      "claim_type": "comparison",
      "claim_role": "intermediate",
      "claim_text": "Crowdsourcing pays off at 7,500-10,000 features vs desktop GIS volunteers",
      "verbatim_quote": "and about 7,500\u201310,000 features versus support for volunteers using desktop GIS.",
      "source_location": {
        "section": "4.1.1",
        "page": 9
      },
      "supported_by_evidence": [
        "E062",
        "E063"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C018",
      "claim_type": "comparison",
      "claim_role": "intermediate",
      "claim_text": "Projects where staff time is at premium may find crowdsourcing valuable for datasets below 1,000 records",
      "verbatim_quote": "Projects where staff time is at a premium, or that operate alongside fieldwork where staff have many competing demands, may find it valuable for smaller datasets (even those below 1,000 records).",
      "source_location": {
        "section": "4.1.2",
        "page": 10
      },
      "supported_by_evidence": [
        "E065"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C019",
      "claim_type": "comparison",
      "claim_role": "core",
      "claim_text": "Crowdsourcing most suitable for 10,000-60,000 records; below 10,000 consider desktop GIS; above 60,000 contemplate ML",
      "verbatim_quote": "To summarise in round numbers, a crowdsourcing approach like ours is most suitable for datasets numbering perhaps 10,000\u201360,000 records, assuming similar feature characteristics and data collection requirements... Below 10,000 records, approaches using desktop GIS should be considered... Above 60,000 records, ML approaches should be contemplated",
      "source_location": {
        "section": "4.1.2",
        "page": 10
      },
      "supported_by_evidence": [
        "E060",
        "E062",
        "E063",
        "E068",
        "E070"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C020",
      "claim_type": "methodological_effectiveness",
      "claim_role": "supporting",
      "claim_text": "ML and crowdsourcing approaches are complementary, not exclusive",
      "verbatim_quote": "A dataset big enough to justify ML will likely need a training dataset big enough to warrant crowdsourcing, especially if the features or background are variable. Once the crowdsourcing platform has been built, moreover, it can be used to produce additional datasets for errorchecking to confirm the accuracy of the ML results. The approaches are not exclusive, therefore, but complementary.",
      "source_location": {
        "section": "4.2",
        "page": 10
      },
      "supported_by_evidence": [
        "E068"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C021",
      "claim_type": "methodological_feasibility",
      "claim_role": "intermediate",
      "claim_text": "Typical small, under-resourced HASS project can deploy collaborative geospatial system but may not incorporate ML successfully",
      "verbatim_quote": "Today, a typical project in history or archaeology - often small, under-resourced, and pursuing several research activities - may not be able to dedicate the personnel, infrastructure, or attention needed to incorporate ML successfully, but could deploy a collaborative geospatial system for crowdsourcing map digitisation.",
      "source_location": {
        "section": "4.3",
        "page": 10
      },
      "supported_by_evidence": [
        "E030",
        "E068"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C022",
      "claim_type": "methodological_feasibility",
      "claim_role": "supporting",
      "claim_text": "Project with digital humanist at Software Carpentry skill level can customize and operate platform for effective crowdsourcing",
      "verbatim_quote": "A project with a digital humanist or similar technologist with skills at the level of core Software Carpentry lessons (TheCarpentries, 2023) can customise and operate a generalised platform such as FAIMS Mobile to implement an effective crowdsourcing system.",
      "source_location": {
        "section": "4.3",
        "page": 10
      },
      "supported_by_evidence": [
        "E022",
        "E027"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C023",
      "claim_type": "methodological_transferability",
      "claim_role": "core",
      "claim_text": "Approach is readily transferable to other mobile GIS systems and map corpora",
      "verbatim_quote": "This approach is readily transferable to other mobile GIS systems and map corpora",
      "source_location": {
        "section": "5. Conclusion",
        "page": 11
      },
      "supported_by_evidence": [],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C024",
      "claim_type": "data_quality",
      "claim_role": "intermediate",
      "claim_text": "Dataset was FAIR-compliant and ready for analysis with less than 2 hours processing after collection",
      "verbatim_quote": "All collected data was available daily for review, and a comprehensive, FAIR-compliant dataset was ready for analysis with less than 2 h of processing after collection.",
      "source_location": {
        "section": "5. Conclusion",
        "page": 11
      },
      "supported_by_evidence": [
        "E006"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C025",
      "claim_type": "data_quality",
      "claim_role": "supporting",
      "claim_text": "Errors were predictable and would be easily mitigated by redundant digitization or peer review",
      "verbatim_quote": "An accuracy check by staff covering 7% of digitised features indicated an error rate of under 6%; errors were predictable and would be easily mitigated by redundant digitisation by volunteers or volunteer peer review.",
      "source_location": {
        "section": "5. Conclusion",
        "page": 11
      },
      "supported_by_evidence": [
        "E048",
        "E049"
      ],
      "extraction_confidence": "high"
    },
    {
      "claim_id": "C026",
      "claim_type": "methodological_effectiveness",
      "claim_role": "supporting",
      "claim_text": "Approach can be used to produce training datasets for ML and as quality assurance tool for ML outputs",
      "verbatim_quote": "Our approach can also be used to produce the training datasets needed for ML, and as a tool for quality assurance for ML outputs.",
      "source_location": {
        "section": "5. Conclusion",
        "page": 11
      },
      "supported_by_evidence": [
        "E068"
      ],
      "extraction_confidence": "high"
    }
  ],
  "implicit_arguments": [],
  "research_designs": [
    {
      "design_id": "RD001",
      "design_type": "research_framing",
      "design_status": "explicit",
      "design_text": "Assess whether mobile crowdsourcing with novice volunteers can produce high-quality geospatial data from historical maps",
      "verbatim_quote": "Here we present a customisation of the Field Acquired Information Management Systems (FAIMS) Mobile platform tailored to offer a streamlined, collaborative system for crowdsourcing map digitisation by volunteers with no prior GIS experience.",
      "location": {
        "section": "Abstract",
        "subsection": null,
        "paragraph": 1
      },
      "enables_methods": [
        "M001",
        "M002"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Core research aim framing entire study"
    },
    {
      "design_id": "RD002",
      "design_type": "study_design",
      "design_status": "explicit",
      "design_text": "Case study design of crowdsourced map digitization in archaeological fieldwork context",
      "verbatim_quote": "This article presents a case study of crowdsourced cultural heritage digitisation from historical maps undertaken by volunteers using a lightweight, streamlined Geographical Information System (GIS) running offline on mobile devices.",
      "location": {
        "section": "1. Introduction",
        "subsection": null,
        "paragraph": 1
      },
      "enables_methods": [
        "M001"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Strategic choice of case study approach"
    },
    {
      "design_id": "RD003",
      "design_type": "study_design",
      "design_status": "explicit",
      "design_text": "Comparative evaluation design to assess digitization approach efficiency relative to desktop GIS and ML alternatives",
      "verbatim_quote": "Digitisation projects will likely choose between one of four principal approaches to digitising historical maps.",
      "location": {
        "section": "4.1. Choosing an approach",
        "subsection": null,
        "paragraph": 1
      },
      "enables_methods": [
        "M003",
        "M004"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Meta-level comparative framework for evaluation"
    },
    {
      "design_id": "RD004",
      "design_type": "research_framing",
      "design_status": "explicit",
      "design_text": "Efficiency threshold hypothesis: crowdsourcing most efficient for 10,000-60,000 features",
      "verbatim_quote": "A conservative estimate based on our work suggests our crowdsourcing approach is most efficient for digitisation projects of 10,000\u201360,000 features, but may offer advantages for datasets as small as a few hundred records.",
      "location": {
        "section": "Abstract",
        "subsection": null,
        "paragraph": 1
      },
      "supports_claims": [
        "C001",
        "C019"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Empirical hypothesis about approach viability"
    },
    {
      "design_id": "RD005",
      "design_type": "study_design",
      "design_status": "explicit",
      "design_text": "Selection of mobile GIS platform for usability, offline capability, and novice accessibility",
      "verbatim_quote": "Having decided to adopt a crowdsourced approach to produce VGI, we chose to customise FAIMS Mobile for map digitisation.",
      "location": {
        "section": "2.3. Using a mobile application for map digitisation",
        "subsection": null,
        "paragraph": 1
      },
      "enables_methods": [
        "M002"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Platform selection rationale documented"
    },
    {
      "design_id": "RD006",
      "design_type": "study_design",
      "design_status": "explicit",
      "design_text": "Use of field school students as novice volunteers to test approach generalizability beyond expert users",
      "verbatim_quote": "The task of digitising potentially thousands of mounds provided an opportunity to involve students in authentic research. Our students came from a range of academic backgrounds in Arts and Humanities. Most had no training in archaeology, cartography, or digital methods",
      "location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "subsection": null,
        "paragraph": 2
      },
      "enables_methods": [
        "M001"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Deliberate choice of novice volunteers as test population"
    }
  ],
  "methods": [
    {
      "method_id": "M001",
      "method_type": "data_collection",
      "method_status": "explicit",
      "method_text": "Crowdsourcing digitization using novice field school participants with minimal training",
      "verbatim_quote": "For the 2017\u20132018 field seasons, TRAP staff created a simplified and streamlined data capture system built using the FAIMS Mobile platform. This system allowed any number of participants to digitise map features using mobile devices, regardless of network connectivity",
      "location": {
        "section": "2. Approach",
        "subsection": null,
        "paragraph": 1
      },
      "realized_through": [
        "RD002",
        "RD006"
      ],
      "realized_through_protocols": [
        "P001",
        "P002",
        "P003"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Core data collection approach"
    },
    {
      "method_id": "M002",
      "method_type": "data_collection",
      "method_status": "explicit",
      "method_text": "Customized mobile GIS application (FAIMS Mobile) with simplified interface for novice users",
      "verbatim_quote": "As such, it stripped GIS functionality to its essentials, focusing on three tasks: layer selection, shape digitisation, and annotation, with validation and automation to improve data quality.",
      "location": {
        "section": "2.2. Crowdsourcing digitisation with field-school participants",
        "subsection": null,
        "paragraph": 4
      },
      "realized_through": [
        "RD005"
      ],
      "realized_through_protocols": [
        "P001",
        "P004"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Platform-based method with usability focus"
    },
    {
      "method_id": "M003",
      "method_type": "evaluation",
      "method_status": "explicit",
      "method_text": "Time-on-task measurement to evaluate efficiency and calculate payoff thresholds",
      "verbatim_quote": "To measure inputs, we collated the amount of time spent by various participants in the process, including the student programmer who instantiated the customisation, the student volunteers who undertook the digitisation, and project staff who configured the system, supported volunteers, exported data, and checked for errors.",
      "location": {
        "section": "2.5. Evaluating the digitisation approach",
        "subsection": null,
        "paragraph": 2
      },
      "realized_through": [
        "RD003"
      ],
      "realized_through_protocols": [
        "P005"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Evaluation methodology for efficiency assessment"
    },
    {
      "method_id": "M004",
      "method_type": "quality_control",
      "method_status": "explicit",
      "method_text": "Random sampling quality assurance review by project staff",
      "verbatim_quote": "Finally, project staff reviewed randomly selected digitisation work completed by volunteers to characterise errors.",
      "location": {
        "section": "2.5. Evaluating the digitisation approach",
        "subsection": null,
        "paragraph": 2
      },
      "realized_through": [
        "RD003"
      ],
      "realized_through_protocols": [
        "P006"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Quality control approach"
    },
    {
      "method_id": "M005",
      "method_type": "validation",
      "method_status": "explicit",
      "method_text": "On-device data validation and automated metadata creation",
      "verbatim_quote": "Data can be validated on devices at the time of capture, or on the server after synchronisation.",
      "location": {
        "section": "2.3. Using a mobile application for map digitisation",
        "subsection": null,
        "paragraph": 3
      },
      "realized_through_protocols": [
        "P004"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "In-app validation approach"
    },
    {
      "method_id": "M006",
      "method_type": "comparison",
      "method_status": "explicit",
      "method_text": "Comparative analysis with desktop GIS and machine learning approaches to determine payoff thresholds",
      "verbatim_quote": "Choosing amongst the approaches involves weighing both qualitative and quantitative considerations inherent to each.",
      "location": {
        "section": "4.1. Choosing an approach",
        "subsection": null,
        "paragraph": 2
      },
      "realized_through": [
        "RD003"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Comparison framework for threshold calculation"
    }
  ],
  "protocols": [
    {
      "protocol_id": "P001",
      "protocol_type": "system_configuration",
      "protocol_status": "explicit",
      "protocol_text": "FAIMS Mobile customization via definition files: 2017: 35h programmer + 4h staff; 2018: 1h validation enhancement",
      "verbatim_quote": "For the first season of use (2017), creating the Map Digitisation customisation of FAIMS Mobile required 35 h from an undergraduate student programmer plus 4 h from staff",
      "location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "subsection": null,
        "paragraph": 1
      },
      "implements_method": [
        "M002"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Detailed customization effort quantified"
    },
    {
      "protocol_id": "P002",
      "protocol_type": "data_preparation",
      "protocol_status": "explicit",
      "protocol_text": "Map preparation: tiling, adding pyramids to georeferenced GeoTIFFs; 2017: 1.5h; 2018: 0.5h",
      "verbatim_quote": "Map preparation (tiling, adding pyramids) required about 1.5 h.",
      "location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "subsection": null,
        "paragraph": 1
      },
      "implements_method": [
        "M001"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Data preparation protocol with time investment"
    },
    {
      "protocol_id": "P003",
      "protocol_type": "training",
      "protocol_status": "explicit",
      "protocol_text": "Participant training: minutes-level introduction allowing immediate digitization start; supervision <30min total per season",
      "verbatim_quote": "Training and supervision of students took no more than half an hour of staff time across the entire season.",
      "location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "subsection": null,
        "paragraph": 1
      },
      "implements_method": [
        "M001"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Minimal training protocol enabling rapid onboarding"
    },
    {
      "protocol_id": "P004",
      "protocol_type": "validation",
      "protocol_status": "explicit",
      "protocol_text": "Data validation rules including controlled vocabularies, automated coordinate extraction from GPS, record completeness checks; enhanced in 2018 to enforce lat/long population",
      "verbatim_quote": "For the second season, adding additional validation to ensure population of latitude and longitude from GPS (see 'Recoverable data omissions and incomplete records' below) took 1 h of development from the programmer.",
      "location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "subsection": null,
        "paragraph": 2
      },
      "implements_method": [
        "M002",
        "M005"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Validation protocol evolved to address observed gaps"
    },
    {
      "protocol_id": "P005",
      "protocol_type": "measurement",
      "protocol_status": "explicit",
      "protocol_text": "Time tracking protocol: programmer timesheets, automated record creation timestamps from devices, staff time-on-task journals",
      "verbatim_quote": "Project records provided much of this data (timesheets from the programmer; record creation timestamps for students using the system), while project staff logged time-on-task for activities in journals.",
      "location": {
        "section": "2.5. Evaluating the digitisation approach",
        "subsection": null,
        "paragraph": 2
      },
      "implements_method": [
        "M003"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Multi-source time measurement protocol"
    },
    {
      "protocol_id": "P006",
      "protocol_type": "quality_assurance",
      "protocol_status": "explicit",
      "protocol_text": "Quality assurance protocol: random selection of 4 maps (7% sample), desktop GIS verification of feature completeness, error tabulation by type (false positive, false negative, double-marking, classification)",
      "verbatim_quote": "Finally, reexamination of four randomly selected maps after fieldwork required 6 h of staff time, including desktop GIS setup, confirmation of feature digitisation, and tabulating errors and error rates.",
      "location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "subsection": null,
        "paragraph": 3
      },
      "implements_method": [
        "M004"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Systematic QA protocol with error classification"
    },
    {
      "protocol_id": "P007",
      "protocol_type": "recording_standard",
      "protocol_status": "explicit",
      "protocol_text": "Record structure: point geometry for feature location, record number, 10 attributes including symbol type and ground control metadata",
      "verbatim_quote": "The records we sought to create were relatively simple: a point for the feature, a record number, plus ten attributes.",
      "location": {
        "section": "2.1. Archaeological features in Soviet topographic maps",
        "subsection": null,
        "paragraph": 2
      },
      "implements_method": [
        "M001"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Data structure specification"
    },
    {
      "protocol_id": "P008",
      "protocol_type": "system_configuration",
      "protocol_status": "explicit",
      "protocol_text": "Server and device setup protocol: 2017: 3h field setup; 2018: 1h setup reusing same equipment",
      "verbatim_quote": "Setup of the server and configuration of the client devices in the field required 3 h from staff. In-field set-up required an hour (reusing the same equipment and system as the previous year)",
      "location": {
        "section": "3.1. Project staff time for setup, support, and accuracy-checking",
        "subsection": null,
        "paragraph": 1
      },
      "implements_method": [
        "M001",
        "M002"
      ],
      "extraction_confidence": "high",
      "extraction_notes": "Infrastructure deployment protocol with efficiency gain in year 2"
    }
  ],
  "project_metadata": {
    "timeline": {
      "project_start": "2008",
      "project_phases": [
        {
          "phase_name": "TRAP initial work",
          "start_date": "2008",
          "end_date": "2016",
          "activities": [
            "pedestrian survey",
            "mound cataloguing"
          ]
        },
        {
          "phase_name": "Map digitization deployment",
          "start_date": "2017",
          "end_date": "2018",
          "activities": [
            "crowdsourced map digitization",
            "field school integration"
          ]
        }
      ]
    },
    "location": {
      "primary_site": "Yambol region, Bulgaria",
      "geographic_context": "Tundzha River watershed, southeast Bulgaria",
      "spatial_extent": "over 20,000 sq km of Soviet military 1:50,000 topographic maps"
    },
    "resources": {
      "platform": "FAIMS Mobile (Field Acquired Information Management Systems)",
      "hardware": "Android mobile devices",
      "data_sources": "Soviet military 1:50,000 topographic maps from 1980s",
      "personnel": {
        "staff": "project staff (57 person-hours)",
        "volunteers": "undergraduate field school students (184 person-hours)"
      }
    },
    "track_record": {
      "prior_work": [
        {
          "activity": "TRAP mound cataloguing 2008-2016",
          "output": "773 mounds in Kazanlak Valley, 431 mounds in Yambol region",
          "method": "pedestrian surface survey with manual digitization"
        }
      ]
    }
  },
  "extraction_notes": {
    "pass": 5,
    "workflow_status": "COMPLETE",
    "extraction_timestamp": "2025-10-26T07:49:32.995396",
    "final_counts": {
      "evidence": 63,
      "claims": 26,
      "research_designs": 6,
      "methods": 6,
      "protocols": 8,
      "total": 109
    },
    "validation_status": "PASS - 100% source verification",
    "assessment_ready": true,
    "autonomous_workflow": "Successfully completed 5-pass extraction autonomously"
  }
}