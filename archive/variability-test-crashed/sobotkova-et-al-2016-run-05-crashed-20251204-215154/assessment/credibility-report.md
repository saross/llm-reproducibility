# Credibility Assessment Report

**Paper:** Measure Twice, Cut Once: Cooperative Deployment of a Generalized, Archaeology-Specific Field Data Collection System

**Authors:** Sobotkova, A., Ross, S.A., Ballsun-Stanton, B., Fairbairn, A., Thompson, J., & VanValkenburgh, P.

**Publication:** In *Mobilizing the Past for a Digital Future* (2016), pp. 337-371

**Run ID:** run-05
**Assessment Date:** 2025-12-04
**Assessor:** Claude (Opus 4.5) via research-assessor skill

---

## Executive Summary

This methodological paper presents the FAIMS (Federated Archaeological Information Management Systems) mobile platform through three deployment case studies. The paper makes a valuable contribution to digital archaeology by documenting the co-development process and quantifying deployment benefits. However, transparency and reproducibility scores are limited by undisclosed conflicts of interest, unavailable case study data, and undocumented analytical procedures.

**Overall Credibility Score: 55/100**

| Pillar | Cluster | Score | Interpretation |
|--------|---------|-------|----------------|
| Transparency | Cluster 1: Foundational Clarity | 60/100 | Moderate |
| Credibility | Cluster 2: Evidential Strength | 62.5/100 | Moderate |
| Reproducibility | Cluster 3: Reproducibility | 44/100 | Low |

---

## Paper Classification

| Attribute | Value | Confidence |
|-----------|-------|------------|
| Paper Type | Methodological (case study) | High |
| Research Approach | Inductive | High |
| Mixed Methods | Yes (qual + quant) | High |
| HARKing Risk | Low | High |

---

## Seven Signals Summary

| Signal | Score | Key Findings |
|--------|-------|--------------|
| 1. Comprehensibility | 74 | Well-written, clear conceptual framework; methods partially implicit |
| 2. Transparency | 46 | Software available; data unavailable; COI undisclosed |
| 3. Plausibility | 74 | Claims scientifically plausible, domain-appropriate |
| 4. Validity | 59 | Case study appropriate but lacks comparison; self-report measures |
| 5. Robustness | 54 | Three-site consistency; single analytical approach |
| 6. Generalisability | 63 | Good scope definition; limited to established projects |
| 7. Reproducibility | 44 | Software open; data/analysis not reproducible |

---

## Strengths

1. **Clear Conceptual Contribution:** The "generalised vs bespoke" software spectrum provides useful framework for understanding digital archaeology tools

2. **Quantified Benefits:** Concrete time savings (95% labour reduction) and cost data (AUD $900-$15,000 per deployment) provide actionable information

3. **Honest Problem Reporting:** Performance issues (E021-E022) and slower field data entry (E022) are acknowledged rather than suppressed

4. **Multi-Site Evidence:** Three geographically diverse case studies provide some confidence in pattern consistency

5. **Open Source Software:** FAIMS platform available under GPLv3 licence supports reproducibility of the tool itself

---

## Limitations

1. **Undisclosed Conflicts of Interest:** Three of six authors are FAIMS team members evaluating their own platform. No COI statement provided.

2. **Unavailable Case Study Data:** Interview transcripts and email correspondence not deposited. Thematic analysis cannot be verified.

3. **Self-Selected Participants:** Case study projects chose to adopt FAIMS; findings may not generalise to reluctant adopters.

4. **No Comparison Condition:** No comparison with FileMaker, paper-based recording, or other digital platforms.

5. **Self-Report Measures:** Time savings and data quality improvements based on researcher estimates, not systematic measurement.

6. **Implicit Analytical Procedures:** Theme identification process not documented; inter-coder reliability not reported.

---

## Contextual Considerations

### Publication Context (2016)
- Data availability statements not yet standard in HASS
- Open science practices emerging in archaeology
- Book chapter format may have constrained methods documentation

### Disciplinary Norms
- Case study methodology appropriate for exploratory evaluation
- Qualitative synthesis common in digital humanities
- Software availability exceeds many contemporaneous papers

### Stakeholder Interests
- Authors have professional stake in FAIMS success
- Balanced by inclusion of external project directors as co-authors
- Negative findings (performance issues) included despite potential reputational impact

---

## Assessment Confidence

| Aspect | Confidence Level | Notes |
|--------|-----------------|-------|
| Classification | High | Clear methodological paper with inductive approach |
| Signal scores | Moderate-High | Sufficient evidence for assessment; some interpretation required |
| Overall rating | Moderate | Contextual factors affect interpretation |

---

## Recommendations

### For Users of This Research

1. **Treat time savings as indicative rather than precise:** The 95% figure is an estimate from one project
2. **Consider your project context:** Benefits documented for established projects; may differ for new projects
3. **Evaluate current FAIMS versions:** Paper describes 2014 deployments; platform has evolved

### For Future Similar Studies

1. **Disclose conflicts of interest explicitly**
2. **Deposit interview data (even de-identified summaries)**
3. **Include comparison with alternative tools**
4. **Use systematic time-on-task measurement**
5. **Document analytical procedures in detail**

---

## Aggregate Scoring

### Calculation Method
Weighted average across clusters with equal pillar weighting:

- Transparency (Cluster 1): 60/100 × 0.33 = 20.0
- Credibility (Cluster 2): 62.5/100 × 0.33 = 20.6
- Reproducibility (Cluster 3): 44/100 × 0.33 = 14.5

**Aggregate Score: 55/100**

### Score Interpretation
| Range | Interpretation |
|-------|----------------|
| 80-100 | High credibility |
| 60-79 | Moderate credibility |
| 40-59 | Limited credibility |
| 0-39 | Low credibility |

**This paper falls in the "Limited Credibility" range**, primarily due to transparency and reproducibility weaknesses. The credibility pillar (evidential strength) scores higher, indicating that the core claims are plausible and reasonably well-supported within the constraints of a small-n case study design.

---

## Version Information

- Schema Version: 2.6
- Assessment Framework: repliCATS Seven Signals (HASS-adapted)
- Research Approach Anchors: Inductive
- Quality Gate: Track A - Full Assessment (HIGH quality extraction)

---

*Assessment generated using the research-assessor skill. This assessment reflects one structured evaluation; other assessors may weight factors differently.*
