# Credibility Assessment Report

## Key et al. (2024): Optimal Linear Estimation for Archaeological Morphometric Range

**Paper:** "Optimal linear estimation models identify the true morphological range of archaeological and primatological artefacts: Method validation and case study application"
**Journal:** Journal of Archaeological Science (2024)
**Authors:** Alastair Key, Metin I. Eren, Michelle R. Bebber, Briggs Buchanan, Alfredo Cortell-Nicolau, Carmen Martín-Ramos, Paloma de la Peña, Cameron A. Petrie, Tomos Proffitt, John Robb, Konstantina-Eleni Michelaki, Ivan Jarić

**Assessment Date:** 2026-01-14
**Assessment Quality State:** HIGH
**Research Approach:** Deductive (methodological validation)
**Paper Type:** Methodological

---

> **EXPERIMENTAL SYSTEM - DEVELOPMENT PHASE**
>
> This credibility assessment was generated by an experimental LLM-assisted system currently in development and validation.
> Assessment quality: HIGH. Findings should be considered preliminary and subject to revision as the system is refined through validation testing.

---

## Executive Summary

Key et al. (2024) presents a rigorous methodological contribution: the application of Optimal Linear Estimation (OLE) modelling to estimate true morphological ranges of archaeological artefacts from fragmentary samples. The paper demonstrates **strong overall credibility** through:

- **Exemplary validation design** using replica assemblages with known distributions as ground truth
- **Comprehensive methods documentation** enabling critical evaluation
- **Systematic sensitivity analysis** across parameter space
- **Appropriate scope constraints** acknowledging model assumptions

The primary limitation is **moderate reproducibility infrastructure**—code and data are available but not archived in dedicated repositories with persistent identifiers. For a 2024 methods paper, this represents adequate but not optimal open science practice.

### Signal Summary

| Signal | Score | Band | Priority |
|--------|-------|------|----------|
| Comprehensibility | 88 | Excellent | Primary |
| Transparency | 78 | Good | Primary |
| Plausibility | 85 | Excellent | Secondary |
| Validity | 87 | Excellent | Secondary |
| Robustness | 82 | Excellent | Deemphasised |
| Generalisability | 76 | Good | Deemphasised |
| Reproducibility | 68 | Good | Primary |

**Mean score:** 80.6/100
**Profile:** Strong methodological paper with excellent validation and documentation; moderate reproducibility infrastructure

---

## Paper Overview

### Research Question

Can Optimal Linear Estimation (OLE), a method developed for temporal extinction estimation, be repurposed to estimate the true morphological range of archaeological artefact assemblages from fragmentary samples?

### Core Contribution

The paper validates OLE for morphometric range estimation using replica assemblages with known complete distributions (n=500 handaxes, n=45 archaic points), then demonstrates application across 10 diverse case studies spanning lithic, ceramic, and metal artefacts from humans, extinct hominins, and non-human primates.

### Key Claims

1. **C001:** OLE modelling provides broadly accurate estimates for the true morphological range of artefact assemblages
2. **C002:** OLE can be applied across lithic, ceramic, and metal artefacts produced by humans, extinct hominins, and non-human primates
3. **C004:** OLE estimate accuracy increases relative to the percentage of the total assemblage used
4. **C010:** OLE extends artefact morphological ranges in all investigated case studies

### Research Approach Classification

- **Expressed:** Deductive (explicit validation framework)
- **Revealed:** Mixed (deductive validation + inductive case studies)
- **Alignment:** Matched (no HARKing concerns)
- **Primary approach:** Deductive methodological validation

---

## Credibility Assessment by Pillar

### Pillar 1: Transparency (Comprehensibility + Transparency)

**Assessment:** Strong foundational clarity supports confident evaluation

**Comprehensibility (88/100 - Excellent)**

The paper demonstrates exceptional clarity for a methodological contribution:

- Core claims are explicitly stated with clear scope boundaries
- All key terms (OLE, CI coverage, k-values, Weibull) are operationally defined
- Logical structure from validation to case studies is transparent and traceable
- Limitations are explicitly acknowledged (C020: estimates contingent on model assumptions)

The argument structure—theoretical justification → validation → demonstration—represents best practice for methods papers. Minor accessibility limitation: dense statistical terminology assumes quantitative background.

**Transparency (78/100 - Good)**

Research design and methods are comprehensively documented:

- 12 protocols specify analytical procedures in detail
- 6 methods and 6 research designs capture methodological framework
- Model assumptions (Weibull, independence, equal discovery) explicitly stated
- R version (4.3.0) specified

Infrastructure gap: Code and data in publisher supplementary rather than dedicated repositories. For a 2024 methods paper, GitHub/Zenodo archiving with DOIs would achieve Excellent transparency.

### Pillar 2: Credibility (Plausibility + Validity + Robustness + Generalisability)

**Assessment:** Strong evidential strength through rigorous validation

**Plausibility (85/100 - Excellent)**

The method is theoretically well-grounded:

- OLE is established in extinction estimation literature
- Application to morphometrics is novel but explicitly justified
- Results align with theoretical expectations (accuracy improves with sample size)
- No implausible auxiliary assumptions required
- Authors appropriately qualify conclusions

**Validity (87/100 - Excellent)**

Validation design is exceptionally rigorous:

- Replica assemblages with known complete distributions provide ground truth
- 64 parameter combinations tested (4 k-values × 4 sample percentages × 2 bounds)
- 1000 iterations per combination ensures statistical stability
- Alternative hypotheses systematically tested (k-value effects, sample size effects)
- Confounds addressed (duplicate handling has "little-to-no impact")

This represents the strongest possible validation design for a method: direct accuracy testing against known truth.

**Robustness (82/100 - Excellent)**

Despite being deemphasised for methods papers, robustness is strong:

- Systematic sensitivity analysis across k-values and sample percentages
- Core findings consistent across parameter variations
- Two different validation assemblages (handaxes, archaic points)
- 10 case studies provide triangulation across diverse contexts

Limitation: No comparison to alternative range estimation methods.

**Generalisability (76/100 - Good)**

Appropriately constrained for a methods paper:

- Scope explicitly bounded by model assumptions (RD004-006)
- 10 case studies demonstrate breadth without overclaiming
- Transfer conditions specified (C024: accuracy varies with distribution shape)
- Paper acknowledges validation scope (lithic replicas) narrower than application scope

### Pillar 3: Reproducibility

**Assessment:** Moderate infrastructure limits practical re-execution

**Reproducibility (68/100 - Good)**

Code and data are available but infrastructure is suboptimal:

**Available:**
- R scripts for validation and case study analyses
- Software version (R 4.3.0)
- Detailed parameter specifications
- CC BY licence enabling reuse

**Missing:**
- Dedicated repository with DOI
- Package dependency documentation
- Environment specification (lockfile, container)
- CodeMeta or standardised software metadata

**Execution feasibility:** "Needs work" - Analyses reproducible with effort, but dependency inference required. For automated reproduction, additional work needed.

**Era context:** For a 2024 methods paper presenting computational analyses, dedicated repository archiving represents expected practice. Supplementary-only provision is adequate but reflects earlier-era norms.

---

## Methodological Considerations

### Research Approach Alignment

The paper's expressed methodology matches its revealed approach:

- **Validation component:** Explicitly framed as hypothesis testing against ground truth—conducted exactly as described
- **Case study component:** Explicitly framed as demonstration—patterns reported without overclaiming confirmatory status
- **No HARKing concerns:** Methodological structure is transparent throughout

### Model Assumptions

The paper explicitly identifies three statistical assumptions:

1. **Weibull distribution (RD004):** Morphometric range tails follow Weibull form
2. **Independence (RD005):** Each artefact represents distinct creative event
3. **Equal discovery probability (RD006):** All morphologies equally likely to be preserved/discovered

These assumptions are reasonable for many archaeological contexts but may not universally hold. The paper appropriately frames OLE estimates as "contingent on model assumptions being met."

### Mixed Methods Structure

The paper combines:
- **Deductive validation:** Hypothesis testing against known ground truth (primary contribution)
- **Inductive case studies:** Pattern demonstration across diverse contexts (secondary)

This mixed structure is appropriate for methods papers: validation establishes credibility, case studies demonstrate applicability.

---

## Strengths and Limitations

### Principal Strengths

1. **Ground truth validation:** Replica assemblages with known distributions enable definitive accuracy testing—the gold standard for method validation
2. **Comprehensive documentation:** 12 protocols, 6 methods, 6 research designs provide complete methodological specification
3. **Systematic sensitivity analysis:** 64 parameter combinations with 1000 iterations each
4. **Appropriate epistemic humility:** Clear acknowledgement of model assumptions and interpretation limits
5. **Diverse demonstration:** 10 case studies spanning 1.8 million years across multiple materials and producers

### Principal Limitations

1. **Reproducibility infrastructure:** Supplementary-only code/data sharing with no dedicated DOIs
2. **Validation scope:** Lithic replicas only; ceramics and metals validated only through case study demonstration
3. **No comparison methods:** OLE tested in isolation; alternative range estimation approaches not compared
4. **Package dependencies:** R packages required for analyses not documented

---

## Assessment Confidence

**Overall confidence:** High

This assessment is based on:
- Complete extraction across all paper sections (Passes 0-7)
- 100% source verification (all items have verbatim quotes)
- High classification confidence (unambiguous methodological paper)
- No major extraction or classification concerns

**Potential limitations:**
- Formal metrics not computed (qualitative estimation only)
- Author ORCIDs not verified via publisher metadata
- Supplementary code not directly inspected

---

## Recommendations

### For Users of This Method

1. **Verify model assumptions** for your assemblage before applying OLE
2. **Use k=5 or k=10** based on validation findings
3. **Interpret as theoretical prediction** rather than proof of extreme morphologies
4. **Consider distribution shape** effects on accuracy (C024)

### For Future Methods Papers

1. **Archive code/data in dedicated repositories** with persistent identifiers
2. **Document all package dependencies** with versions
3. **Provide environment specification** (lockfile or container)
4. **Validate across multiple material types** in primary validation (not just case studies)

### For This Paper (if revised)

1. Create GitHub repository with Zenodo DOI for R scripts
2. Add renv.lock or requirements documentation
3. Include CodeMeta metadata for software citation

---

## Conclusion

Key et al. (2024) represents a **high-quality methodological contribution** to archaeological morphometric analysis. The validation design—testing OLE accuracy against known ground truth distributions—is rigorous and convincing. The paper demonstrates strong Foundational Clarity (excellent comprehensibility and good transparency) and strong Evidential Strength (excellent plausibility, validity, and robustness with good generalisability).

The primary area for improvement is **Reproducibility infrastructure**. While code and data are available, archiving in dedicated repositories with persistent identifiers would better serve the archaeological community's ability to adopt and verify this method.

**Overall credibility profile:** Strong methodological paper meriting confidence in its core claims about OLE validity for morphometric range estimation.

---

## Assessment Metadata

| Field | Value |
|-------|-------|
| Paper ID | key-et-al-2024 |
| Assessment Date | 2026-01-14 |
| Quality State | HIGH |
| Report Type | Standard |
| Assessor | research-assessor skill v2.1 |
| Extraction Passes | 0-7 complete |
| Classification | Pass 8 complete |
| Assessment | Pass 9 complete |

---

## Signal Scores Reference

| # | Signal | Score | Cluster | Priority |
|---|--------|-------|---------|----------|
| 1 | Comprehensibility | 88 | Foundational Clarity | Primary |
| 2 | Transparency | 78 | Foundational Clarity | Primary |
| 3 | Plausibility | 85 | Evidential Strength | Secondary |
| 4 | Validity | 87 | Evidential Strength | Secondary |
| 5 | Robustness | 82 | Evidential Strength | Deemphasised |
| 6 | Generalisability | 76 | Evidential Strength | Deemphasised |
| 7 | Reproducibility | 68 | Reproducibility | Primary |
